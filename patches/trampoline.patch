diff --git a/.gitignore b/.gitignore
index 1c83f9ec..7bae4cc2 100644
--- a/.gitignore
+++ b/.gitignore
@@ -23,3 +23,21 @@
 *.fls
 *.ilg
 *.ind
+##Generated files
+*.map
+*.hex
+*.bin
+*.lst
+##Generated goil files
+goil/makefile-unix/goil
+goil/makefile-unix/goil-debug
+##Generated example files
+examples/cortex-a/armv7/bcm2836/rpi2/blink/blink
+examples/cortex-a/armv7/bcm2836/rpi2/blink/build.py
+examples/cortex-a/armv7/bcm2836/rpi2/blink/make.py
+examples/cortex-a/armv7/bcm2836/rpi2/blink/blink_exe
+examples/cortex-r7/blink/blink
+examples/cortex-r7/blink/build.py
+examples/cortex-r7/blink/make.py
+examples/cortex-r7/blink/blink_exe
+examples/cortex-r/blink/blink_exe
diff --git a/CMakeLists.txt b/CMakeLists.txt
new file mode 100644
index 00000000..06f52597
--- /dev/null
+++ b/CMakeLists.txt
@@ -0,0 +1,92 @@
+# cmake_minimum_required(VERSION 3.16)
+set(PARENT_PROJECT_NAME ${PROJECT_NAME})
+project(${RCAR_TARGET_OS})
+
+# Must enable ASM
+enable_language(C ASM)
+
+include_directories(
+    ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/debug
+    ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/CMSIS
+)
+
+# Mark assembly files
+set_property(
+    SOURCE
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_invoque.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/scif.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/boot.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_stacks.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_vector_table.s
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_irq.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_system_call.S
+    PROPERTY
+        LANGUAGE ASM
+)
+
+# Generated source files
+set_source_files_properties(
+    SOURCE
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_app_config.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_dispatch_table.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/autosar_main.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/autosar_threads.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_invoque.S
+    PROPERTIES GENERATED TRUE
+)
+
+add_library(${RCAR_TARGET_OS}-${PARENT_PROJECT_NAME}
+    STATIC
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_invoque.S
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_app_config.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/tpl_dispatch_table.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/autosar_main.c
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}/autosar_threads.c
+
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_alarm_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_interrupt_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_os.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_os_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_error.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_task_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_resource_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_event_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_machine_arm.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_stacks.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_vector_table.s
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_irq.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/tpl_system_call.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl_gic.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/boot.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/interrupts.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/r_os_cache.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/serial.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/system_rcar_gen3.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/tick_config.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/scif.S
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common/heap_useNewlib.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_timeobj_kernel.c
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os/tpl_os_action.c
+)
+
+target_include_directories(${RCAR_TARGET_OS}-${PARENT_PROJECT_NAME}
+    PUBLIC
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/os
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/com
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar
+        ${CMAKE_VLIB_ROOT}/os/${RCAR_TARGET_OS}/machines/cortex-r/armv7/RCar/common
+        ${CMAKE_BINARY_DIR}/app/${PARENT_PROJECT_NAME}/${RCAR_TARGET_OS}
+)
+
+# Depends on application "dummy",
+#  this causes goil to execute first and generate our source files
+add_dependencies(${RCAR_TARGET_OS}-${PARENT_PROJECT_NAME} ${PARENT_PROJECT_NAME}_goil_files)
+
+target_link_libraries(${RCAR_TARGET_OS}-${PARENT_PROJECT_NAME}
+    ${PARENT_PROJECT_NAME}
+)
+
+# default prefix is "lib"
+set_target_properties(${RCAR_TARGET_OS}-${PARENT_PROJECT_NAME} PROPERTIES PREFIX "")
diff --git a/cmd/env.sh b/cmd/env.sh
new file mode 100755
index 00000000..75459cf6
--- /dev/null
+++ b/cmd/env.sh
@@ -0,0 +1,2 @@
+echo  Adding $(pwd)/goil/makefile-unix to PATH
+export PATH=$PATH:$(pwd)/goil/makefile-unix
diff --git a/examples/cortex-r/blink/.gitignore b/examples/cortex-r/blink/.gitignore
new file mode 100755
index 00000000..56ec7bff
--- /dev/null
+++ b/examples/cortex-r/blink/.gitignore
@@ -0,0 +1,6 @@
+blink
+build
+*_exe.elf
+*.bin
+*.map
+*.py
diff --git a/examples/cortex-r/blink/README.md b/examples/cortex-r/blink/README.md
new file mode 100644
index 00000000..2a8dae32
--- /dev/null
+++ b/examples/cortex-r/blink/README.md
@@ -0,0 +1,19 @@
+|=-----=[ Blink example ]=-----=|
+
+This application is a simple periodic example which prints a periodic message on an UART console.
+This application can be launched with a bootloader that will be soon pushed on the GitHub.
+
+This is for the R-Car Gen3 SoC using the ARM Cortex-R7 CPU
+
+How to build the example:
+Generates the code:
+```
+goil --target=cortex-r/armv7/RCar --templates=../../../goil/templates/ blink.oil
+```
+
+Build:
+```
+./make.py
+```
+
+
diff --git a/examples/cortex-r/blink/blink.c b/examples/cortex-r/blink/blink.c
new file mode 100644
index 00000000..82f94a56
--- /dev/null
+++ b/examples/cortex-r/blink/blink.c
@@ -0,0 +1,193 @@
+#include "tpl_os.h"
+
+//#include "bcm2836.h"
+//#include "emblib.h"
+//#include "rpi2_uart.h"
+//#include "rpi2_timer.h"
+//#include "rpi2_trace.h"
+
+volatile unsigned int nbsvc;
+extern unsigned int __SP_irq_bot_ ;
+extern unsigned int __SP_irq_top_;
+extern unsigned int __SP_svc_bot_;
+extern unsigned int __SP_svc_top_;
+extern unsigned int __SP_usr_bot_;
+extern unsigned int __SP_usr_top_;
+
+#define APP_Task_blink_START_SEC_CODE
+#include "tpl_memmap.h"
+FUNC(int, OS_APPL_CODE) main(void) {
+  unsigned int ra;
+
+  #if 1
+  // CR7 TODO
+  /* Setup here or better in the BSP (machines/cortex-r7/armv7/bcm2836/tpl_machine_bcm2836.c
+     or machines/cortex-r7/tpl_machine_arm.c)
+     - I/O if needed 
+     - Timer tick
+     - GIC
+  */
+  #else
+  uart_init();
+
+  uart_write_string((const unsigned char*)"MAIN");
+
+  ra=readFromReg(GPFSEL4);
+  ra&=~(7<<21);
+  ra|=1<<21;
+  writeToReg(GPFSEL4,ra);
+
+  ra=readFromReg(GPFSEL3);
+  ra&=~(7<<15);
+  ra|=1<<15;
+  writeToReg(GPFSEL3,ra);
+
+  ra=readFromReg(GPFSEL2);
+  ra&=~(7<<3);
+  ra|=1<<3;
+  writeToReg(GPFSEL2,ra);
+
+  writeToReg(GPCLR1,1<<(47-32));
+  writeToReg(GPCLR1,1<<(35-32));
+  writeToReg(GPCLR0,1<<21);
+
+  /* Setup the system timer interrupt
+   * Timer frequency = Clk/250 * 1000
+   * PreDivider = 249
+   * timer_clock = apb_clock / (PreDivider + 1) = 250MHz / (249 + 1) = 1MHz
+   * Load value is 1000 so that the ARM timer raises an IRQ every 1ms
+   * 
+   */
+  RPI_GetArmTimer()->Load = 1000;
+  /* Setup the ARM Timer */
+  RPI_GetArmTimer()->Control = ARM_TIMER_CTRL_23BIT
+                             | ARM_TIMER_CTRL_ENABLE
+                             | ARM_TIMER_CTRL_INT_ENABLE
+                             | ARM_TIMER_CTRL_PRESCALE_1;
+  RPI_GetArmTimer()->PreDivider = 0x000000F9;
+
+  writeToReg(IRQ_ENABLE_BASIC,1);
+
+  /* we should not have to enable IRQ as first context switch should enable them */
+  enable_irq();
+  // CR7 TODO
+  #endif
+
+  StartOS(OSDEFAULTAPPMODE);
+  return 0;
+}
+
+FUNC(void, OS_APPL_CODE) pushbutton_isr_function(void)
+{
+  // do something interesting here...toggle LED?
+}
+
+TASK(blink) {
+  static uint32 compte = 0;
+
+  compte++;
+  //uart_write_strings((const unsigned char*)"Tache BLINK : ");
+  //hexstring(compte);
+
+  TerminateTask();
+}
+#define APP_Task_blink_STOP_SEC_CODE
+#include "tpl_memmap.h"
+
+#define APP_Task_stacks_START_SEC_CODE
+#include "tpl_memmap.h"
+TASK(stacks)
+{
+    #if 0
+    // CR7
+  uint32 botAddr;
+  uint32 topAddr;
+  uint32 sp_irq_value;
+  uint32 sp_svc_value;
+  uint32 sp_usr_value;
+
+  uart_write_string((const unsigned char*)"Tache STACKS");
+
+  __asm volatile ("mrs %0, SP_irq" : "=r" (sp_irq_value));
+  __asm volatile ("mrs %0, SP_svc" : "=r" (sp_svc_value));
+  __asm volatile ("mov %0, sp" : "=r" (sp_usr_value));
+
+  if ( (sp_irq_value < (uint32)&__SP_irq_bot_) || (sp_irq_value > (uint32)&__SP_irq_top_) ) {
+    uart_write_string((const unsigned char*)"SP_irq : ");
+    hexstrings((uint32)&__SP_irq_bot_);
+    uart_write_strings((const unsigned char*)" | ");
+    hexstrings(sp_irq_value);
+    uart_write_strings((const unsigned char*)" | ");
+    hexstrings((uint32)&__SP_irq_top_);
+    uart_write_char((unsigned char)0x0D);
+    uart_write_char((unsigned char)0x0A);
+  }
+
+  if ( (sp_svc_value < (uint32)&__SP_svc_bot_) || (sp_svc_value > (uint32)&__SP_svc_top_) ) {
+    uart_write_string((const unsigned char*)"SP_svc : ");
+    hexstrings((uint32)&__SP_svc_bot_);
+    uart_write_strings((const unsigned char*)" | ");
+    hexstrings(sp_svc_value);
+    uart_write_strings((const unsigned char*)" | ");
+    hexstrings((uint32)&__SP_svc_top_);
+    uart_write_char((unsigned char)0x0D);
+    uart_write_char((unsigned char)0x0A);
+  }
+
+  // if ( (sp_usr_value < (uint32)&__SP_usr_bot_) || (sp_usr_value > (uint32)&__SP_usr_top_) ) {
+  //   uart_write_string((const unsigned char*)"SP_usr : ");
+  //   hexstrings((uint32)&__SP_usr_bot_);
+  //   uart_write_strings((const unsigned char*)" | ");
+  //   hexstrings(sp_usr_value);
+  //   uart_write_strings((const unsigned char*)" | ");
+  //   hexstrings((uint32)&__SP_usr_top_);
+  //   uart_write_char((unsigned char)0x0D);
+  //   uart_write_char((unsigned char)0x0A);
+  // }
+
+  // CR7
+  #endif
+  TerminateTask();
+}
+#define APP_Task_stacks_STOP_SEC_CODE
+#include "tpl_memmap.h"
+
+#define OS_START_SEC_CODE
+#include "tpl_memmap.h"
+/*
+ *  * This is necessary for ST libraries
+ *   */
+FUNC(void, OS_CODE) assert_failed(uint8* file, uint32 line)
+{
+}
+
+FUNC(void, OS_CODE) PreTaskHook()
+{
+  TaskType task_id = 0;
+  GetTaskID(&task_id);
+  if (task_id == blink) {
+    // ledOn(ORANGE);
+  }
+}
+
+FUNC(void, OS_CODE) PostTaskHook()
+{
+  TaskType task_id = 0;
+  GetTaskID(&task_id);
+  if (task_id == blink) {
+    // ledOff(ORANGE);
+  }
+}
+
+/* The following code was added to make the linker work after 
+   https://ree-dusgitlab.ree.adwin.renesas.com/RCarGen3_VLib/OS/trampoline/-/commit/822b241a2dee20c73301e0e41a63cc4c5981f747
+   TODO: Remove _sbrk from the code
+ */
+void _sbrk(void) {
+    while (1) {
+    }
+}
+
+
+#define OS_STOP_SEC_CODE
+#include "tpl_memmap.h"
diff --git a/examples/cortex-r/blink/blink.oil b/examples/cortex-r/blink/blink.oil
new file mode 100644
index 00000000..b39fcbd2
--- /dev/null
+++ b/examples/cortex-r/blink/blink.oil
@@ -0,0 +1,97 @@
+OIL_VERSION = "2.5";
+
+IMPLEMENTATION trampoline {
+
+    /* This fix the default STACKSIZE of tasks */
+    TASK {
+        UINT32 STACKSIZE = 300 ;
+    } ;
+
+    /* This fix the default STACKSIZE of ISRs */
+    ISR {
+        UINT32 STACKSIZE = 200 ;
+    } ;
+};
+
+CPU blink {
+  OS config {
+    STATUS = EXTENDED;
+    PRETASKHOOK = FALSE;
+    POSTTASKHOOK = FALSE;
+
+    BUILD = TRUE {
+      TRAMPOLINE_BASE_PATH = "../../..";
+      APP_SRC = "blink.c";
+      APP_NAME = "blink_exe";
+      CFLAGS  = "-O0";
+      LDFLAGS = "-Wl,-Map=blink.map -lg -lm -lc -lnosys";
+      COMPILER = "arm-none-eabi-gcc";
+      ASSEMBLER = "arm-none-eabi-as";
+      LINKER = "arm-none-eabi-gcc";
+      COPIER = "arm-none-eabi-objcopy";
+      SYSTEM = PYTHON;
+    };
+    SYSTEM_CALL = TRUE;
+    MEMMAP = TRUE {
+      COMPILER = gcc;
+      LINKER = gnu_ld { SCRIPT = "script.ld"; };
+      ASSEMBLER = gnu_as;
+      MEMORY_PROTECTION = FALSE;
+    };
+  };
+
+  APPMODE std {};
+
+  TASK blink {
+    PRIORITY = 1;
+    AUTOSTART = FALSE;
+    ACTIVATION = 1;
+    SCHEDULE = FULL;
+  };
+
+  ALARM blink_blink {
+    COUNTER = SystemCounter;
+    ACTION = ACTIVATETASK {
+      TASK = blink;
+    };
+    AUTOSTART = TRUE {
+      APPMODE = std;
+      ALARMTIME = 250;
+      CYCLETIME = 250;
+    };
+  };
+
+  COUNTER pushbutton_counter {
+    TICKSPERBASE = 1;
+    MAXALLOWEDVALUE = 65535;
+    MINCYCLE = 1;
+    SOURCE = GPIO_CH5;
+  };
+
+  ISR pushbutton_isr {
+    CATEGORY = 2;
+    PRIORITY = 1;
+
+    SOURCE = GPIO_CH5 {  PIN = PIN5  { TRIGGER = BOTH; PULL=UP; }; };
+  };
+
+  TASK stacks {
+    PRIORITY = 2;
+    AUTOSTART = FALSE;
+    ACTIVATION = 1;
+    SCHEDULE = FULL;
+  };
+
+  ALARM fast {
+    COUNTER = SystemCounter;
+    ACTION = ACTIVATETASK {
+      TASK = stacks;
+    };
+    AUTOSTART = TRUE {
+      APPMODE = std;
+      ALARMTIME = 50;
+      CYCLETIME = 50;
+    };
+  };
+
+};
diff --git a/goil/galgas-sources/goil_options.galgas b/goil/galgas-sources/goil_options.galgas
index 5bb25af4..4cee3fe1 100755
--- a/goil/galgas-sources/goil_options.galgas
+++ b/goil/galgas-sources/goil_options.galgas
@@ -55,7 +55,7 @@ option goil_options {
   'c',
   "config"
   -> "Specifies the OIL config file used by goil" default "config"
-  
+
 #@bool   orti_on           : '\0', "orti"              -> "Generate an ORTI file" ;
 #@uint   corrected_bits    : '\0', "crc"               -> "Generate correcting code" default 0 ;
 
diff --git a/goil/templates/build/build_py.goilTemplate b/goil/templates/build/build_py.goilTemplate
index 6075013f..bf4bc663 100755
--- a/goil/templates/build/build_py.goilTemplate
+++ b/goil/templates/build/build_py.goilTemplate
@@ -603,7 +603,7 @@ make.addGoal("% !goal::NAME %", depList, "% !goal::MESSAGE %")%
 end foreach
 %
 
-make.runGoal(maxParallelJobs, maxParallelJobs == 1)
+make.runGoal(maxParallelJobs, True)
 
 postVariableMapping = dict(
   MACHINE_PATH='% ! MACHINESPATH %',
diff --git a/goil/templates/build/make_py.goilTemplate b/goil/templates/build/make_py.goilTemplate
index 131c5fb2..3e3ad835 100755
--- a/goil/templates/build/make_py.goilTemplate
+++ b/goil/templates/build/make_py.goilTemplate
@@ -163,7 +163,7 @@ make.addRule (rule)
 make.addGoal("all", sourceList, "Building all")
 
 if goal == "all" or goal == "clean" :
-  make.runGoal(maxParallelJobs, maxParallelJobs == 1)
+  make.runGoal(maxParallelJobs, True)
 
 #----------------------------------------------------------------------
 #--- Call the seconde stage of make
diff --git a/goil/templates/code/cortex-r/armv7/counter_call.goilTemplate b/goil/templates/code/cortex-r/armv7/counter_call.goilTemplate
new file mode 100755
index 00000000..fc505fc9
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/counter_call.goilTemplate
@@ -0,0 +1,38 @@
+#include "tpl_os_kernel.h"          /* tpl_schedule */
+#include "tpl_os_timeobj_kernel.h"  /* tpl_counter_tick */
+#include "tpl_machine_interface.h"  /* tpl_switch_context_from_it */
+
+#define OS_START_SEC_CODE
+#include "tpl_memmap.h"
+%
+
+foreach interrupt in INTERRUPT_SOURCE do
+  let counterFct := emptylist
+  foreach counter in COUNTERS do
+    if counter::SOURCE == interrupt::NAME then
+      let counterFct += counter::NAME
+    end if
+  end foreach
+  foreach cpt_fct in counterFct
+    before
+%
+FUNC(void, OS_CODE) tpl_tick_% !interrupt::NAME %()
+{
+%
+    do
+      %  tpl_counter_tick(&% !cpt_fct %_counter_desc);
+%
+    after %
+
+  if (tpl_kern.need_schedule)
+  {
+    tpl_schedule_from_running();
+    LOCAL_SWITCH_CONTEXT()
+  }
+}
+%
+  end foreach
+end foreach
+%
+#define OS_STOP_SEC_CODE
+#include "tpl_memmap.h"
diff --git a/goil/templates/code/cortex-r/armv7/interrupt_table.goilTemplate b/goil/templates/code/cortex-r/armv7/interrupt_table.goilTemplate
new file mode 100755
index 00000000..bcfd9343
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/interrupt_table.goilTemplate
@@ -0,0 +1,177 @@
+#include "tpl_machine.h"
+
+%
+%
+#define OS_START_SEC_CODE
+#include "tpl_memmap.h"
+%
+
+#------------------------------------------------------------------------------*
+# Target specific initializations
+# build the maps for IRQ
+#
+let INTERRUPT_SOURCE_MAP := mapof INTERRUPT_SOURCE by NAME
+
+let objForSRC := emptymap
+let objlist := ISR | COUNTER
+display objlist
+let objset := [objlist setBy: "SOURCE"]
+display objset
+# Map ISR into objForSRC
+display ISR
+foreach isr in ISR do
+  let key := isr::SOURCE
+  display key
+  display isr
+  if not exists objForSRC[key] then
+    let objForSRC[key] := emptylist
+  end if
+  let isr::KIND := "ISR"
+  let isr::ACK := INTERRUPT_SOURCE_MAP[key]::ACK
+  let objForSRC[key] += isr
+ display objForSRC[key]
+end foreach
+# Map COUNTER into objForSRC
+display COUNTER
+foreach cnt in COUNTER do
+  let key := cnt::SOURCE
+  if not exists objForSRC[key] then
+    let objForSRC[key] := emptylist
+  end if
+  let cnt::KIND := "COUNTER"
+#  display INTERRUPTMAP[key]
+  let cnt::ACK := INTERRUPT_SOURCE_MAP[key]::ACK
+  let objForSRC[key] += cnt
+ display objForSRC[key]
+end foreach
+
+# Build the list of counters to call
+let counterForIRQ := emptymap
+
+# Build a list of virtual objects (counters) each of them holding values :
+# handlerSource, handlerName, handlerAck, generatePrimaryIrq
+foreach objList in objForSRC do
+  foreach obj in objList do
+    if obj::KIND == "COUNTER" then
+      let counterForIRQ[KEY] := emptylist
+    end if
+  end foreach
+  foreach obj in objList do
+    if obj::KIND == "COUNTER" then
+      let  counterForIRQ[KEY] += obj::NAME
+    end if
+  end foreach
+end foreach
+
+#------------------------------------------------------------------------------*
+
+foreach objList_KEY,objList in objForSRC do
+  let indexISR2 := 0
+  foreach obj in objList do
+    if obj::KIND == "ISR" then
+%  extern FUNC(void, OS_CODE) % !obj::NAME %_function(void);
+%
+      end if
+      if obj::ACK then
+%  extern FUNC(void, OS_CODE) %!objList_KEY%_ClearFlag(void);
+%
+      end if
+  end foreach
+end foreach
+
+foreach objList_KEY,objList in objForSRC do
+%
+FUNC(void, OS_CODE) % !objList_KEY %_Handler(void)
+{
+%
+  let indexISR2 := 0
+  foreach obj in objList do
+    if obj::KIND == "ISR" then
+# ISR 1
+      if obj::CATEGORY == 1 then
+%
+  % !obj::NAME %_function();
+%
+      else
+# ISR2
+        if obj::CATEGORY == 2 then
+	display TASKS
+	display indexISR2
+%
+  tpl_central_interrupt_handler(% !obj::NAME %_id);
+%
+          let indexISR2 += 1
+        else
+          error obj::CATEGORY : "This interrupt category ".obj::CATEGORY." does not exist"
+        end if
+      end if
+    end if
+  end foreach
+  foreach objCounter_KEY,objCounter in counterForIRQ do
+    if objCounter_KEY == objList_KEY then
+      %  tpl_tick_% !objCounter_KEY %();
+%
+    end if
+  end foreach
+  let ackDone := false
+  foreach obj in objList do
+    if not ackDone then
+      if obj::ACK then
+        let ackDone := true
+%  %!objList_KEY%_ClearFlag();
+%
+      end if
+    end if
+  end foreach
+%
+}
+%
+end foreach
+%
+#define OS_STOP_SEC_CODE
+#include "tpl_memmap.h"
+%
+
+%
+
+/* Interrupt table vector */
+%
+%
+#define OS_START_SEC_CODE
+#include "tpl_memmap.h"
+%
+loop ENTRY from 0 to INTERRUPT_COUNT::IT_TABLE_SIZE - 1
+ before
+%
+CONST(tpl_it_vector_entry, OS_CONST) tpl_it_vector[% !INTERRUPT_COUNT::IT_TABLE_SIZE %] = {
+%
+ do
+   let src_found := false
+   foreach src in INTERRUPT_SOURCE do
+     if not src_found then
+       if src::SOURCE_NUM == ENTRY then
+         if exists objForSRC[src::NAME] then
+          let src_found := true
+%  { (tpl_it_handler)% !src::NAME %_Handler, (void *)NULL }%
+         end if
+       end if
+     end if
+     # Il ne doit rien y avoir ici
+   end foreach
+   if not src_found then
+%  { (tpl_it_handler)tpl_null_it, (void *)NULL }%   
+   end if
+ between
+%,
+%
+ after
+%
+};
+% 
+end loop
+%
+#define OS_STOP_SEC_CODE
+#include "tpl_memmap.h"
+%
+
+# vim:ft=goil_templates
diff --git a/goil/templates/code/cortex-r/armv7/process_specific.goilTemplate b/goil/templates/code/cortex-r/armv7/process_specific.goilTemplate
new file mode 100755
index 00000000..3fde5c78
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/process_specific.goilTemplate
@@ -0,0 +1,42 @@
+/*
+ * % !proc::KIND % % !proc::NAME % stack
+ */
+%
+if exists task::SECTION then
+%#define % !task::SECTION %_START_SEC_VAR_16BIT%
+else
+%#define APP_% !proc::KIND %_% !proc::NAME %_START_SEC_STACK
+%
+end if
+%
+#include "tpl_memmap.h"
+VAR(tpl_stack_word, OS_APPL_DATA) % !proc::NAME %_stack_zone[% !proc::STACKSIZE %/sizeof(tpl_stack_word)];
+%
+if exists task::SECTION then
+%#define % !task::SECTION %_STOP_SEC_VAR_16BIT%
+else
+%#define APP_% !proc::KIND %_% !proc::NAME %_STOP_SEC_STACK
+%
+end if
+%
+#include "tpl_memmap.h"
+
+#define % !proc::NAME %_STACK {% !proc::NAME %_stack_zone, % !proc::STACKSIZE %}
+
+/*
+ * % !proc::KIND % % !proc::NAME % context
+ */
+#define OS_START_SEC_VAR_NOINIT_32BIT
+#include "tpl_memmap.h"
+VAR(arm_context, OS_VAR) % !proc::NAME %_int_context;
+
+#define % !proc::NAME %_CONTEXT &% !proc::NAME %_int_context
+
+#define OS_STOP_SEC_VAR_NOINIT_32BIT
+#include "tpl_memmap.h"
+%if proc::KIND == "ISR" then 
+    if not exists proc::SOURCE then
+       error proc::NAME : "SOURCE attribute not defined for ".proc::KIND." ".proc::NAME
+    end if
+  end if
+%
diff --git a/goil/templates/code/cortex-r/armv7/service_call.goilTemplate b/goil/templates/code/cortex-r/armv7/service_call.goilTemplate
new file mode 100755
index 00000000..d0d6e1bc
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/service_call.goilTemplate
@@ -0,0 +1,7 @@
+  .global % !exists api_func::ACTUAL default ( api_func::NAME ) %
+% !exists api_func::ACTUAL default ( api_func::NAME ) %:
+  stmfd sp!,{lr}
+  mov r3,#% !api_sec::ID_PREFIX %ServiceId_% !api_func::NAME %
+  swi #% !api_sec::ID_PREFIX %ServiceId_% !api_func::NAME %
+  ldmfd sp!,{lr}
+  mov pc,lr
diff --git a/goil/templates/code/cortex-r/armv7/std_as_code_dir.goilTemplate b/goil/templates/code/cortex-r/armv7/std_as_code_dir.goilTemplate
new file mode 100755
index 00000000..bc3be771
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/std_as_code_dir.goilTemplate
@@ -0,0 +1,3 @@
+.text
+.code 32
+.align 2
diff --git a/goil/templates/code/cortex-r/armv7/tpl_invoque_s.goilTemplate b/goil/templates/code/cortex-r/armv7/tpl_invoque_s.goilTemplate
new file mode 100755
index 00000000..b8559c1b
--- /dev/null
+++ b/goil/templates/code/cortex-r/armv7/tpl_invoque_s.goilTemplate
@@ -0,0 +1,7 @@
+%
+!PROJECT %/tpl_invoque.S
+%
+write to PROJECT."/tpl_invoque.S":
+  let EXTENSION := "S"
+  template tpl_invoque in code
+end write
\ No newline at end of file
diff --git a/goil/templates/code/isr_descriptor.goilTemplate b/goil/templates/code/isr_descriptor.goilTemplate
index 586efef1..d23b5ac6 100755
--- a/goil/templates/code/isr_descriptor.goilTemplate
+++ b/goil/templates/code/isr_descriptor.goilTemplate
@@ -84,7 +84,7 @@ if OS::NUMBER_OF_CORES > 1 then%
 %
 
   /* ISR base priority       */  % !isr::PRIORITY %,
-  /* ISR activation count     */  1,
+  /* ISR activation count     */ 2,
   /* ISR type                */  IS_ROUTINE,
 #if WITH_AUTOSAR_TIMING_PROTECTION == YES
 %
diff --git a/goil/templates/code/orti.goilTemplate b/goil/templates/code/orti.goilTemplate
index 4b39110d..135ede5d 100644
--- a/goil/templates/code/orti.goilTemplate
+++ b/goil/templates/code/orti.goilTemplate
@@ -146,6 +146,29 @@ end if
     ] RUNNINGTASK[];
     ENUM [
 %
+foreach proc in PROCESSES do
+  if proc::KIND == "Task" then
+%      "% !proc::NAME %" = % !INDEX %,
+%
+  else
+%      "X" = % !INDEX %,
+%
+  end if
+end foreach
+
+if OS::NUMBER_OF_CORES > 1 then
+  loop core_id from 0 to OS::NUMBER_OF_CORES - 1 do
+%      "idle_% !core_id %" = % !([PROCESSES length] + core_id)
+  between %,
+%
+  end loop
+else
+%      "idle" = % ![PROCESSES length]
+end if
+%
+    ] vs_SIGNAL_RUNNINGTASK[];
+    ENUM [
+%
 foreach proc in PROCESSES do
   if proc::KIND == "ISR" then
 %      "% !proc::NAME %" = % !INDEX %,
@@ -167,6 +190,29 @@ else
 end if
 %
     ] RUNNINGISR2[];
+    ENUM [
+%
+foreach proc in PROCESSES do
+  if proc::KIND == "ISR" then
+%      "% !proc::NAME %" = % !INDEX %,
+%
+  else
+%      "X" = % !INDEX %,
+%
+  end if
+end foreach
+
+if OS::NUMBER_OF_CORES > 1 then
+  loop core_id from 0 to OS::NUMBER_OF_CORES - 1 do
+%      "X" = % !([PROCESSES length] + core_id)
+  between %,
+%
+  end loop
+else
+%      "X" = % ![PROCESSES length]
+end if
+%
+    ] vs_SIGNAL_RUNNINGISR2[];
     CTYPE RUNNINGTASKPRIORITY[];
     TOTRACE ENUM [
 %
@@ -354,6 +400,9 @@ end foreach
 end if%
   };
 
+%
+# TODO: Collapase these two lists with a for loop...
+%
   TASK
   {
     CTYPE PRIORITY;
@@ -362,10 +411,12 @@ end if%
       "READY" = 1,
       "RUNNING" = 2,
       "WAITING" = 3,
+      "AUTOSTART" = 4,
+      "READY_AND_NEW" = 5,
     ] STATE;
     ENUM [%
 foreach proc in PROCESSES do%
-      "% !proc::NAME %_stack" = "&(% !proc::NAME %_stack_zone[0])"%
+      "% !proc::NAME %_stack":%!proc::NAME%_stack = "&(% !proc::NAME %_stack_zone[0])"%
 between %,%
 end foreach
   %
@@ -373,7 +424,7 @@ end foreach
     CTYPE CURRENTACTIVATIONS;
     ENUM [%
 foreach proc in PROCESSES do%
-      "% !proc::NAME %_context" = "&(tpl_stat_proc_table[% !INDEX %].context)"%
+      "% !proc::NAME %_context":%!proc::NAME%_context = "&(tpl_stat_proc_table[% !INDEX %]->context)"%
 between %,%
 end foreach
   %
@@ -388,10 +439,12 @@ end foreach
       "READY" = 1,
       "RUNNING" = 2,
       "WAITING" = 3,
+      "AUTOSTART" = 4,
+      "READY_AND_NEW" = 5,
     ] STATE;
     ENUM [%
 foreach proc in PROCESSES do%
-      "% !proc::NAME %_stack" = "&(% !proc::NAME %_stack_zone[0])"%
+      "% !proc::NAME %_stack":%!proc::NAME%_stack = "&(% !proc::NAME %_stack_zone[0])"%
 between %,%
 end foreach
   %
@@ -399,7 +452,7 @@ end foreach
     CTYPE CURRENTACTIVATIONS;
     ENUM [%
 foreach proc in PROCESSES do%
-      "% !proc::NAME %_context" = "&(tpl_stat_proc_table[% !INDEX %].context)"%
+      "% !proc::NAME %_context":%!proc::NAME%_context = "&(tpl_stat_proc_table[% !INDEX %]->context)"%
 between %,%
 end foreach
   %
@@ -478,6 +531,13 @@ end foreach
   /* ----------------------------------------------------------------------------
    * Architecture dependant orti implementation
    */
+  CONTEXT
+  {
+    CTYPE VALID;
+    CTYPE ADDRESS;
+    CTYPE _CPU_PC;
+    CTYPE _CPU_R13;
+  };
 %
 template if exists custom_orti_implementation
 %
@@ -512,7 +572,11 @@ loop core_id from 0 to OS::NUMBER_OF_CORES - 1 do
 %
   RUNNINGTASK% !orti_core_a % = "% !orti_running_task_id %";
   RUNNINGISR2% !orti_core_a % = "% !orti_running_task_id %";
-  RUNNINGTASKPRIORITY% !orti_core_a % = "tpl_dyn_proc_table[% !orti_running_task_id %].priority";
+%
+#  vs_SIGNAL_RUNNINGTASK% !orti_core_a % = "OTM.0.1.0";
+#  vs_SIGNAL_RUNNINGISR2% !orti_core_a % = "OTM.0.1.1";
+%
+  RUNNINGTASKPRIORITY% !orti_core_a % = "tpl_dyn_proc_table[% !orti_running_task_id %]->priority";
   LASTERROR% !orti_core_a % = "% !orti_last_error %";
   CURRENTAPPMODE% !orti_core_a % = "% !orti_current_appmode %"
   VALID% !orti_core_a % = "% !orti_running_task_id % != -1";
@@ -554,7 +618,7 @@ _vs_OS CORE_% !core_id %
   vs_SMP_NUMCPU = "% !OS::NUMBER_OF_CORES %";
   RUNNINGTASK% !orti_core_a % = "% !orti_running_task_id %";
   RUNNINGISR2% !orti_core_a % = "% !orti_running_task_id %";
-  RUNNINGTASKPRIORITY% !orti_core_a % = "tpl_dyn_proc_table[% !orti_running_task_id %].priority";
+  RUNNINGTASKPRIORITY% !orti_core_a % = "tpl_dyn_proc_table[% !orti_running_task_id %]->priority";
   LASTERROR% !orti_core_a % = "% !orti_last_error %";
   CURRENTAPPMODE% !orti_core_a % = "% !orti_current_appmode %"
   VALID% !orti_core_a % = "% !orti_running_task_id % != -1";
@@ -577,11 +641,11 @@ _vs_ISR % !proc::NAME
   end if
 %
 {
-  PRIORITY = "tpl_dyn_proc_table[% !INDEX %].priority";
-  STATE = "tpl_dyn_proc_table[% !INDEX %].state";
+  PRIORITY = "tpl_dyn_proc_table[% !INDEX %]->priority";
+  STATE = "tpl_dyn_proc_table[% !INDEX %]->state";
   STACK = "&(% !proc::NAME %_stack_zone[0])";
-  CURRENTACTIVATIONS = "tpl_dyn_proc_table[% !INDEX %].activate_count";
-  CONTEXT = "&(tpl_stat_proc_table[% !INDEX %].context)";
+  CURRENTACTIVATIONS = "tpl_dyn_proc_table[% !INDEX %]->activate_count";
+  CONTEXT = "&(tpl_stat_proc_table[% !INDEX %]->context)";
 };
 %
 end foreach
@@ -706,6 +770,29 @@ end foreach
  * Architecture dependant orti definitions
  */
 %
+foreach proc in PROCESSES do%
+CONTEXT %!proc::NAME%_context {
+  VALID = "1";
+  ADDRESS = "&(tpl_stat_proc_table[% !INDEX %]->context)";
+  _CPU_CPSR = "tpl_stat_proc_table[% !INDEX %]->context->psr"; %
+  loop regnum from 0 to 14 do %
+  _CPU_R% !regnum % = "tpl_stat_proc_table[% !INDEX %]->context->r[% !regnum %]"; %
+  end loop %
+  _CPU_PC = "tpl_stat_proc_table[% !INDEX %]->context->r[15]";
+};  
+%
+end foreach
+
+foreach proc in PROCESSES do%
+STACK %!proc::NAME%_stack {
+  VALID = "1";
+  SIZE = "tpl_stat_proc_table[% !INDEX %]->stack.stack_size";
+  BASEADDRESS = "tpl_stat_proc_table[% !INDEX %]->stack.stack_zone";
+  STACKDIRECTION = "down";
+  FILLPATTERN = "0xDEADBEEF";
+};  
+%
+end foreach
 template if exists custom_orti_definition
 
 %
diff --git a/goil/templates/code/tpl_app_custom_types_h.goilTemplate b/goil/templates/code/tpl_app_custom_types_h.goilTemplate
index 9136af68..cba7ea24 100755
--- a/goil/templates/code/tpl_app_custom_types_h.goilTemplate
+++ b/goil/templates/code/tpl_app_custom_types_h.goilTemplate
@@ -53,9 +53,9 @@ typedef uint% ! [1 << [APPMODE length] - 1 numberOfBytes] * 8 % tpl_appmode_mask
 /**
  * tpl_priority represents a task's or a resource's priority.
  *
- * @warning This type must be signed.
+ * The data type is computed according to the number of ISR2 and jobs that can * be present in the list of ready tasks.
  */
-typedef sint% !8*KEY_SIZE % tpl_priority;
+typedef uint% !8*KEY_SIZE % tpl_priority;
 
 /**
  * tpl_activate_counter is used to count
diff --git a/goil/templates/config/cortex-r/armv7/RCar/config.oil b/goil/templates/config/cortex-r/armv7/RCar/config.oil
new file mode 100755
index 00000000..d05a7ad4
--- /dev/null
+++ b/goil/templates/config/cortex-r/armv7/RCar/config.oil
@@ -0,0 +1,577 @@
+#includeifexists <buildOptions.oil>
+
+/*
+ * Interrupt sources of the board
+ */
+CPU RCar {
+  INTERRUPT_COUNT nb_it {
+    IT_TABLE_SIZE = 512;
+  };
+  INTERRUPT_VECTOR Reset                 { VECTOR_NUM = 0; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR Undefined_Instruction { VECTOR_NUM = 1; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR Supervisor_Call       { VECTOR_NUM = 2; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR Prefetch_Abort        { VECTOR_NUM = 3; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR Data_Abort            { VECTOR_NUM = 4; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR Reserved              { VECTOR_NUM = 5; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR IRQ_Interrupt         { VECTOR_NUM = 6; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+  INTERRUPT_VECTOR FIQ_Interrupt         { VECTOR_NUM = 7; VECTOR_KIND = HANDLER { NAME =  ""; }; };
+
+  INTERRUPT_SOURCE SGI_ID0                                      { SOURCE_NUM =   0; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID1                                      { SOURCE_NUM =   1; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID2                                      { SOURCE_NUM =   2; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID3                                      { SOURCE_NUM =   3; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID4                                      { SOURCE_NUM =   4; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID5                                      { SOURCE_NUM =   5; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID6                                      { SOURCE_NUM =   6; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID7                                      { SOURCE_NUM =   7; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID8                                      { SOURCE_NUM =   8; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID9                                      { SOURCE_NUM =   9; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID10                                     { SOURCE_NUM =  10; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID11                                     { SOURCE_NUM =  11; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID12                                     { SOURCE_NUM =  12; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID13                                     { SOURCE_NUM =  13; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID14                                     { SOURCE_NUM =  14; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SGI_ID15                                     { SOURCE_NUM =  15; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_16                                  { SOURCE_NUM =  16; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_17                                  { SOURCE_NUM =  17; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_18                                  { SOURCE_NUM =  18; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_19                                  { SOURCE_NUM =  19; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_20                                  { SOURCE_NUM =  20; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_21                                  { SOURCE_NUM =  21; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_22                                  { SOURCE_NUM =  22; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_23                                  { SOURCE_NUM =  23; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_24                                  { SOURCE_NUM =  24; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIRTUAL_MAINTENANCE_INTERRUPT                { SOURCE_NUM =  25; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_26                                  { SOURCE_NUM =  26; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CR7_GLOBAL_TIMER                             { SOURCE_NUM =  27; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CR7_LEGACY_FIQ_INPUT                         { SOURCE_NUM =  28; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CR7_PRIVATE_TIMER                            { SOURCE_NUM =  29; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CR7_WATCHDOG_TIMER                           { SOURCE_NUM =  30; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CR7_GIC_ID_IRQ                               { SOURCE_NUM =  31; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ0                                         { SOURCE_NUM =  32; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ1                                         { SOURCE_NUM =  33; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ2                                         { SOURCE_NUM =  34; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ3                                         { SOURCE_NUM =  35; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH0                                     { SOURCE_NUM =  36; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH1                                     { SOURCE_NUM =  37; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH2                                     { SOURCE_NUM =  38; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH3                                     { SOURCE_NUM =  39; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH4                                     { SOURCE_NUM =  40; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH5                                     { SOURCE_NUM =  41; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH6                                     { SOURCE_NUM =  42; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GPIO_CH7                                     { SOURCE_NUM =  43; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF00                                       { SOURCE_NUM =  44; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF01                                       { SOURCE_NUM =  45; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF10                                       { SOURCE_NUM =  46; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF11                                       { SOURCE_NUM =  47; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH4                                     { SOURCE_NUM =  48; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH5                                     { SOURCE_NUM =  49; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ4                                         { SOURCE_NUM =  50; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH4                                      { SOURCE_NUM =  51; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH5                                      { SOURCE_NUM =  52; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH6                                      { SOURCE_NUM =  53; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_54                                  { SOURCE_NUM =  54; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH3                                     { SOURCE_NUM =  55; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF20                                       { SOURCE_NUM =  56; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF21                                       { SOURCE_NUM =  57; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF30                                       { SOURCE_NUM =  58; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DRIF31                                       { SOURCE_NUM =  59; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DCU                                          { SOURCE_NUM =  60; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CAN_FD_CHANNEL                               { SOURCE_NUM =  61; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CAN_FD_GLOBAL                                { SOURCE_NUM =  62; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR10                                 { SOURCE_NUM =  63; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RFSO_CH0                                     { SOURCE_NUM =  64; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RFSO_CH1                                     { SOURCE_NUM =  65; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB_DMAC_CH2                                 { SOURCE_NUM =  66; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB_DMAC_CH3                                 { SOURCE_NUM =  67; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE EHCI_HOST3                                   { SOURCE_NUM =  68; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE EHCI_OHCI_OTG_CH3                            { SOURCE_NUM =  69; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RPC_IF                                       { SOURCE_NUM =  70; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH0                           { SOURCE_NUM =  71; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH1                           { SOURCE_NUM =  72; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH2                           { SOURCE_NUM =  73; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH3                           { SOURCE_NUM =  74; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH4                           { SOURCE_NUM =  75; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH5                           { SOURCE_NUM =  76; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH6                           { SOURCE_NUM =  77; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH7                           { SOURCE_NUM =  78; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH8                           { SOURCE_NUM =  79; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH9                           { SOURCE_NUM =  80; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH10                          { SOURCE_NUM =  81; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH11                          { SOURCE_NUM =  82; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH12                          { SOURCE_NUM =  83; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH13                          { SOURCE_NUM =  84; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH14                          { SOURCE_NUM =  85; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH15                          { SOURCE_NUM =  86; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH16                          { SOURCE_NUM =  87; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH17                          { SOURCE_NUM =  88; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH18                          { SOURCE_NUM =  89; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH19                          { SOURCE_NUM =  90; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH20                          { SOURCE_NUM =  91; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH21                          { SOURCE_NUM =  92; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH22                          { SOURCE_NUM =  93; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH23                          { SOURCE_NUM =  94; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ETHERNETAVB_IF_CH24                          { SOURCE_NUM =  95; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_96                                  { SOURCE_NUM =  96; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SECURE_ENGINE_PKA_SEC                        { SOURCE_NUM =  97; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SECURE_ENGINE_PKA_PUB                        { SOURCE_NUM =  98; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE THERMAL_SENSOR_CH0                           { SOURCE_NUM =  99; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE THERMAL_SENSOR_CH1                           { SOURCE_NUM = 100; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE THERMAL_SENSOR_CH2                           { SOURCE_NUM = 101; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SECURE_ENGINE_SEC                            { SOURCE_NUM = 102; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SECURE_ENGINE_PUB                            { SOURCE_NUM = 103; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE0_PMU                                { SOURCE_NUM = 104; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE1_PMU                                { SOURCE_NUM = 105; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE2_PMU                                { SOURCE_NUM = 106; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE3_PMU                                { SOURCE_NUM = 107; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE0_CTI                                { SOURCE_NUM = 108; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE1_CTI                                { SOURCE_NUM = 109; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE2_CTI                                { SOURCE_NUM = 110; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE3_CTI                                { SOURCE_NUM = 111; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE0_COMM                               { SOURCE_NUM = 112; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE1_COMM                               { SOURCE_NUM = 113; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE2_COMM                               { SOURCE_NUM = 114; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A57_CORE3_COMM                               { SOURCE_NUM = 115; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE0_PMU                                { SOURCE_NUM = 116; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE1_PMU                                { SOURCE_NUM = 117; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE2_PMU                                { SOURCE_NUM = 118; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE3_PMU                                { SOURCE_NUM = 119; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE0_CTI                                { SOURCE_NUM = 120; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE1_CTI                                { SOURCE_NUM = 121; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE2_CTI                                { SOURCE_NUM = 122; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE3_CTI                                { SOURCE_NUM = 123; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE0_COMM                               { SOURCE_NUM = 124; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE1_COMM                               { SOURCE_NUM = 125; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE2_COMM                               { SOURCE_NUM = 126; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE A53_CORE3_COMM                               { SOURCE_NUM = 127; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE LBSC                                         { SOURCE_NUM = 128; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DAVE_HD_PAUSE                                { SOURCE_NUM = 129; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DAVE_HD_SPECIAL                              { SOURCE_NUM = 130; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DAVE_HD_SYNC                                 { SOURCE_NUM = 131; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_132                                 { SOURCE_NUM = 132; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB3_0_HOST_CONTROLLER_CH0_BC                { SOURCE_NUM = 133; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB3_0_HOST_CONTROLLER_CH0_HOST              { SOURCE_NUM = 134; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB3_0_HOST_CONTROLLER_CH0_OTG               { SOURCE_NUM = 135; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB3_0_HOST_CONTROLLER_CH0_PERI              { SOURCE_NUM = 136; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SERIAL_ATA_GEN3                              { SOURCE_NUM = 137; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AP_SYSTEM_CORE_CCI                           { SOURCE_NUM = 138; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_139                                 { SOURCE_NUM = 139; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE EHCI_HOST0                                   { SOURCE_NUM = 140; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB_DMAC_CH0                                 { SOURCE_NUM = 141; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB_DMAC_CH1                                 { SOURCE_NUM = 142; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE USB_DDM                                      { SOURCE_NUM = 143; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE EHCI_HOST1                                   { SOURCE_NUM = 144; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE EHCI_HOST2                                   { SOURCE_NUM = 145; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_146                                 { SOURCE_NUM = 146; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_147                                 { SOURCE_NUM = 147; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH0                                     { SOURCE_NUM = 148; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH0_DMA                                 { SOURCE_NUM = 149; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH0_ER                                  { SOURCE_NUM = 150; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE GFX_3DGE                                     { SOURCE_NUM = 151; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH0                                     { SOURCE_NUM = 152; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH1                                     { SOURCE_NUM = 153; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH2                                     { SOURCE_NUM = 154; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH3                                     { SOURCE_NUM = 155; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH4                                     { SOURCE_NUM = 156; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH5                                     { SOURCE_NUM = 157; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH6                                     { SOURCE_NUM = 158; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT1_CH7                                     { SOURCE_NUM = 159; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI3                                    { SOURCE_NUM = 160; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI4                                    { SOURCE_NUM = 161; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI5                                    { SOURCE_NUM = 162; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI9                                    { SOURCE_NUM = 163; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MU_3_CH1                                     { SOURCE_NUM = 164; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI11                                   { SOURCE_NUM = 165; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYSTEM_TIME                                  { SOURCE_NUM = 166; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TPU                                          { SOURCE_NUM = 167; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI0                                    { SOURCE_NUM = 168; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI1                                    { SOURCE_NUM = 169; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI2                                    { SOURCE_NUM = 170; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYSTEM_UP_TIME_CLOCK                         { SOURCE_NUM = 171; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RCLK_WATCHDOG_TIMER                          { SOURCE_NUM = 172; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYSTEM_WATCHDOG_TIMER                        { SOURCE_NUM = 173; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT0_CH0                                     { SOURCE_NUM = 174; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT0_CH1                                     { SOURCE_NUM = 175; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HSCIF_CH2                                    { SOURCE_NUM = 176; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HSCIF_CH3                                    { SOURCE_NUM = 177; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HSCIF_CH4                                    { SOURCE_NUM = 178; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TICP15                                   { SOURCE_NUM = 179; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH1                                     { SOURCE_NUM = 180; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH1_DMA                                 { SOURCE_NUM = 181; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE PCIE_CH1_ER                                  { SOURCE_NUM = 182; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_183                                 { SOURCE_NUM = 183; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH0                                     { SOURCE_NUM = 184; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH1                                     { SOURCE_NUM = 185; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HSCIF_CH0                                    { SOURCE_NUM = 186; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HSCIF_CH1                                    { SOURCE_NUM = 187; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MSIOF_CH0                                    { SOURCE_NUM = 188; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MSIOF_CH1                                    { SOURCE_NUM = 189; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MSIOF_CH2                                    { SOURCE_NUM = 190; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MSIOF_CH3                                    { SOURCE_NUM = 191; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_192                                 { SOURCE_NUM = 192; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IRQ5                                         { SOURCE_NUM = 193; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI0_CH0                        { SOURCE_NUM = 194; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI0_CH1                        { SOURCE_NUM = 195; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCIF_CH2                                     { SOURCE_NUM = 196; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SDHI_CH0                                     { SOURCE_NUM = 197; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SDHI_CH1                                     { SOURCE_NUM = 198; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SDHI_CH2                                     { SOURCE_NUM = 199; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SDHI_CH3                                     { SOURCE_NUM = 200; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI0_CH2                        { SOURCE_NUM = 201; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI0_CH3                        { SOURCE_NUM = 202; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH7                                      { SOURCE_NUM = 203; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_204                                 { SOURCE_NUM = 204; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IIC_FOR_DVF                                  { SOURCE_NUM = 205; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH4                                      { SOURCE_NUM = 206; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH5                                      { SOURCE_NUM = 207; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH6                                      { SOURCE_NUM = 208; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_209                                 { SOURCE_NUM = 209; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_210                                 { SOURCE_NUM = 210; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_211                                 { SOURCE_NUM = 211; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_212                                 { SOURCE_NUM = 212; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_213                                 { SOURCE_NUM = 213; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_214                                 { SOURCE_NUM = 214; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_215                                 { SOURCE_NUM = 215; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CSI2_CH0                                     { SOURCE_NUM = 216; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RFSO_CH2_10                                  { SOURCE_NUM = 217; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CAN_CH0                                      { SOURCE_NUM = 218; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CAN_CH1                                      { SOURCE_NUM = 219; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH0                                      { SOURCE_NUM = 220; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH1                                      { SOURCE_NUM = 221; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH2                                      { SOURCE_NUM = 222; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VIN_CH3                                      { SOURCE_NUM = 223; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IMR_LX4_CH0                                  { SOURCE_NUM = 224; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IMR_LX4_CH1                                  { SOURCE_NUM = 225; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IMR_LX4_CH2                                  { SOURCE_NUM = 226; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IMR_LX4_CH3                                  { SOURCE_NUM = 227; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IPMMU                                        { SOURCE_NUM = 228; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IPMMU_SEC                                    { SOURCE_NUM = 229; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_230                                 { SOURCE_NUM = 230; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_ERR                                { SOURCE_NUM = 231; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH0                                { SOURCE_NUM = 232; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH1                                { SOURCE_NUM = 233; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH2                                { SOURCE_NUM = 234; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH3                                { SOURCE_NUM = 235; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH4                                { SOURCE_NUM = 236; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH5                                { SOURCE_NUM = 237; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH6                                { SOURCE_NUM = 238; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH7                                { SOURCE_NUM = 239; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH8                                { SOURCE_NUM = 240; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH9                                { SOURCE_NUM = 241; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH10                               { SOURCE_NUM = 242; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH11                               { SOURCE_NUM = 243; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH12                               { SOURCE_NUM = 244; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH13                               { SOURCE_NUM = 245; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH14                               { SOURCE_NUM = 246; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC0_CH15                               { SOURCE_NUM = 247; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH0                                { SOURCE_NUM = 248; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH1                                { SOURCE_NUM = 249; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH2                                { SOURCE_NUM = 250; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH3                                { SOURCE_NUM = 251; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_ERR                                { SOURCE_NUM = 252; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR11                                 { SOURCE_NUM = 253; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI1_CH0                        { SOURCE_NUM = 254; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IVDP1C_CMINT                                 { SOURCE_NUM = 255; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH0                              { SOURCE_NUM = 256; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH1                              { SOURCE_NUM = 257; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH2                              { SOURCE_NUM = 258; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH3                              { SOURCE_NUM = 259; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH4                              { SOURCE_NUM = 260; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH5                              { SOURCE_NUM = 261; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH6                              { SOURCE_NUM = 262; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ARIICR_CH7                              { SOURCE_NUM = 263; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI1_CH1                        { SOURCE_NUM = 264; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_265                                 { SOURCE_NUM = 265; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CPG_CH2                                      { SOURCE_NUM = 266; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_267                                 { SOURCE_NUM = 267; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SPEED_PULSE_I_F                              { SOURCE_NUM = 268; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ADSP                                         { SOURCE_NUM = 269; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_270                                 { SOURCE_NUM = 270; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_271                                 { SOURCE_NUM = 271; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VCP4_VDPB_VINT                               { SOURCE_NUM = 272; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VCP4_VDPB_CINT                               { SOURCE_NUM = 273; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DTCP_CH0                                     { SOURCE_NUM = 274; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DTCP_CH1                                     { SOURCE_NUM = 275; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CPG_CH0                                      { SOURCE_NUM = 276; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CPG_CH1                                      { SOURCE_NUM = 277; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CSI2_CH2                                     { SOURCE_NUM = 278; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CSI2_CH3                                     { SOURCE_NUM = 279; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_280                                 { SOURCE_NUM = 280; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_281                                 { SOURCE_NUM = 281; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_282                                 { SOURCE_NUM = 282; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_283                                 { SOURCE_NUM = 283; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_284                                 { SOURCE_NUM = 284; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_285                                 { SOURCE_NUM = 285; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_286                                 { SOURCE_NUM = 286; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_287                                 { SOURCE_NUM = 287; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DU_CH0                                       { SOURCE_NUM = 288; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI1_CH2                        { SOURCE_NUM = 289; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_290                                 { SOURCE_NUM = 290; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_291                                 { SOURCE_NUM = 291; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VCP4_VCPLF_VINT                              { SOURCE_NUM = 292; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VCP4_VCPLF_CINT                              { SOURCE_NUM = 293; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE FDP1_CH0                                     { SOURCE_NUM = 294; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE FDP1_CH1                                     { SOURCE_NUM = 295; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_296                                 { SOURCE_NUM = 296; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_DISCOM_CMPI1_CH3                        { SOURCE_NUM = 297; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPBD                                   { SOURCE_NUM = 298; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_299                                 { SOURCE_NUM = 299; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DU_CH1                                       { SOURCE_NUM = 300; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DU_CH2                                       { SOURCE_NUM = 301; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DU_CH3                                       { SOURCE_NUM = 302; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_303                                 { SOURCE_NUM = 303; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_304                                 { SOURCE_NUM = 304; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_M_CH0                                   { SOURCE_NUM = 305; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_M_CH1                                   { SOURCE_NUM = 306; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_M_CH2                                   { SOURCE_NUM = 307; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_M_CH3                                   { SOURCE_NUM = 308; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_M_CH4                                   { SOURCE_NUM = 309; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_S_CH0                                   { SOURCE_NUM = 310; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_S_CH1                                   { SOURCE_NUM = 311; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_S_CH2                                   { SOURCE_NUM = 312; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_S_CH3                                   { SOURCE_NUM = 313; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSP1_S_CH4                                   { SOURCE_NUM = 314; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TSIF_CH0                                     { SOURCE_NUM = 315; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TSIF_CH1                                     { SOURCE_NUM = 316; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_317                                 { SOURCE_NUM = 317; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH2                                      { SOURCE_NUM = 318; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH0                                      { SOURCE_NUM = 319; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH1                                      { SOURCE_NUM = 320; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_321                                 { SOURCE_NUM = 321; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE I2C_CH3                                      { SOURCE_NUM = 322; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_323                                 { SOURCE_NUM = 323; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_324                                 { SOURCE_NUM = 324; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_325                                 { SOURCE_NUM = 325; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_326                                 { SOURCE_NUM = 326; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR8                                  { SOURCE_NUM = 327; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SIM                                          { SOURCE_NUM = 328; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYSTEM_CONTROLLER                            { SOURCE_NUM = 329; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE FM_MULTIPLE_DEMODULATOR                      { SOURCE_NUM = 330; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_331                                 { SOURCE_NUM = 331; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR9                                  { SOURCE_NUM = 332; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_333                                 { SOURCE_NUM = 333; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_334                                 { SOURCE_NUM = 334; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI6                                    { SOURCE_NUM = 335; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI7                                    { SOURCE_NUM = 336; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI8                                    { SOURCE_NUM = 337; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TICP18                                   { SOURCE_NUM = 338; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR7                                  { SOURCE_NUM = 339; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH4                                { SOURCE_NUM = 340; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH5                                { SOURCE_NUM = 341; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH6                                { SOURCE_NUM = 342; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH7                                { SOURCE_NUM = 343; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH8                                { SOURCE_NUM = 344; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH9                                { SOURCE_NUM = 345; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH10                               { SOURCE_NUM = 346; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH11                               { SOURCE_NUM = 347; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH12                               { SOURCE_NUM = 348; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH13                               { SOURCE_NUM = 349; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH14                               { SOURCE_NUM = 350; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC1_CH15                               { SOURCE_NUM = 351; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH0                              { SOURCE_NUM = 352; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH1                              { SOURCE_NUM = 353; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH2                              { SOURCE_NUM = 354; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH3                              { SOURCE_NUM = 355; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH4                              { SOURCE_NUM = 356; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH5                              { SOURCE_NUM = 357; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH6                              { SOURCE_NUM = 358; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH7                              { SOURCE_NUM = 359; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH8                              { SOURCE_NUM = 360; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH9                              { SOURCE_NUM = 361; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH10                             { SOURCE_NUM = 362; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH11                             { SOURCE_NUM = 363; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH12                             { SOURCE_NUM = 364; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH13                             { SOURCE_NUM = 365; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH14                             { SOURCE_NUM = 366; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_CH15                             { SOURCE_NUM = 367; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH0                              { SOURCE_NUM = 368; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH1                              { SOURCE_NUM = 369; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH2                              { SOURCE_NUM = 370; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH3                              { SOURCE_NUM = 371; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH4                              { SOURCE_NUM = 372; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH5                              { SOURCE_NUM = 373; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH6                              { SOURCE_NUM = 374; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH7                              { SOURCE_NUM = 375; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH8                              { SOURCE_NUM = 376; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH9                              { SOURCE_NUM = 377; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH10                             { SOURCE_NUM = 378; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH11                             { SOURCE_NUM = 379; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH12                             { SOURCE_NUM = 380; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH13                             { SOURCE_NUM = 381; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC0_ERR                              { SOURCE_NUM = 382; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_ERR                              { SOURCE_NUM = 383; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH0                                      { SOURCE_NUM = 384; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH1                                      { SOURCE_NUM = 385; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH2                                      { SOURCE_NUM = 386; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH3                                      { SOURCE_NUM = 387; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH4                                      { SOURCE_NUM = 388; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH5                                      { SOURCE_NUM = 389; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH6                                      { SOURCE_NUM = 390; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH7                                      { SOURCE_NUM = 391; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH8                                      { SOURCE_NUM = 392; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SCU_CH9                                      { SOURCE_NUM = 393; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH0                                      { SOURCE_NUM = 394; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH1                                      { SOURCE_NUM = 395; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH2                                      { SOURCE_NUM = 396; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH3                                      { SOURCE_NUM = 397; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH4                                      { SOURCE_NUM = 398; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH5                                      { SOURCE_NUM = 399; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH6                                      { SOURCE_NUM = 400; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLM_CH7                                      { SOURCE_NUM = 401; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH0                                      { SOURCE_NUM = 402; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH1                                      { SOURCE_NUM = 403; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH2                                      { SOURCE_NUM = 404; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH3                                      { SOURCE_NUM = 405; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH4                                      { SOURCE_NUM = 406; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH5                                      { SOURCE_NUM = 407; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH6                                      { SOURCE_NUM = 408; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH7                                      { SOURCE_NUM = 409; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH8                                      { SOURCE_NUM = 410; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SSI_CH9                                      { SOURCE_NUM = 411; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IVDP1C_VINT                                  { SOURCE_NUM = 412; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE IVDP1C_CINT                                  { SOURCE_NUM = 413; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH14                             { SOURCE_NUM = 414; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE AUDIO_DMAC1_CH15                             { SOURCE_NUM = 415; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLBIF_MLB                                    { SOURCE_NUM = 416; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLBIF_AHB_CH0                                { SOURCE_NUM = 417; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLBIF_AHB_CH1                                { SOURCE_NUM = 418; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLBIF_RX_CH0                                 { SOURCE_NUM = 419; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MLBIF_RX_CH1                                 { SOURCE_NUM = 420; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI0_MASTER                                 { SOURCE_NUM = 421; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_422                                 { SOURCE_NUM = 422; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI0_ESM                                    { SOURCE_NUM = 423; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI0_RNG                                    { SOURCE_NUM = 424; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_425                                 { SOURCE_NUM = 425; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_426                                 { SOURCE_NUM = 426; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ARM_REALTIM_CORE_PMU                         { SOURCE_NUM = 427; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE ARM_REALTIM_CORE_CTI                         { SOURCE_NUM = 428; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH15                               { SOURCE_NUM = 429; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH0                                     { SOURCE_NUM = 430; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH1                                     { SOURCE_NUM = 431; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH2                                     { SOURCE_NUM = 432; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH3                                     { SOURCE_NUM = 433; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH4                                     { SOURCE_NUM = 434; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH5                                     { SOURCE_NUM = 435; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH6                                     { SOURCE_NUM = 436; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT2_CH7                                     { SOURCE_NUM = 437; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI12                                   { SOURCE_NUM = 438; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI13                                   { SOURCE_NUM = 439; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE TMU_TUNI14                                   { SOURCE_NUM = 440; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR0                                  { SOURCE_NUM = 441; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR1                                  { SOURCE_NUM = 442; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR2                                  { SOURCE_NUM = 443; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR3                                  { SOURCE_NUM = 444; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR4                                  { SOURCE_NUM = 445; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR5                                  { SOURCE_NUM = 446; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR6                                  { SOURCE_NUM = 447; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_ERR                                { SOURCE_NUM = 448; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH0                                { SOURCE_NUM = 449; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH1                                { SOURCE_NUM = 450; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH2                                { SOURCE_NUM = 451; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH3                                { SOURCE_NUM = 452; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH4                                { SOURCE_NUM = 453; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH5                                { SOURCE_NUM = 454; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH6                                { SOURCE_NUM = 455; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH7                                { SOURCE_NUM = 456; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH8                                { SOURCE_NUM = 457; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH9                                { SOURCE_NUM = 458; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH10                               { SOURCE_NUM = 459; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH11                               { SOURCE_NUM = 460; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH12                               { SOURCE_NUM = 461; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH13                               { SOURCE_NUM = 462; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE SYS_DMAC2_CH14                               { SOURCE_NUM = 463; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DOC0_DOC                                     { SOURCE_NUM = 464; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DOC0_ACT                                     { SOURCE_NUM = 465; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DOC1_DOC                                     { SOURCE_NUM = 466; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE DOC1_ACT                                     { SOURCE_NUM = 467; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI1_MASTER                                 { SOURCE_NUM = 468; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_469                                 { SOURCE_NUM = 469; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI1_ESM                                    { SOURCE_NUM = 470; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_471                                 { SOURCE_NUM = 471; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_472                                 { SOURCE_NUM = 472; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_473                                 { SOURCE_NUM = 473; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_474                                 { SOURCE_NUM = 474; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_475                                 { SOURCE_NUM = 475; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPI_CH0                                { SOURCE_NUM = 476; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPI_CH1                                { SOURCE_NUM = 477; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE MFIS_ERROR12                                 { SOURCE_NUM = 478; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE HDMI1_RNG                                    { SOURCE_NUM = 479; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_ERR                                 { SOURCE_NUM = 480; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH0                                 { SOURCE_NUM = 481; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH1                                 { SOURCE_NUM = 482; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH2                                 { SOURCE_NUM = 483; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH3                                 { SOURCE_NUM = 484; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH4                                 { SOURCE_NUM = 485; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH5                                 { SOURCE_NUM = 486; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH6                                 { SOURCE_NUM = 487; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC0_CH7                                 { SOURCE_NUM = 488; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH0                                 { SOURCE_NUM = 489; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH1                                 { SOURCE_NUM = 490; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH2                                 { SOURCE_NUM = 491; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH3                                 { SOURCE_NUM = 492; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH4                                 { SOURCE_NUM = 493; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH5                                 { SOURCE_NUM = 494; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH6                                 { SOURCE_NUM = 495; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_CH7                                 { SOURCE_NUM = 496; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPBC                                   { SOURCE_NUM = 497; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPD_CH0                                { SOURCE_NUM = 498; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPD_CH1                                { SOURCE_NUM = 499; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE VSP2_VSPD_CH2                                { SOURCE_NUM = 500; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RT_DMAC1_ERR_ERR                             { SOURCE_NUM = 501; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH0                                     { SOURCE_NUM = 502; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH1                                     { SOURCE_NUM = 503; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH2                                     { SOURCE_NUM = 504; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH3                                     { SOURCE_NUM = 505; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH4                                     { SOURCE_NUM = 506; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH5                                     { SOURCE_NUM = 507; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH6                                     { SOURCE_NUM = 508; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE CMT3_CH7                                     { SOURCE_NUM = 509; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_510                                 { SOURCE_NUM = 510; VECTOR = IRQ_Interrupt; };
+  INTERRUPT_SOURCE RESERVED_511                                  { SOURCE_NUM = 511; VECTOR = IRQ_Interrupt; };
+
+  PLATFORM_FILES rcar {
+    PATH = "cortex-r/armv7/RCar/common";
+    CFILE = "boot.S";
+    CFILE = "system_rcar_gen3.c";
+    CFILE = "interrupts.c";
+    CFILE = "tick_config.c";
+    CFILE = "serial.c";
+    CFILE = "scif.S";
+    CFILE = "r_os_cache.c";
+  };
+
+  PLATFORM_FILES cmsis {
+    PATH = "cortex-r/armv7/RCar/CMSIS";
+    CFILE = "irq_ctrl_gic.c";
+  };
+
+/*  INTERRUPT it_timer1 {
+    ID = 0;
+  };
+
+  POSTBUILD all {
+    COMMAND buildhex {
+      TYPE = COPIER;
+      INPUT = ORIGINAL_TARGET;
+      OUTPUT = ".hex";
+      PREOPTION = "-O ihex";
+    };
+    COMMAND buildbin {
+      TYPE = COPIER;
+      INPUT = ORIGINAL_TARGET;
+      OUTPUT = ".bin";
+      PREOPTION = "-O binary";
+    };
+  };
+  POSTCOMMAND img {
+    COMMAND makekernel {
+      MESSAGE = "make kernel";
+      COMMAND = "cp";
+      INPUT = TARGET { EXT = ".bin"; };
+      PREOPTION = "";
+      POSTOPTION = "kernel7.img";
+    };
+  };
+*/
+};
+
diff --git a/goil/templates/config/cortex-r/armv7/RCar/interruptSources.oil b/goil/templates/config/cortex-r/armv7/RCar/interruptSources.oil
new file mode 100755
index 00000000..3770a8c4
--- /dev/null
+++ b/goil/templates/config/cortex-r/armv7/RCar/interruptSources.oil
@@ -0,0 +1,517 @@
+/*
+ * Interrupt sources for the RCar Gen3 SoC H3 superset (does not cover V3x)
+ */
+ENUM [
+    SGI_ID0,
+    SGI_ID1,
+    SGI_ID2,
+    SGI_ID3,
+    SGI_ID4,
+    SGI_ID5,
+    SGI_ID6,
+    SGI_ID7,
+    SGI_ID8,
+    SGI_ID9,
+    SGI_ID10,
+    SGI_ID11,
+    SGI_ID12,
+    SGI_ID13,
+    SGI_ID14,
+    SGI_ID15,
+    RESERVED_16,
+    RESERVED_17,
+    RESERVED_18,
+    RESERVED_19,
+    RESERVED_20,
+    RESERVED_21,
+    RESERVED_22,
+    RESERVED_23,
+    RESERVED_24,
+    VIRTUAL_MAINTENANCE_INTERRUPT,
+    RESERVED_26,
+    CR7_GLOBAL_TIMER,
+    CR7_LEGACY_FIQ_INPUT,
+    CR7_PRIVATE_TIMER,
+    CR7_WATCHDOG_TIMER,
+    CR7_GIC_ID_IRQ,
+    IRQ0,
+    IRQ1,
+    IRQ2,
+    IRQ3,
+    GPIO_CH0 {#include <pins.oil> },
+    GPIO_CH1 {#include <pins.oil> },
+    GPIO_CH2 {#include <pins.oil> },
+    GPIO_CH3 {#include <pins.oil> },
+    GPIO_CH4 {#include <pins.oil> },
+    GPIO_CH5 {#include <pins.oil> },
+    GPIO_CH6 {#include <pins.oil> },
+    GPIO_CH7 {#include <pins.oil> },
+    DRIF00,
+    DRIF01,
+    DRIF10,
+    DRIF11,
+    SCIF_CH4,
+    SCIF_CH5,
+    IRQ4,
+    I2C_CH4,
+    I2C_CH5,
+    I2C_CH6,
+    RESERVED_54,
+    SCIF_CH3,
+    DRIF20,
+    DRIF21,
+    DRIF30,
+    DRIF31,
+    DCU,
+    CAN_FD_CHANNEL,
+    CAN_FD_GLOBAL,
+    MFIS_ERROR10,
+    RFSO_CH0,
+    RFSO_CH1,
+    USB_DMAC_CH2,
+    USB_DMAC_CH3,
+    EHCI_HOST3,
+    EHCI_OHCI_OTG_CH3,
+    RPC_IF,
+    ETHERNETAVB_IF_CH0,
+    ETHERNETAVB_IF_CH1,
+    ETHERNETAVB_IF_CH2,
+    ETHERNETAVB_IF_CH3,
+    ETHERNETAVB_IF_CH4,
+    ETHERNETAVB_IF_CH5,
+    ETHERNETAVB_IF_CH6,
+    ETHERNETAVB_IF_CH7,
+    ETHERNETAVB_IF_CH8,
+    ETHERNETAVB_IF_CH9,
+    ETHERNETAVB_IF_CH10,
+    ETHERNETAVB_IF_CH11,
+    ETHERNETAVB_IF_CH12,
+    ETHERNETAVB_IF_CH13,
+    ETHERNETAVB_IF_CH14,
+    ETHERNETAVB_IF_CH15,
+    ETHERNETAVB_IF_CH16,
+    ETHERNETAVB_IF_CH17,
+    ETHERNETAVB_IF_CH18,
+    ETHERNETAVB_IF_CH19,
+    ETHERNETAVB_IF_CH20,
+    ETHERNETAVB_IF_CH21,
+    ETHERNETAVB_IF_CH22,
+    ETHERNETAVB_IF_CH23,
+    ETHERNETAVB_IF_CH24,
+    RESERVED_96,
+    SECURE_ENGINE_PKA_SEC,
+    SECURE_ENGINE_PKA_PUB,
+    THERMAL_SENSOR_CH0,
+    THERMAL_SENSOR_CH1,
+    THERMAL_SENSOR_CH2,
+    SECURE_ENGINE_SEC,
+    SECURE_ENGINE_PUB,
+    A57_CORE0_PMU,
+    A57_CORE1_PMU,
+    A57_CORE2_PMU,
+    A57_CORE3_PMU,
+    A57_CORE0_CTI,
+    A57_CORE1_CTI,
+    A57_CORE2_CTI,
+    A57_CORE3_CTI,
+    A57_CORE0_COMM,
+    A57_CORE1_COMM,
+    A57_CORE2_COMM,
+    A57_CORE3_COMM,
+    A53_CORE0_PMU,
+    A53_CORE1_PMU,
+    A53_CORE2_PMU,
+    A53_CORE3_PMU,
+    A53_CORE0_CTI,
+    A53_CORE1_CTI,
+    A53_CORE2_CTI,
+    A53_CORE3_CTI,
+    A53_CORE0_COMM,
+    A53_CORE1_COMM,
+    A53_CORE2_COMM,
+    A53_CORE3_COMM,
+    LBSC,
+    DAVE_HD_PAUSE,
+    DAVE_HD_SPECIAL,
+    DAVE_HD_SYNC,
+    RESERVED_132,
+    USB3_0_HOST_CONTROLLER_CH0_BC,
+    USB3_0_HOST_CONTROLLER_CH0_HOST,
+    USB3_0_HOST_CONTROLLER_CH0_OTG,
+    USB3_0_HOST_CONTROLLER_CH0_PERI,
+    SERIAL_ATA_GEN3,
+    AP_SYSTEM_CORE_CCI,
+    RESERVED_139,
+    EHCI_HOST0,
+    USB_DMAC_CH0,
+    USB_DMAC_CH1,
+    USB_DDM,
+    EHCI_HOST1,
+    EHCI_HOST2,
+    RESERVED_146,
+    RESERVED_147,
+    PCIE_CH0,
+    PCIE_CH0_DMA,
+    PCIE_CH0_ER,
+    GFX_3DGE,
+    CMT1_CH0,
+    CMT1_CH1,
+    CMT1_CH2,
+    CMT1_CH3,
+    CMT1_CH4,
+    CMT1_CH5,
+    CMT1_CH6,
+    CMT1_CH7,
+    TMU_TUNI3,
+    TMU_TUNI4,
+    TMU_TUNI5,
+    TMU_TUNI9,
+    MU_3_CH1,
+    TMU_TUNI11,
+    SYSTEM_TIME,
+    TPU,
+    TMU_TUNI0,
+    TMU_TUNI1,
+    TMU_TUNI2,
+    SYSTEM_UP_TIME_CLOCK,
+    RCLK_WATCHDOG_TIMER,
+    SYSTEM_WATCHDOG_TIMER,
+    CMT0_CH0,
+    CMT0_CH1,
+    HSCIF_CH2,
+    HSCIF_CH3,
+    HSCIF_CH4,
+    TMU_TICP15,
+    PCIE_CH1,
+    PCIE_CH1_DMA,
+    PCIE_CH1_ER,
+    RESERVED_183,
+    SCIF_CH0,
+    SCIF_CH1,
+    HSCIF_CH0,
+    HSCIF_CH1,
+    MSIOF_CH0,
+    MSIOF_CH1,
+    MSIOF_CH2,
+    MSIOF_CH3,
+    RESERVED_192,
+    IRQ5,
+    VSP2_DISCOM_CMPI0_CH0,
+    VSP2_DISCOM_CMPI0_CH1,
+    SCIF_CH2,
+    SDHI_CH0,
+    SDHI_CH1,
+    SDHI_CH2,
+    SDHI_CH3,
+    VSP2_DISCOM_CMPI0_CH2,
+    VSP2_DISCOM_CMPI0_CH3,
+    VIN_CH7,
+    RESERVED_204,
+    IIC_FOR_DVF,
+    VIN_CH4,
+    VIN_CH5,
+    VIN_CH6,
+    RESERVED_209,
+    RESERVED_210,
+    RESERVED_211,
+    RESERVED_212,
+    RESERVED_213,
+    RESERVED_214,
+    RESERVED_215,
+    CSI2_CH0,
+    RFSO_CH2_10,
+    CAN_CH0,
+    CAN_CH1,
+    VIN_CH0,
+    VIN_CH1,
+    VIN_CH2,
+    VIN_CH3,
+    IMR_LX4_CH0,
+    IMR_LX4_CH1,
+    IMR_LX4_CH2,
+    IMR_LX4_CH3,
+    IPMMU,
+    IPMMU_SEC,
+    RESERVED_230,
+    SYS_DMAC0_ERR,
+    SYS_DMAC0_CH0,
+    SYS_DMAC0_CH1,
+    SYS_DMAC0_CH2,
+    SYS_DMAC0_CH3,
+    SYS_DMAC0_CH4,
+    SYS_DMAC0_CH5,
+    SYS_DMAC0_CH6,
+    SYS_DMAC0_CH7,
+    SYS_DMAC0_CH8,
+    SYS_DMAC0_CH9,
+    SYS_DMAC0_CH10,
+    SYS_DMAC0_CH11,
+    SYS_DMAC0_CH12,
+    SYS_DMAC0_CH13,
+    SYS_DMAC0_CH14,
+    SYS_DMAC0_CH15,
+    SYS_DMAC1_CH0,
+    SYS_DMAC1_CH1,
+    SYS_DMAC1_CH2,
+    SYS_DMAC1_CH3,
+    SYS_DMAC1_ERR,
+    MFIS_ERROR11,
+    VSP2_DISCOM_CMPI1_CH0,
+    IVDP1C_CMINT,
+    MFIS_ARIICR_CH0,
+    MFIS_ARIICR_CH1,
+    MFIS_ARIICR_CH2,
+    MFIS_ARIICR_CH3,
+    MFIS_ARIICR_CH4,
+    MFIS_ARIICR_CH5,
+    MFIS_ARIICR_CH6,
+    MFIS_ARIICR_CH7,
+    VSP2_DISCOM_CMPI1_CH1,
+    RESERVED_265,
+    CPG_CH2,
+    RESERVED_267,
+    SPEED_PULSE_I_F,
+    ADSP,
+    RESERVED_270,
+    RESERVED_271,
+    VCP4_VDPB_VINT,
+    VCP4_VDPB_CINT,
+    DTCP_CH0,
+    DTCP_CH1,
+    CPG_CH0,
+    CPG_CH1,
+    CSI2_CH2,
+    CSI2_CH3,
+    RESERVED_280,
+    RESERVED_281,
+    RESERVED_282,
+    RESERVED_283,
+    RESERVED_284,
+    RESERVED_285,
+    RESERVED_286,
+    RESERVED_287,
+    DU_CH0,
+    VSP2_DISCOM_CMPI1_CH2,
+    RESERVED_290,
+    RESERVED_291,
+    VCP4_VCPLF_VINT,
+    VCP4_VCPLF_CINT,
+    FDP1_CH0,
+    FDP1_CH1,
+    RESERVED_296,
+    VSP2_DISCOM_CMPI1_CH3,
+    VSP2_VSPBD,
+    RESERVED_299,
+    DU_CH1,
+    DU_CH2,
+    DU_CH3,
+    RESERVED_303,
+    RESERVED_304,
+    SSP1_M_CH0,
+    SSP1_M_CH1,
+    SSP1_M_CH2,
+    SSP1_M_CH3,
+    SSP1_M_CH4,
+    SSP1_S_CH0,
+    SSP1_S_CH1,
+    SSP1_S_CH2,
+    SSP1_S_CH3,
+    SSP1_S_CH4,
+    TSIF_CH0,
+    TSIF_CH1,
+    RESERVED_317,
+    I2C_CH2,
+    I2C_CH0,
+    I2C_CH1,
+    RESERVED_321,
+    I2C_CH3,
+    RESERVED_323,
+    RESERVED_324,
+    RESERVED_325,
+    RESERVED_326,
+    MFIS_ERROR8,
+    SIM,
+    SYSTEM_CONTROLLER,
+    FM_MULTIPLE_DEMODULATOR,
+    RESERVED_331,
+    MFIS_ERROR9,
+    RESERVED_333,
+    RESERVED_334,
+    TMU_TUNI6,
+    TMU_TUNI7,
+    TMU_TUNI8,
+    TMU_TICP18,
+    MFIS_ERROR7,
+    SYS_DMAC1_CH4,
+    SYS_DMAC1_CH5,
+    SYS_DMAC1_CH6,
+    SYS_DMAC1_CH7,
+    SYS_DMAC1_CH8,
+    SYS_DMAC1_CH9,
+    SYS_DMAC1_CH10,
+    SYS_DMAC1_CH11,
+    SYS_DMAC1_CH12,
+    SYS_DMAC1_CH13,
+    SYS_DMAC1_CH14,
+    SYS_DMAC1_CH15,
+    AUDIO_DMAC0_CH0,
+    AUDIO_DMAC0_CH1,
+    AUDIO_DMAC0_CH2,
+    AUDIO_DMAC0_CH3,
+    AUDIO_DMAC0_CH4,
+    AUDIO_DMAC0_CH5,
+    AUDIO_DMAC0_CH6,
+    AUDIO_DMAC0_CH7,
+    AUDIO_DMAC0_CH8,
+    AUDIO_DMAC0_CH9,
+    AUDIO_DMAC0_CH10,
+    AUDIO_DMAC0_CH11,
+    AUDIO_DMAC0_CH12,
+    AUDIO_DMAC0_CH13,
+    AUDIO_DMAC0_CH14,
+    AUDIO_DMAC0_CH15,
+    AUDIO_DMAC1_CH0,
+    AUDIO_DMAC1_CH1,
+    AUDIO_DMAC1_CH2,
+    AUDIO_DMAC1_CH3,
+    AUDIO_DMAC1_CH4,
+    AUDIO_DMAC1_CH5,
+    AUDIO_DMAC1_CH6,
+    AUDIO_DMAC1_CH7,
+    AUDIO_DMAC1_CH8,
+    AUDIO_DMAC1_CH9,
+    AUDIO_DMAC1_CH10,
+    AUDIO_DMAC1_CH11,
+    AUDIO_DMAC1_CH12,
+    AUDIO_DMAC1_CH13,
+    AUDIO_DMAC0_ERR,
+    AUDIO_DMAC1_ERR,
+    SCU_CH0,
+    SCU_CH1,
+    SCU_CH2,
+    SCU_CH3,
+    SCU_CH4,
+    SCU_CH5,
+    SCU_CH6,
+    SCU_CH7,
+    SCU_CH8,
+    SCU_CH9,
+    MLM_CH0,
+    MLM_CH1,
+    MLM_CH2,
+    MLM_CH3,
+    MLM_CH4,
+    MLM_CH5,
+    MLM_CH6,
+    MLM_CH7,
+    SSI_CH0,
+    SSI_CH1,
+    SSI_CH2,
+    SSI_CH3,
+    SSI_CH4,
+    SSI_CH5,
+    SSI_CH6,
+    SSI_CH7,
+    SSI_CH8,
+    SSI_CH9,
+    IVDP1C_VINT,
+    IVDP1C_CINT,
+    AUDIO_DMAC1_CH14,
+    AUDIO_DMAC1_CH15,
+    MLBIF_MLB,
+    MLBIF_AHB_CH0,
+    MLBIF_AHB_CH1,
+    MLBIF_RX_CH0,
+    MLBIF_RX_CH1,
+    HDMI0_MASTER,
+    RESERVED_422,
+    HDMI0_ESM,
+    HDMI0_RNG,
+    RESERVED_425,
+    RESERVED_426,
+    ARM_REALTIM_CORE_PMU,
+    ARM_REALTIM_CORE_CTI,
+    SYS_DMAC2_CH15,
+    CMT2_CH0,
+    CMT2_CH1,
+    CMT2_CH2,
+    CMT2_CH3,
+    CMT2_CH4,
+    CMT2_CH5,
+    CMT2_CH6,
+    CMT2_CH7,
+    TMU_TUNI12,
+    TMU_TUNI13,
+    TMU_TUNI14,
+    MFIS_ERROR0,
+    MFIS_ERROR1,
+    MFIS_ERROR2,
+    MFIS_ERROR3,
+    MFIS_ERROR4,
+    MFIS_ERROR5,
+    MFIS_ERROR6,
+    SYS_DMAC2_ERR,
+    SYS_DMAC2_CH0,
+    SYS_DMAC2_CH1,
+    SYS_DMAC2_CH2,
+    SYS_DMAC2_CH3,
+    SYS_DMAC2_CH4,
+    SYS_DMAC2_CH5,
+    SYS_DMAC2_CH6,
+    SYS_DMAC2_CH7,
+    SYS_DMAC2_CH8,
+    SYS_DMAC2_CH9,
+    SYS_DMAC2_CH10,
+    SYS_DMAC2_CH11,
+    SYS_DMAC2_CH12,
+    SYS_DMAC2_CH13,
+    SYS_DMAC2_CH14,
+    DOC0_DOC,
+    DOC0_ACT,
+    DOC1_DOC,
+    DOC1_ACT,
+    HDMI1_MASTER,
+    RESERVED_469,
+    HDMI1_ESM,
+    RESERVED_471,
+    RESERVED_472,
+    RESERVED_473,
+    RESERVED_474,
+    RESERVED_475,
+    VSP2_VSPI_CH0,
+    VSP2_VSPI_CH1,
+    MFIS_ERROR12,
+    HDMI1_RNG,
+    RT_DMAC0_ERR,
+    RT_DMAC0_CH0,
+    RT_DMAC0_CH1,
+    RT_DMAC0_CH2,
+    RT_DMAC0_CH3,
+    RT_DMAC0_CH4,
+    RT_DMAC0_CH5,
+    RT_DMAC0_CH6,
+    RT_DMAC0_CH7,
+    RT_DMAC1_CH0,
+    RT_DMAC1_CH1,
+    RT_DMAC1_CH2,
+    RT_DMAC1_CH3,
+    RT_DMAC1_CH4,
+    RT_DMAC1_CH5,
+    RT_DMAC1_CH6,
+    RT_DMAC1_CH7,
+    VSP2_VSPBC,
+    VSP2_VSPD_CH0,
+    VSP2_VSPD_CH1,
+    VSP2_VSPD_CH2,
+    RT_DMAC1_ERR_ERR,
+    CMT3_CH0,
+    CMT3_CH1,
+    CMT3_CH2,
+    CMT3_CH3,
+    CMT3_CH4,
+    CMT3_CH5,
+    CMT3_CH6,
+    CMT3_CH7,
+    RESERVED_510,
+    RESERVED_511
+] SOURCE;
diff --git a/goil/templates/config/cortex-r/armv7/RCar/pins.oil b/goil/templates/config/cortex-r/armv7/RCar/pins.oil
new file mode 100755
index 00000000..62b9d762
--- /dev/null
+++ b/goil/templates/config/cortex-r/armv7/RCar/pins.oil
@@ -0,0 +1,34 @@
+ENUM [
+  PIN0 { #include <sensibility.oil> },
+  PIN1 { #include <sensibility.oil> },
+  PIN2 { #include <sensibility.oil> },
+  PIN3 { #include <sensibility.oil> },
+  PIN4 { #include <sensibility.oil> },
+  PIN5 { #include <sensibility.oil> },
+  PIN6 { #include <sensibility.oil> },
+  PIN7 { #include <sensibility.oil> },
+  PIN8 { #include <sensibility.oil> },
+  PIN9 { #include <sensibility.oil> },
+  PIN10 { #include <sensibility.oil> },
+  PIN11 { #include <sensibility.oil> },
+  PIN12 { #include <sensibility.oil> },
+  PIN13 { #include <sensibility.oil> },
+  PIN14 { #include <sensibility.oil> },
+  PIN15 { #include <sensibility.oil> },
+  PIN16 { #include <sensibility.oil> },
+  PIN17 { #include <sensibility.oil> },
+  PIN18 { #include <sensibility.oil> },
+  PIN19 { #include <sensibility.oil> },
+  PIN20 { #include <sensibility.oil> },
+  PIN21 { #include <sensibility.oil> },
+  PIN22 { #include <sensibility.oil> },
+  PIN23 { #include <sensibility.oil> },
+  PIN24 { #include <sensibility.oil> },
+  PIN25 { #include <sensibility.oil> },
+  PIN26 { #include <sensibility.oil> },
+  PIN27 { #include <sensibility.oil> },
+  PIN28 { #include <sensibility.oil> },
+  PIN29 { #include <sensibility.oil> },
+  PIN30 { #include <sensibility.oil> },
+  PIN31 { #include <sensibility.oil> }
+] PIN[];
diff --git a/goil/templates/config/cortex-r/armv7/RCar/sensibility.oil b/goil/templates/config/cortex-r/armv7/RCar/sensibility.oil
new file mode 100755
index 00000000..78c28418
--- /dev/null
+++ b/goil/templates/config/cortex-r/armv7/RCar/sensibility.oil
@@ -0,0 +1,2 @@
+ENUM [ RISING, FALLING, BOTH ] TRIGGER = RISING;
+ENUM [ UP, DOWN, NONE ] PULL = NONE;
diff --git a/goil/templates/config/cortex-r/armv7/buildOptions.oil b/goil/templates/config/cortex-r/armv7/buildOptions.oil
new file mode 100755
index 00000000..3fc79c8d
--- /dev/null
+++ b/goil/templates/config/cortex-r/armv7/buildOptions.oil
@@ -0,0 +1,43 @@
+/*
+ * ARMv7 build options for gcc
+ */
+CPU buildOptions {
+  BUILDOPTIONS defaultBuildOptionsForCR7 {
+    /*
+     * Common flags for C and C++ compiling
+     * -Wall -O2 -nostdlib -nostartfiles -ffreestanding
+     */
+    COMMONFLAGS = "-g";                           // Produce debugging information
+    COMMONFLAGS = "-Wall";                        // All warnings on
+    COMMONFLAGS = "-pedantic";
+    COMMONFLAGS = "-Wformat";
+    COMMONFLAGS = "-std=gnu99";
+    COMMONFLAGS = "-ffreestanding";
+    COMMONFLAGS = "-mcpu=cortex-r7";              // Compile for arm7tdmi
+    COMMONFLAGS = "-Wmissing-field-initializers"; // Struct initialized with incorrect number of fiels
+    COMMONFLAGS = "-mfloat-abi=soft";             // Floating point numbers are computed in software
+
+    /*
+     * C++ compiler flags
+     */
+    CPPFLAGS = "-fno-rtti";                       // No information for runtime (run time type information) - reduce exe size
+    CPPFLAGS = "-felide-constructors";            // Optimization to omit creating temporary object when used to initialize another object
+    CPPFLAGS = "-fno-threadsafe-statics";         // No thread safe init of local static variables - reduce code size
+    CPPFLAGS = "-fno-use-cxa-get-exception-ptr";  // Don't use the __cxa_get_exception_ptr runtime routine (no exception anyway)
+    CPPFLAGS = "-fno-enforce-eh-specs";           // Don't generate code to check for violation of exception specifications at runtime (no exception anyway)
+
+    /*
+     * Assembler flags
+     */
+    ASFLAGS = "-g";                               // Produce debugging information
+    ASFLAGS = "-mcpu=cortex-r7";                 // Assemble for arm7tdmi
+    ASFLAGS = "--fatal-warnings";                 // A warning is an error
+    ASFLAGS = "-mfloat-abi=soft";                 // Floating point numbers are computed in software gcc-options-to-the-arm-mcu-fpu-datasheet
+
+    LDFLAGS = "-g";
+    LDFLAGS = "-Wl,--fatal-warnings";                 // A warning is an error
+    LDFLAGS = "-Wl,--warn-common";                    // Warn when a common symbol is combined with another common symbol
+    LDFLAGS = "-Wl,--no-undefined";                   // Report unresolved symbol references
+/*    LDFLAGS = "--gc-sections";                    // Remove unused sections. Works with -ffunction-sections and -fdata-sections, see above*/
+  };
+};
diff --git a/goil/templates/config/cortex-r/config.oil b/goil/templates/config/cortex-r/config.oil
new file mode 100755
index 00000000..33cb576f
--- /dev/null
+++ b/goil/templates/config/cortex-r/config.oil
@@ -0,0 +1,43 @@
+/*
+ * This configuration file adds a SOURCE attribute to ISR and COUNTER
+ * It also define a new object type: INTERRUPT
+ */
+IMPLEMENTATION arm_interrupt {
+  INTERRUPT_VECTOR [] {
+    UINT32 VECTOR_NUM;
+    BOOLEAN EXCEPTION = FALSE;
+    ENUM [
+      HANDLER { STRING NAME; },
+      REFERENCE { STRING NAME; }
+    ] VECTOR_KIND;
+  };
+  INTERRUPT_SOURCE [] {
+    UINT32 SOURCE_NUM;
+    INTERRUPT_VECTOR_TYPE VECTOR;
+    BOOLEAN ACK = TRUE;
+  };
+  ISR [] {
+    #include <interruptSources.oil>
+  };
+  COUNTER [] {
+    #include <interruptSources.oil>
+  };
+  INTERRUPT_COUNT {
+    UINT32 IT_TABLE_SIZE;
+  };
+};
+
+CPU arm_interrupt {
+  COUNTER SystemCounter {
+    SOURCE = CR7_PRIVATE_TIMER;
+  };
+
+  PLATFORM_FILES cortex_r_armv7 {
+    PATH = "cortex-r/armv7";
+    CFILE = "tpl_irq.S";
+    CFILE = "tpl_system_call.S";
+    CFILE = "tpl_stacks.S";
+    CFILE = "tpl_vector_table.s";
+    CFILE = "tpl_machine_arm.c";
+  };
+};
diff --git a/goil/templates/linker/gnu_ld/cortex-r/armv7/RCar/script.goilTemplate b/goil/templates/linker/gnu_ld/cortex-r/armv7/RCar/script.goilTemplate
new file mode 100755
index 00000000..7b537d6a
--- /dev/null
+++ b/goil/templates/linker/gnu_ld/cortex-r/armv7/RCar/script.goilTemplate
@@ -0,0 +1,298 @@
+_STACK_SIZE       = 0x100000;
+_IRQ_STACK_SIZE   = 0x4000;
+_FIQ_STACK_SIZE   = 0x4000;
+_SVC_STACK_SIZE   = 0x4000;
+_ABORT_STACK_SIZE = 0x4000;
+_UNDEF_STACK_SIZE = 0x4000;
+_HEAP_SIZE        = 0x400000;
+/* Heap uses HeapBase global var, see FreeRTOS configTOTAL_HEAP_SIZE */
+
+ENTRY(_Reset)
+
+SECTIONS
+{
+  PROVIDE (__executable_start = SEGMENT_START("text-segment", 0x70000000));
+
+  . = SEGMENT_START("text-segment", 0x70000000);
+  .text : { *(.isr_vector) }
+
+  . = 0x70400000;
+  . = ALIGN(4096);
+  .resource_table : { *(.resource_table) }
+
+  /* Read-only sections, merged into text segment: */
+  /* PROVIDE (__executable_start = SEGMENT_START("text-segment", 0x70000000)); . = SEGMENT_START("text-segment", 0x70000000); */
+    . = SEGMENT_START("text-segment", 0x70500000);
+  app_ram_start = .;
+  .interp         : { *(.interp) }
+  .note.gnu.build-id : { *(.note.gnu.build-id) }
+  .hash           : { *(.hash) }
+  .gnu.hash       : { *(.gnu.hash) }
+  .dynsym         : { *(.dynsym) }
+  .dynstr         : { *(.dynstr) }
+  .gnu.version    : { *(.gnu.version) }
+  .gnu.version_d  : { *(.gnu.version_d) }
+  .gnu.version_r  : { *(.gnu.version_r) }
+  .rela.init      : { *(.rela.init) }
+  .rela.text      : { *(.rela.text .rela.text.* .rela.gnu.linkonce.t.*) }
+  .rela.fini      : { *(.rela.fini) }
+  .rela.rodata    : { *(.rela.rodata .rela.rodata.* .rela.gnu.linkonce.r.*) }
+  .rela.data.rel.ro   : { *(.rela.data.rel.ro .rela.data.rel.ro.* .rela.gnu.linkonce.d.rel.ro.*) }
+  .rela.data      : { *(.rela.data .rela.data.* .rela.gnu.linkonce.d.*) }
+  .rela.tdata	  : { *(.rela.tdata .rela.tdata.* .rela.gnu.linkonce.td.*) }
+  .rela.tbss	  : { *(.rela.tbss .rela.tbss.* .rela.gnu.linkonce.tb.*) }
+  .rela.ctors     : { *(.rela.ctors) }
+  .rela.dtors     : { *(.rela.dtors) }
+  .rela.got       : { *(.rela.got) }
+  .rela.bss       : { *(.rela.bss .rela.bss.* .rela.gnu.linkonce.b.*) }
+  .rela.ifunc     : { *(.rela.ifunc) }
+  .rela.plt       :
+    {
+      *(.rela.plt)
+      PROVIDE_HIDDEN (__rela_iplt_start = .);
+      *(.rela.iplt)
+      PROVIDE_HIDDEN (__rela_iplt_end = .);
+    }
+  .text           :
+  {
+    *(.isr_vector) *(.vectors) *(.boot)
+    *(.vectbl*)
+    }
+  .init           :
+  {
+    KEEP (*(SORT_NONE(.init)))
+  } =0
+  .plt            : { *(.plt) *(.iplt) }
+  .text           :
+  {
+    *(.text.unlikely .text.*_unlikely .text.unlikely.*)
+    *(.text.exit .text.exit.*)
+    *(.text.startup .text.startup.*)
+    *(.startup_code)
+    *(.text.hot .text.hot.*)
+    *(.text .stub .text.* .gnu.linkonce.t.*)
+    /* .gnu.warning sections are handled specially by elf32.em.  */
+    *(.gnu.warning)
+  } =0
+  .fini           :
+  {
+    KEEP (*(SORT_NONE(.fini)))
+  } =0
+  PROVIDE (__etext = .);
+  PROVIDE (_etext = .);
+  PROVIDE (etext = .);
+  .rodata         : { *(.rodata .rodata.* .gnu.linkonce.r.*) }
+  .rodata1        : { *(.rodata1) }
+  .eh_frame_hdr : { *(.eh_frame_hdr) *(.eh_frame_entry .eh_frame_entry.*) }
+  .eh_frame       : ONLY_IF_RO { KEEP (*(.eh_frame)) *(.eh_frame.*) }
+  .gcc_except_table   : ONLY_IF_RO { *(.gcc_except_table
+  .gcc_except_table.*) }
+  .gnu_extab   : ONLY_IF_RO { *(.gnu_extab*) }
+  /* These sections are generated by the Sun/Oracle C++ compiler.  */
+  .exception_ranges   : ONLY_IF_RO { *(.exception_ranges
+  .exception_ranges*) }
+  /* Adjust the address for the data segment.  We want to adjust up to
+     the same address within the page on the next page up.  */
+  . = ALIGN(CONSTANT (MAXPAGESIZE)) + (. & (CONSTANT (MAXPAGESIZE) - 1));
+  /* Exception handling  */
+  .eh_frame       : ONLY_IF_RW { KEEP (*(.eh_frame)) *(.eh_frame.*) }
+  .gnu_extab      : ONLY_IF_RW { *(.gnu_extab) }
+  .gcc_except_table   : ONLY_IF_RW { *(.gcc_except_table .gcc_except_table.*) }
+  .exception_ranges   : ONLY_IF_RW { *(.exception_ranges .exception_ranges*) }
+  /* Thread Local Storage sections  */
+  .tdata	  : { *(.tdata .tdata.* .gnu.linkonce.td.*) }
+  .tbss		  : { *(.tbss .tbss.* .gnu.linkonce.tb.*) *(.tcommon) }
+  .preinit_array     :
+  {
+    PROVIDE_HIDDEN (__preinit_array_start = .);
+    KEEP (*(.preinit_array))
+    PROVIDE_HIDDEN (__preinit_array_end = .);
+  }
+  .init_array     :
+  {
+    PROVIDE_HIDDEN (__init_array_start = .);
+    KEEP (*(SORT_BY_INIT_PRIORITY(.init_array.*) SORT_BY_INIT_PRIORITY(.ctors.*)))
+    KEEP (*(.init_array EXCLUDE_FILE (*crtbegin.o *crtbegin?.o *crtend.o *crtend?.o ) .ctors))
+    PROVIDE_HIDDEN (__init_array_end = .);
+  }
+  .fini_array     :
+  {
+    PROVIDE_HIDDEN (__fini_array_start = .);
+    KEEP (*(SORT_BY_INIT_PRIORITY(.fini_array.*) SORT_BY_INIT_PRIORITY(.dtors.*)))
+    KEEP (*(.fini_array EXCLUDE_FILE (*crtbegin.o *crtbegin?.o *crtend.o *crtend?.o ) .dtors))
+    PROVIDE_HIDDEN (__fini_array_end = .);
+  }
+  .ctors          :
+  {
+    /* gcc uses crtbegin.o to find the start of
+       the constructors, so we make sure it is
+       first.  Because this is a wildcard, it
+       doesn't matter if the user does not
+       actually link against crtbegin.o; the
+       linker won't look for a file to match a
+       wildcard.  The wildcard also means that it
+       doesn't matter which directory crtbegin.o
+       is in.  */
+    KEEP (*crtbegin.o(.ctors))
+    KEEP (*crtbegin?.o(.ctors))
+    /* We don't want to include the .ctor section from
+       the crtend.o file until after the sorted ctors.
+       The .ctor section from the crtend file contains the
+       end of ctors marker and it must be last */
+    KEEP (*(EXCLUDE_FILE (*crtend.o *crtend?.o ) .ctors))
+    KEEP (*(SORT(.ctors.*)))
+    KEEP (*(.ctors))
+  }
+  .dtors          :
+  {
+    KEEP (*crtbegin.o(.dtors))
+    KEEP (*crtbegin?.o(.dtors))
+    KEEP (*(EXCLUDE_FILE (*crtend.o *crtend?.o ) .dtors))
+    KEEP (*(SORT(.dtors.*)))
+    KEEP (*(.dtors))
+  }
+  .jcr            : { KEEP (*(.jcr)) }
+  .data.rel.ro : { *(.data.rel.ro.local* .gnu.linkonce.d.rel.ro.local.*) *(.data.rel.ro .data.rel.ro.* .gnu.linkonce.d.rel.ro.*) }
+  .dynamic        : { *(.dynamic) }
+  .got            : { *(.got) *(.igot) }
+  .got.plt        : { *(.got.plt)  *(.igot.plt) }
+
+  /*
+  . = 0x70400000;
+  . = ALIGN(4096);
+  .resource_table : { *(.resource_table) }
+  */
+
+
+  .data           :
+  {
+    __data_start = . ;
+    *(.data .data.* .gnu.linkonce.d.*)
+    SORT(CONSTRUCTORS)
+  }
+  .data1          : { *(.data1) }
+  _edata = .; PROVIDE (edata = .);
+  . = .;
+  __bss_start = .;
+  __bss_start__ = .;
+  .bss            :
+  {
+   *(.dynbss)
+   *(.bss .bss.* .gnu.linkonce.b.*)
+   *(COMMON)
+   /* Align here to ensure that the .bss section occupies space up to
+      _end.  Align after .bss to ensure correct alignment even if the
+      .bss section disappears because there are no input sections.
+      FIXME: Why do we need it? When there is no .bss section, we don't
+      pad the .data section.  */
+   . = ALIGN(. != 0 ? 16 : 1);
+  }
+  _bss_end__ = . ; __bss_end__ = . ;
+  . = ALIGN(16);
+  . = SEGMENT_START("ldata-segment", .);
+  . = ALIGN(16);
+  __end__ = . ;
+  _end = .; PROVIDE (end = .);
+
+  .heap (NOLOAD) : {
+   . = ALIGN(16);
+   HeapBase = .;
+   __heap_start__ = .;
+   end = __heap_start__;
+   _end = end;
+   __end = end;
+   . += _HEAP_SIZE;
+   _heap_end = .;
+   HeapLimit = .;
+  }
+
+.stack (NOLOAD) : {
+   . = ALIGN(16);
+   stack_bottom = .;
+   . += _STACK_SIZE;
+  __stack = .;
+  stack_top = .;
+    . = ALIGN(16);
+   _irq_stack_end = .;
+   . += _IRQ_STACK_SIZE;
+   __irq_stack = .;
+   _supervisor_stack_end = .;
+   . += _SVC_STACK_SIZE;
+   . = ALIGN(16);
+   __supervisor_stack = .;
+   _abort_stack_end = .;
+   . += _ABORT_STACK_SIZE;
+   . = ALIGN(16);
+   __abort_stack = .;
+   _fiq_stack_end = .;
+   . += _FIQ_STACK_SIZE;
+   . = ALIGN(16);
+   __fiq_stack = .;
+   _undef_stack_end = .;
+   . += _UNDEF_STACK_SIZE;
+   . = ALIGN(16);
+   __undef_stack = .;
+}
+
+  . = ALIGN(0x4000);
+  tbl1_start = .;
+  . = . + 0x4000;
+  tbl1_end = .;
+   app_ram_end = .;
+
+  /* APP related */
+  VSPD1_WPF0_DL_START	= . ;
+  VSPD2_WPF0_DL_START	= VSPD1_WPF0_DL_START    + 0x00000500;
+  DHD_DL_START		= VSPD2_WPF0_DL_START        + 0x00000500;
+  DHD_TEX_START		= DHD_DL_START               + 0x00a00000;
+
+  /* reserve 4*8MB for framebuffers (1920x1080x32b = 8MB) */
+  DU_PLANE1_START_ADDR	= DHD_TEX_START        + 0x00800000;
+  DU_PLANE2_START_ADDR	= DU_PLANE1_START_ADDR + 0x00800000;
+  DU_PLANE3_START_ADDR	= DU_PLANE2_START_ADDR + 0x00800000;
+  DU_PLANE4_START_ADDR	= DU_PLANE3_START_ADDR + 0x00800000; 
+
+
+  /* Stabs debugging sections.  */
+  .stab          0 : { *(.stab) }
+  .stabstr       0 : { *(.stabstr) }
+  .stab.excl     0 : { *(.stab.excl) }
+  .stab.exclstr  0 : { *(.stab.exclstr) }
+  .stab.index    0 : { *(.stab.index) }
+  .stab.indexstr 0 : { *(.stab.indexstr) }
+  .comment       0 : { *(.comment) }
+  /* DWARF debug sections.
+     Symbols in the DWARF debugging sections are relative to the beginning
+     of the section so we begin them at 0.  */
+  /* DWARF 1 */
+  .debug          0 : { *(.debug) }
+  .line           0 : { *(.line) }
+  /* GNU DWARF 1 extensions */
+  .debug_srcinfo  0 : { *(.debug_srcinfo) }
+  .debug_sfnames  0 : { *(.debug_sfnames) }
+  /* DWARF 1.1 and DWARF 2 */
+  .debug_aranges  0 : { *(.debug_aranges) }
+  .debug_pubnames 0 : { *(.debug_pubnames) }
+  /* DWARF 2 */
+  .debug_info     0 : { *(.debug_info .gnu.linkonce.wi.*) }
+  .debug_abbrev   0 : { *(.debug_abbrev) }
+  .debug_line     0 : { *(.debug_line .debug_line.* .debug_line_end ) }
+  .debug_frame    0 : { *(.debug_frame) }
+  .debug_str      0 : { *(.debug_str) }
+  .debug_loc      0 : { *(.debug_loc) }
+  .debug_macinfo  0 : { *(.debug_macinfo) }
+  /* SGI/MIPS DWARF 2 extensions */
+  .debug_weaknames 0 : { *(.debug_weaknames) }
+  .debug_funcnames 0 : { *(.debug_funcnames) }
+  .debug_typenames 0 : { *(.debug_typenames) }
+  .debug_varnames  0 : { *(.debug_varnames) }
+  /* DWARF 3 */
+  .debug_pubtypes 0 : { *(.debug_pubtypes) }
+  .debug_ranges   0 : { *(.debug_ranges) }
+  /* DWARF Extension.  */
+  .debug_macro    0 : { *(.debug_macro) }
+  .debug_addr     0 : { *(.debug_addr) }
+  .ARM.attributes 0 : { KEEP (*(.ARM.attributes)) KEEP (*(.gnu.attributes)) }
+  .note.gnu.arm.ident 0 : { KEEP (*(.note.gnu.arm.ident)) }
+  /DISCARD/ : { *(.note.GNU-stack) *(.gnu_debuglink) *(.gnu.lto_*) }
+}
diff --git a/goil/templates/root.goilTemplate b/goil/templates/root.goilTemplate
index 7612fe84..43136748 100755
--- a/goil/templates/root.goilTemplate
+++ b/goil/templates/root.goilTemplate
@@ -700,6 +700,7 @@ let BASICTASKS := @()
 let EXTENDEDTASKS := @()
 let TASKS := @()
 let RESOURCES := @()
+let isr_start := 0
 foreach obj in PRIO2 do
   if obj::KIND == "Task" then
     if not exists obj::EVENT then
@@ -711,7 +712,16 @@ foreach obj in PRIO2 do
       let OS::RESSCHEDULERPRIORITY := obj::PRIORITY
       let highest_priority_task_uses_resource := exists obj::RESOURCE
     end if
+  elsif obj::KIND == "ISR" then
+    if obj::CATEGORY == 2 then
+      # from this prio ISR are shifted and any resouce must be shifted too
+      let isr_start :=1
+    end if
   elsif obj::KIND == "Resource" then
+    # if we started shifting cat2 ISR we have to shift objects above too.
+    if isr_start == 1 then
+      let obj::PRIORITY := obj::PRIORITY + 1
+    end if
     let RESOURCES += obj
   end if
 end foreach
diff --git a/machines/cortex-r/Makefile b/machines/cortex-r/Makefile
new file mode 100644
index 00000000..fb745aed
--- /dev/null
+++ b/machines/cortex-r/Makefile
@@ -0,0 +1,13 @@
+#
+# This makefile should be included into ARM subarchitecture
+#
+
+TEMP_SOURCE_DIRS += $(MACHINE_PATH)/..
+
+#SOURCES += tpl_machine_arm_generic.c \
+#tpl_irq.S \
+#tpl_system_call.S \
+#tpl_stacks.S \
+#tpl_trusted_fct.S \
+#tpl_vector_table.s
+
diff --git a/machines/cortex-r/armv7/Makefile b/machines/cortex-r/armv7/Makefile
new file mode 100644
index 00000000..f93e368f
--- /dev/null
+++ b/machines/cortex-r/armv7/Makefile
@@ -0,0 +1,36 @@
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Copyright ESEO for function and data structures documentation and ARM port
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# $Date$
+# $Rev$
+# $Author$
+# $URL$
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#          generated by goil.
+#
+#kernel OS architecture dependant files
+
+SOURCES += \
+tpl_irq.S \
+tpl_machine_arm.c \
+tpl_stacks.S \
+tpl_system_call.S \
+tpl_vector_table.s
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/Makefile b/machines/cortex-r/armv7/RCar/CMSIS/Makefile
new file mode 100644
index 00000000..363dbfeb
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/Makefile
@@ -0,0 +1,34 @@
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Copyright ESEO for function and data structures documentation and ARM port
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# $Date$
+# $Rev$
+# $Author$
+# $URL$
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#          generated by goil.
+#
+#kernel OS architecture dependant files
+
+SOURCES += \
+irq_ctrl_gic.c
+
+
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armcc.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armcc.h
new file mode 100644
index 00000000..313d7435
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armcc.h
@@ -0,0 +1,544 @@
+/**************************************************************************//**
+ * @file     cmsis_armcc.h
+ * @brief    CMSIS compiler specific macros, functions, instructions
+ * @version  V1.0.2
+ * @date     10. January 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef __CMSIS_ARMCC_H
+#define __CMSIS_ARMCC_H
+
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 400677)
+  #error "Please use Arm Compiler Toolchain V4.0.677 or later!"
+#endif
+
+/* CMSIS compiler control architecture macros */
+#if (defined (__TARGET_ARCH_7_A ) && (__TARGET_ARCH_7_A  == 1))
+  #define __ARM_ARCH_7A__           1
+#endif
+
+/* CMSIS compiler specific defines */
+#ifndef   __ASM
+  #define __ASM                                  __asm
+#endif
+#ifndef   __INLINE
+  #define __INLINE                               __inline
+#endif
+#ifndef   __FORCEINLINE
+  #define __FORCEINLINE                          __forceinline
+#endif
+#ifndef   __STATIC_INLINE
+  #define __STATIC_INLINE                        static __inline
+#endif
+#ifndef   __STATIC_FORCEINLINE
+  #define __STATIC_FORCEINLINE                   static __forceinline
+#endif
+#ifndef   __NO_RETURN
+  #define __NO_RETURN                            __declspec(noreturn)
+#endif
+#ifndef   CMSIS_DEPRECATED
+  #define CMSIS_DEPRECATED                       __attribute__((deprecated))
+#endif
+#ifndef   __USED
+  #define __USED                                 __attribute__((used))
+#endif
+#ifndef   __WEAK
+  #define __WEAK                                 __attribute__((weak))
+#endif
+#ifndef   __PACKED
+  #define __PACKED                               __attribute__((packed))
+#endif
+#ifndef   __PACKED_STRUCT
+  #define __PACKED_STRUCT                        __packed struct
+#endif
+#ifndef   __UNALIGNED_UINT16_WRITE
+  #define __UNALIGNED_UINT16_WRITE(addr, val)    ((*((__packed uint16_t *)(addr))) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT16_READ
+  #define __UNALIGNED_UINT16_READ(addr)          (*((const __packed uint16_t *)(addr)))
+#endif
+#ifndef   __UNALIGNED_UINT32_WRITE
+  #define __UNALIGNED_UINT32_WRITE(addr, val)    ((*((__packed uint32_t *)(addr))) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT32_READ
+  #define __UNALIGNED_UINT32_READ(addr)          (*((const __packed uint32_t *)(addr)))
+#endif
+#ifndef   __ALIGNED
+  #define __ALIGNED(x)                           __attribute__((aligned(x)))
+#endif
+#ifndef   __PACKED
+  #define __PACKED                               __attribute__((packed))
+#endif
+
+/* ##########################  Core Instruction Access  ######################### */
+/**
+  \brief   No Operation
+ */
+#define __NOP                             __nop
+
+/**
+  \brief   Wait For Interrupt
+ */
+#define __WFI                             __wfi
+
+/**
+  \brief   Wait For Event
+ */
+#define __WFE                             __wfe
+
+/**
+  \brief   Send Event
+ */
+#define __SEV                             __sev
+
+/**
+  \brief   Instruction Synchronization Barrier
+ */
+#define __ISB() do {\
+                   __schedule_barrier();\
+                   __isb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Data Synchronization Barrier
+ */
+#define __DSB() do {\
+                   __schedule_barrier();\
+                   __dsb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Data Memory Barrier
+ */
+#define __DMB() do {\
+                   __schedule_barrier();\
+                   __dmb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Reverse byte order (32 bit)
+  \details Reverses the byte order in unsigned integer value. For example, 0x12345678 becomes 0x78563412.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __REV                             __rev
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order within each halfword of a word. For example, 0x12345678 becomes 0x34127856.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#ifndef __NO_EMBEDDED_ASM
+__attribute__((section(".rev16_text"))) __STATIC_INLINE __ASM uint32_t __REV16(uint32_t value)
+{
+  rev16 r0, r0
+  bx lr
+}
+#endif
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order in a 16-bit value and returns the signed 16-bit result. For example, 0x0080 becomes 0x8000.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#ifndef __NO_EMBEDDED_ASM
+__attribute__((section(".revsh_text"))) __STATIC_INLINE __ASM int16_t __REVSH(int16_t value)
+{
+  revsh r0, r0
+  bx lr
+}
+#endif
+
+/**
+  \brief   Rotate Right in unsigned value (32 bit)
+  \param [in]    op1  Value to rotate
+  \param [in]    op2  Number of Bits to rotate
+  \return               Rotated value
+ */
+#define __ROR                             __ror
+
+/**
+  \brief   Breakpoint
+  \param [in]    value  is ignored by the processor.
+                 If required, a debugger can use it to store additional information about the breakpoint.
+ */
+#define __BKPT(value)                     __breakpoint(value)
+
+/**
+  \brief   Reverse bit order of value
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __RBIT                            __rbit
+
+/**
+  \brief   Count leading zeros
+  \param [in]  value  Value to count the leading zeros
+  \return             number of leading zeros in value
+ */
+#define __CLZ                             __clz
+
+/**
+  \brief   LDR Exclusive (8 bit)
+  \details Executes a exclusive LDR instruction for 8 bit value.
+  \param [in]    ptr  Pointer to data
+  \return             value of type uint8_t at (*ptr)
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __LDREXB(ptr)                                                        ((uint8_t ) __ldrex(ptr))
+#else
+  #define __LDREXB(ptr)          _Pragma("push") _Pragma("diag_suppress 3731") ((uint8_t ) __ldrex(ptr))  _Pragma("pop")
+#endif
+
+/**
+  \brief   LDR Exclusive (16 bit)
+  \details Executes a exclusive LDR instruction for 16 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint16_t at (*ptr)
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __LDREXH(ptr)                                                        ((uint16_t) __ldrex(ptr))
+#else
+  #define __LDREXH(ptr)          _Pragma("push") _Pragma("diag_suppress 3731") ((uint16_t) __ldrex(ptr))  _Pragma("pop")
+#endif
+
+/**
+  \brief   LDR Exclusive (32 bit)
+  \details Executes a exclusive LDR instruction for 32 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint32_t at (*ptr)
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __LDREXW(ptr)                                                        ((uint32_t ) __ldrex(ptr))
+#else
+  #define __LDREXW(ptr)          _Pragma("push") _Pragma("diag_suppress 3731") ((uint32_t ) __ldrex(ptr))  _Pragma("pop")
+#endif
+
+/**
+  \brief   STR Exclusive (8 bit)
+  \details Executes a exclusive STR instruction for 8 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __STREXB(value, ptr)                                                 __strex(value, ptr)
+#else
+  #define __STREXB(value, ptr)   _Pragma("push") _Pragma("diag_suppress 3731") __strex(value, ptr)        _Pragma("pop")
+#endif
+
+/**
+  \brief   STR Exclusive (16 bit)
+  \details Executes a exclusive STR instruction for 16 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __STREXH(value, ptr)                                                 __strex(value, ptr)
+#else
+  #define __STREXH(value, ptr)   _Pragma("push") _Pragma("diag_suppress 3731") __strex(value, ptr)        _Pragma("pop")
+#endif
+
+/**
+  \brief   STR Exclusive (32 bit)
+  \details Executes a exclusive STR instruction for 32 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#if defined(__ARMCC_VERSION) && (__ARMCC_VERSION < 5060020)
+  #define __STREXW(value, ptr)                                                 __strex(value, ptr)
+#else
+  #define __STREXW(value, ptr)   _Pragma("push") _Pragma("diag_suppress 3731") __strex(value, ptr)        _Pragma("pop")
+#endif
+
+/**
+  \brief   Remove the exclusive lock
+  \details Removes the exclusive lock which is created by LDREX.
+ */
+#define __CLREX                           __clrex
+
+
+/**
+  \brief   Signed Saturate
+  \details Saturates a signed value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (1..32)
+  \return             Saturated value
+ */
+#define __SSAT                            __ssat
+
+/**
+  \brief   Unsigned Saturate
+  \details Saturates an unsigned value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (0..31)
+  \return             Saturated value
+ */
+#define __USAT                            __usat
+
+/* ###########################  Core Function Access  ########################### */
+
+/**
+  \brief   Get FPSCR (Floating Point Status/Control)
+  \return               Floating Point Status/Control register value
+ */
+__STATIC_INLINE uint32_t __get_FPSCR(void)
+{
+#if ((defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)) && \
+     (defined (__FPU_USED   ) && (__FPU_USED    == 1U))     )
+  register uint32_t __regfpscr         __ASM("fpscr");
+  return(__regfpscr);
+#else
+   return(0U);
+#endif
+}
+
+/**
+  \brief   Set FPSCR (Floating Point Status/Control)
+  \param [in]    fpscr  Floating Point Status/Control value to set
+ */
+__STATIC_INLINE void __set_FPSCR(uint32_t fpscr)
+{
+#if ((defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)) && \
+     (defined (__FPU_USED   ) && (__FPU_USED    == 1U))     )
+  register uint32_t __regfpscr         __ASM("fpscr");
+  __regfpscr = (fpscr);
+#else
+  (void)fpscr;
+#endif
+}
+
+/** \brief  Get CPSR (Current Program Status Register)
+    \return               CPSR Register value
+ */
+__STATIC_INLINE uint32_t __get_CPSR(void)
+{
+  register uint32_t __regCPSR          __ASM("cpsr");
+  return(__regCPSR);
+}
+
+
+/** \brief  Set CPSR (Current Program Status Register)
+    \param [in]    cpsr  CPSR value to set
+ */
+__STATIC_INLINE void __set_CPSR(uint32_t cpsr)
+{
+  register uint32_t __regCPSR          __ASM("cpsr");
+  __regCPSR = cpsr;
+}
+
+/** \brief  Get Mode
+    \return                Processor Mode
+ */
+__STATIC_INLINE uint32_t __get_mode(void)
+{
+  return (__get_CPSR() & 0x1FU);
+}
+
+/** \brief  Set Mode
+    \param [in]    mode  Mode value to set
+ */
+__STATIC_INLINE __ASM void __set_mode(uint32_t mode)
+{
+  MOV  r1, lr
+  MSR  CPSR_C, r0
+  BX   r1
+}
+
+/** \brief  Get Stack Pointer
+    \return Stack Pointer
+ */
+__STATIC_INLINE __ASM uint32_t __get_SP(void)
+{
+  MOV  r0, sp
+  BX   lr
+}
+
+/** \brief  Set Stack Pointer
+    \param [in]    stack  Stack Pointer value to set
+ */
+__STATIC_INLINE __ASM void __set_SP(uint32_t stack)
+{
+  MOV  sp, r0
+  BX   lr
+}
+
+
+/** \brief  Get USR/SYS Stack Pointer
+    \return USR/SYSStack Pointer
+ */
+__STATIC_INLINE __ASM uint32_t __get_SP_usr(void)
+{
+  ARM
+  PRESERVE8
+
+  MRS     R1, CPSR
+  CPS     #0x1F       ;no effect in USR mode
+  MOV     R0, SP
+  MSR     CPSR_c, R1  ;no effect in USR mode
+  ISB
+  BX      LR
+}
+
+/** \brief  Set USR/SYS Stack Pointer
+    \param [in]    topOfProcStack  USR/SYS Stack Pointer value to set
+ */
+__STATIC_INLINE __ASM void __set_SP_usr(uint32_t topOfProcStack)
+{
+  ARM
+  PRESERVE8
+
+  MRS     R1, CPSR
+  CPS     #0x1F       ;no effect in USR mode
+  MOV     SP, R0
+  MSR     CPSR_c, R1  ;no effect in USR mode
+  ISB
+  BX      LR
+}
+
+/** \brief  Get FPEXC (Floating Point Exception Control Register)
+    \return               Floating Point Exception Control Register value
+ */
+__STATIC_INLINE uint32_t __get_FPEXC(void)
+{
+#if (__FPU_PRESENT == 1)
+  register uint32_t __regfpexc         __ASM("fpexc");
+  return(__regfpexc);
+#else
+  return(0);
+#endif
+}
+
+/** \brief  Set FPEXC (Floating Point Exception Control Register)
+    \param [in]    fpexc  Floating Point Exception Control value to set
+ */
+__STATIC_INLINE void __set_FPEXC(uint32_t fpexc)
+{
+#if (__FPU_PRESENT == 1)
+  register uint32_t __regfpexc         __ASM("fpexc");
+  __regfpexc = (fpexc);
+#endif
+}
+
+/*
+ * Include common core functions to access Coprocessor 15 registers
+ */
+
+#define __get_CP(cp, op1, Rt, CRn, CRm, op2) do { register volatile uint32_t tmp __ASM("cp" # cp ":" # op1 ":c" # CRn ":c" # CRm ":" # op2); (Rt) = tmp; } while(0)
+#define __set_CP(cp, op1, Rt, CRn, CRm, op2) do { register volatile uint32_t tmp __ASM("cp" # cp ":" # op1 ":c" # CRn ":c" # CRm ":" # op2); tmp = (Rt); } while(0)
+#define __get_CP64(cp, op1, Rt, CRm) \
+  do { \
+    uint32_t ltmp, htmp; \
+    __ASM volatile("MRRC p" # cp ", " # op1 ", ltmp, htmp, c" # CRm); \
+    (Rt) = ((((uint64_t)htmp) << 32U) | ((uint64_t)ltmp)); \
+  } while(0)
+
+#define __set_CP64(cp, op1, Rt, CRm) \
+  do { \
+    const uint64_t tmp = (Rt); \
+    const uint32_t ltmp = (uint32_t)(tmp); \
+    const uint32_t htmp = (uint32_t)(tmp >> 32U); \
+    __ASM volatile("MCRR p" # cp ", " # op1 ", ltmp, htmp, c" # CRm); \
+  } while(0)
+
+#include "cmsis_cp15.h"
+
+/** \brief  Enable Floating Point Unit
+
+  Critical section, called from undef handler, so systick is disabled
+ */
+__STATIC_INLINE __ASM void __FPU_Enable(void)
+{
+        ARM
+
+        //Permit access to VFP/NEON, registers by modifying CPACR
+        MRC     p15,0,R1,c1,c0,2
+        ORR     R1,R1,#0x00F00000
+        MCR     p15,0,R1,c1,c0,2
+
+        //Ensure that subsequent instructions occur in the context of VFP/NEON access permitted
+        ISB
+
+        //Enable VFP/NEON
+        VMRS    R1,FPEXC
+        ORR     R1,R1,#0x40000000
+        VMSR    FPEXC,R1
+
+        //Initialise VFP/NEON registers to 0
+        MOV     R2,#0
+
+        //Initialise D16 registers to 0
+        VMOV    D0, R2,R2
+        VMOV    D1, R2,R2
+        VMOV    D2, R2,R2
+        VMOV    D3, R2,R2
+        VMOV    D4, R2,R2
+        VMOV    D5, R2,R2
+        VMOV    D6, R2,R2
+        VMOV    D7, R2,R2
+        VMOV    D8, R2,R2
+        VMOV    D9, R2,R2
+        VMOV    D10,R2,R2
+        VMOV    D11,R2,R2
+        VMOV    D12,R2,R2
+        VMOV    D13,R2,R2
+        VMOV    D14,R2,R2
+        VMOV    D15,R2,R2
+
+  IF {TARGET_FEATURE_EXTENSION_REGISTER_COUNT} == 32
+        //Initialise D32 registers to 0
+        VMOV    D16,R2,R2
+        VMOV    D17,R2,R2
+        VMOV    D18,R2,R2
+        VMOV    D19,R2,R2
+        VMOV    D20,R2,R2
+        VMOV    D21,R2,R2
+        VMOV    D22,R2,R2
+        VMOV    D23,R2,R2
+        VMOV    D24,R2,R2
+        VMOV    D25,R2,R2
+        VMOV    D26,R2,R2
+        VMOV    D27,R2,R2
+        VMOV    D28,R2,R2
+        VMOV    D29,R2,R2
+        VMOV    D30,R2,R2
+        VMOV    D31,R2,R2
+  ENDIF
+
+        //Initialise FPSCR to a known state
+        VMRS    R2,FPSCR
+        LDR     R3,=0x00086060 //Mask off all bits that do not have to be preserved. Non-preserved bits can/should be zero.
+        AND     R2,R2,R3
+        VMSR    FPSCR,R2
+
+        BX      LR
+}
+
+#endif /* __CMSIS_ARMCC_H */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armclang.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armclang.h
new file mode 100644
index 00000000..efc53582
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_armclang.h
@@ -0,0 +1,519 @@
+/**************************************************************************//**
+ * @file     cmsis_armclang.h
+ * @brief    CMSIS compiler specific macros, functions, instructions
+ * @version  V1.0.2
+ * @date     10. January 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef __CMSIS_ARMCLANG_H
+#define __CMSIS_ARMCLANG_H
+
+#pragma clang system_header   /* treat file as system include file */
+
+#ifndef __ARM_COMPAT_H
+#include <arm_compat.h>    /* Compatibility header for Arm Compiler 5 intrinsics */
+#endif
+
+/* CMSIS compiler specific defines */
+#ifndef   __ASM
+  #define __ASM                                  __asm
+#endif
+#ifndef   __INLINE
+  #define __INLINE                               __inline
+#endif
+#ifndef   __FORCEINLINE
+  #define __FORCEINLINE                          __attribute__((always_inline))
+#endif
+#ifndef   __STATIC_INLINE
+  #define __STATIC_INLINE                        static __inline
+#endif
+#ifndef   __STATIC_FORCEINLINE
+  #define __STATIC_FORCEINLINE                   __attribute__((always_inline)) static __inline
+#endif
+#ifndef   __NO_RETURN
+  #define __NO_RETURN                            __attribute__((__noreturn__))
+#endif
+#ifndef   CMSIS_DEPRECATED
+  #define CMSIS_DEPRECATED                       __attribute__((deprecated))
+#endif
+#ifndef   __USED
+  #define __USED                                 __attribute__((used))
+#endif
+#ifndef   __WEAK
+  #define __WEAK                                 __attribute__((weak))
+#endif
+#ifndef   __PACKED
+  #define __PACKED                               __attribute__((packed, aligned(1)))
+#endif
+#ifndef   __PACKED_STRUCT
+  #define __PACKED_STRUCT                        struct __attribute__((packed, aligned(1)))
+#endif
+#ifndef   __UNALIGNED_UINT16_WRITE
+  #pragma clang diagnostic push
+  #pragma clang diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT16_WRITE)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT16_WRITE */
+  __PACKED_STRUCT T_UINT16_WRITE { uint16_t v; };
+  #pragma clang diagnostic pop
+  #define __UNALIGNED_UINT16_WRITE(addr, val)    (void)((((struct T_UINT16_WRITE *)(void *)(addr))->v) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT16_READ
+  #pragma clang diagnostic push
+  #pragma clang diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT16_READ)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT16_READ */
+  __PACKED_STRUCT T_UINT16_READ { uint16_t v; };
+  #pragma clang diagnostic pop
+  #define __UNALIGNED_UINT16_READ(addr)          (((const struct T_UINT16_READ *)(const void *)(addr))->v)
+#endif
+#ifndef   __UNALIGNED_UINT32_WRITE
+  #pragma clang diagnostic push
+  #pragma clang diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT32_WRITE)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT32_WRITE */
+  __PACKED_STRUCT T_UINT32_WRITE { uint32_t v; };
+  #pragma clang diagnostic pop
+  #define __UNALIGNED_UINT32_WRITE(addr, val)    (void)((((struct T_UINT32_WRITE *)(void *)(addr))->v) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT32_READ
+  #pragma clang diagnostic push
+  #pragma clang diagnostic ignored "-Wpacked"
+  __PACKED_STRUCT T_UINT32_READ { uint32_t v; };
+  #pragma clang diagnostic pop
+  #define __UNALIGNED_UINT32_READ(addr)          (((const struct T_UINT32_READ *)(const void *)(addr))->v)
+#endif
+#ifndef   __ALIGNED
+  #define __ALIGNED(x)                           __attribute__((aligned(x)))
+#endif
+#ifndef   __PACKED
+  #define __PACKED                               __attribute__((packed))
+#endif
+
+/* ##########################  Core Instruction Access  ######################### */
+/**
+  \brief   No Operation
+ */
+#define __NOP                             __builtin_arm_nop
+
+/**
+  \brief   Wait For Interrupt
+ */
+#define __WFI                             __builtin_arm_wfi
+
+/**
+  \brief   Wait For Event
+ */
+#define __WFE                             __builtin_arm_wfe
+
+/**
+  \brief   Send Event
+ */
+#define __SEV                             __builtin_arm_sev
+
+/**
+  \brief   Instruction Synchronization Barrier
+ */
+#define __ISB() do {\
+                   __schedule_barrier();\
+                   __builtin_arm_isb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Data Synchronization Barrier
+ */
+#define __DSB() do {\
+                   __schedule_barrier();\
+                   __builtin_arm_dsb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Data Memory Barrier
+ */
+#define __DMB() do {\
+                   __schedule_barrier();\
+                   __builtin_arm_dmb(0xF);\
+                   __schedule_barrier();\
+                } while (0U)
+
+/**
+  \brief   Reverse byte order (32 bit)
+  \details Reverses the byte order in unsigned integer value. For example, 0x12345678 becomes 0x78563412.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __REV(value)   __builtin_bswap32(value)
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order within each halfword of a word. For example, 0x12345678 becomes 0x34127856.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __REV16(value) __ROR(__REV(value), 16)
+
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order in a 16-bit value and returns the signed 16-bit result. For example, 0x0080 becomes 0x8000.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __REVSH(value) (int16_t)__builtin_bswap16(value)
+
+
+/**
+  \brief   Rotate Right in unsigned value (32 bit)
+  \details Rotate Right (immediate) provides the value of the contents of a register rotated by a variable number of bits.
+  \param [in]    op1  Value to rotate
+  \param [in]    op2  Number of Bits to rotate
+  \return               Rotated value
+ */
+__STATIC_FORCEINLINE uint32_t __ROR(uint32_t op1, uint32_t op2)
+{
+  op2 %= 32U;
+  if (op2 == 0U)
+  {
+    return op1;
+  }
+  return (op1 >> op2) | (op1 << (32U - op2));
+}
+
+
+/**
+  \brief   Breakpoint
+  \param [in]    value  is ignored by the processor.
+                 If required, a debugger can use it to store additional information about the breakpoint.
+ */
+#define __BKPT(value)   __ASM volatile ("bkpt "#value)
+
+/**
+  \brief   Reverse bit order of value
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#define __RBIT          __builtin_arm_rbit
+
+/**
+  \brief   Count leading zeros
+  \param [in]  value  Value to count the leading zeros
+  \return             number of leading zeros in value
+ */
+__STATIC_FORCEINLINE uint8_t __CLZ(uint32_t value)
+{
+  /* Even though __builtin_clz produces a CLZ instruction on ARM, formally
+     __builtin_clz(0) is undefined behaviour, so handle this case specially.
+     This guarantees ARM-compatible results if happening to compile on a non-ARM
+     target, and ensures the compiler doesn't decide to activate any
+     optimisations using the logic "value was passed to __builtin_clz, so it
+     is non-zero".
+     ARM Compiler 6.10 and possibly earlier will optimise this test away, leaving a
+     single CLZ instruction.
+   */
+  if (value == 0U)
+  {
+    return 32U;
+  }
+  return __builtin_clz(value);
+}
+
+/**
+  \brief   LDR Exclusive (8 bit)
+  \details Executes a exclusive LDR instruction for 8 bit value.
+  \param [in]    ptr  Pointer to data
+  \return             value of type uint8_t at (*ptr)
+ */
+#define __LDREXB        (uint8_t)__builtin_arm_ldrex
+
+
+/**
+  \brief   LDR Exclusive (16 bit)
+  \details Executes a exclusive LDR instruction for 16 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint16_t at (*ptr)
+ */
+#define __LDREXH        (uint16_t)__builtin_arm_ldrex
+
+/**
+  \brief   LDR Exclusive (32 bit)
+  \details Executes a exclusive LDR instruction for 32 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint32_t at (*ptr)
+ */
+#define __LDREXW        (uint32_t)__builtin_arm_ldrex
+
+/**
+  \brief   STR Exclusive (8 bit)
+  \details Executes a exclusive STR instruction for 8 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#define __STREXB        (uint32_t)__builtin_arm_strex
+
+/**
+  \brief   STR Exclusive (16 bit)
+  \details Executes a exclusive STR instruction for 16 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#define __STREXH        (uint32_t)__builtin_arm_strex
+
+/**
+  \brief   STR Exclusive (32 bit)
+  \details Executes a exclusive STR instruction for 32 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+#define __STREXW        (uint32_t)__builtin_arm_strex
+
+/**
+  \brief   Remove the exclusive lock
+  \details Removes the exclusive lock which is created by LDREX.
+ */
+#define __CLREX             __builtin_arm_clrex
+
+/**
+  \brief   Signed Saturate
+  \details Saturates a signed value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (1..32)
+  \return             Saturated value
+ */
+#define __SSAT             __builtin_arm_ssat
+
+/**
+  \brief   Unsigned Saturate
+  \details Saturates an unsigned value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (0..31)
+  \return             Saturated value
+ */
+#define __USAT             __builtin_arm_usat
+
+
+/* ###########################  Core Function Access  ########################### */
+
+/**
+  \brief   Get FPSCR
+  \details Returns the current value of the Floating Point Status/Control register.
+  \return               Floating Point Status/Control register value
+ */
+#define __get_FPSCR      __builtin_arm_get_fpscr
+
+/**
+  \brief   Set FPSCR
+  \details Assigns the given value to the Floating Point Status/Control register.
+  \param [in]    fpscr  Floating Point Status/Control value to set
+ */
+#define __set_FPSCR      __builtin_arm_set_fpscr
+
+/** \brief  Get CPSR Register
+    \return               CPSR Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CPSR(void)
+{
+  uint32_t result;
+  __ASM volatile("MRS %0, cpsr" : "=r" (result) );
+  return(result);
+}
+
+/** \brief  Set CPSR Register
+    \param [in]    cpsr  CPSR value to set
+ */
+__STATIC_FORCEINLINE void __set_CPSR(uint32_t cpsr)
+{
+__ASM volatile ("MSR cpsr, %0" : : "r" (cpsr) : "memory");
+}
+
+/** \brief  Get Mode
+    \return                Processor Mode
+ */
+__STATIC_FORCEINLINE uint32_t __get_mode(void)
+{
+	return (__get_CPSR() & 0x1FU);
+}
+
+/** \brief  Set Mode
+    \param [in]    mode  Mode value to set
+ */
+__STATIC_FORCEINLINE void __set_mode(uint32_t mode)
+{
+  __ASM volatile("MSR  cpsr_c, %0" : : "r" (mode) : "memory");
+}
+
+/** \brief  Get Stack Pointer
+    \return Stack Pointer value
+ */
+__STATIC_FORCEINLINE uint32_t __get_SP()
+{
+  uint32_t result;
+  __ASM volatile("MOV  %0, sp" : "=r" (result) : : "memory");
+  return result;
+}
+
+/** \brief  Set Stack Pointer
+    \param [in]    stack  Stack Pointer value to set
+ */
+__STATIC_FORCEINLINE void __set_SP(uint32_t stack)
+{
+  __ASM volatile("MOV  sp, %0" : : "r" (stack) : "memory");
+}
+
+/** \brief  Get USR/SYS Stack Pointer
+    \return USR/SYS Stack Pointer value
+ */
+__STATIC_FORCEINLINE uint32_t __get_SP_usr()
+{
+  uint32_t cpsr;
+  uint32_t result;
+  __ASM volatile(
+    "MRS     %0, cpsr   \n"
+    "CPS     #0x1F      \n" // no effect in USR mode
+    "MOV     %1, sp     \n"
+    "MSR     cpsr_c, %2 \n" // no effect in USR mode
+    "ISB" :  "=r"(cpsr), "=r"(result) : "r"(cpsr) : "memory"
+   );
+  return result;
+}
+
+/** \brief  Set USR/SYS Stack Pointer
+    \param [in]    topOfProcStack  USR/SYS Stack Pointer value to set
+ */
+__STATIC_FORCEINLINE void __set_SP_usr(uint32_t topOfProcStack)
+{
+  uint32_t cpsr;
+  __ASM volatile(
+    "MRS     %0, cpsr   \n"
+    "CPS     #0x1F      \n" // no effect in USR mode
+    "MOV     sp, %1     \n"
+    "MSR     cpsr_c, %2 \n" // no effect in USR mode
+    "ISB" : "=r"(cpsr) : "r" (topOfProcStack), "r"(cpsr) : "memory"
+   );
+}
+
+/** \brief  Get FPEXC
+    \return               Floating Point Exception Control register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_FPEXC(void)
+{
+#if (__FPU_PRESENT == 1)
+  uint32_t result;
+  __ASM volatile("VMRS %0, fpexc" : "=r" (result) : : "memory");
+  return(result);
+#else
+  return(0);
+#endif
+}
+
+/** \brief  Set FPEXC
+    \param [in]    fpexc  Floating Point Exception Control value to set
+ */
+__STATIC_FORCEINLINE void __set_FPEXC(uint32_t fpexc)
+{
+#if (__FPU_PRESENT == 1)
+  __ASM volatile ("VMSR fpexc, %0" : : "r" (fpexc) : "memory");
+#endif
+}
+
+/*
+ * Include common core functions to access Coprocessor 15 registers
+ */
+
+#define __get_CP(cp, op1, Rt, CRn, CRm, op2) __ASM volatile("MRC p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : "=r" (Rt) : : "memory" )
+#define __set_CP(cp, op1, Rt, CRn, CRm, op2) __ASM volatile("MCR p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : : "r" (Rt) : "memory" )
+#define __get_CP64(cp, op1, Rt, CRm)         __ASM volatile("MRRC p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : "=r" (Rt) : : "memory" )
+#define __set_CP64(cp, op1, Rt, CRm)         __ASM volatile("MCRR p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : : "r" (Rt) : "memory" )
+
+#include "cmsis_cp15.h"
+
+/** \brief  Enable Floating Point Unit
+
+  Critical section, called from undef handler, so systick is disabled
+ */
+__STATIC_INLINE void __FPU_Enable(void)
+{
+  __ASM volatile(
+    //Permit access to VFP/NEON, registers by modifying CPACR
+    "        MRC     p15,0,R1,c1,c0,2  \n"
+    "        ORR     R1,R1,#0x00F00000 \n"
+    "        MCR     p15,0,R1,c1,c0,2  \n"
+
+    //Ensure that subsequent instructions occur in the context of VFP/NEON access permitted
+    "        ISB                       \n"
+
+    //Enable VFP/NEON
+    "        VMRS    R1,FPEXC          \n"
+    "        ORR     R1,R1,#0x40000000 \n"
+    "        VMSR    FPEXC,R1          \n"
+
+    //Initialise VFP/NEON registers to 0
+    "        MOV     R2,#0             \n"
+
+    //Initialise D16 registers to 0
+    "        VMOV    D0, R2,R2         \n"
+    "        VMOV    D1, R2,R2         \n"
+    "        VMOV    D2, R2,R2         \n"
+    "        VMOV    D3, R2,R2         \n"
+    "        VMOV    D4, R2,R2         \n"
+    "        VMOV    D5, R2,R2         \n"
+    "        VMOV    D6, R2,R2         \n"
+    "        VMOV    D7, R2,R2         \n"
+    "        VMOV    D8, R2,R2         \n"
+    "        VMOV    D9, R2,R2         \n"
+    "        VMOV    D10,R2,R2         \n"
+    "        VMOV    D11,R2,R2         \n"
+    "        VMOV    D12,R2,R2         \n"
+    "        VMOV    D13,R2,R2         \n"
+    "        VMOV    D14,R2,R2         \n"
+    "        VMOV    D15,R2,R2         \n"
+
+#if __ARM_NEON == 1
+    //Initialise D32 registers to 0
+    "        VMOV    D16,R2,R2         \n"
+    "        VMOV    D17,R2,R2         \n"
+    "        VMOV    D18,R2,R2         \n"
+    "        VMOV    D19,R2,R2         \n"
+    "        VMOV    D20,R2,R2         \n"
+    "        VMOV    D21,R2,R2         \n"
+    "        VMOV    D22,R2,R2         \n"
+    "        VMOV    D23,R2,R2         \n"
+    "        VMOV    D24,R2,R2         \n"
+    "        VMOV    D25,R2,R2         \n"
+    "        VMOV    D26,R2,R2         \n"
+    "        VMOV    D27,R2,R2         \n"
+    "        VMOV    D28,R2,R2         \n"
+    "        VMOV    D29,R2,R2         \n"
+    "        VMOV    D30,R2,R2         \n"
+    "        VMOV    D31,R2,R2         \n"
+#endif
+
+    //Initialise FPSCR to a known state
+    "        VMRS    R2,FPSCR          \n"
+    "        LDR     R3,=0x00086060    \n" //Mask off all bits that do not have to be preserved. Non-preserved bits can/should be zero.
+    "        AND     R2,R2,R3          \n"
+    "        VMSR    FPSCR,R2            "
+  );
+}
+
+#endif /* __CMSIS_ARMCLANG_H */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_compiler.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_compiler.h
new file mode 100644
index 00000000..b00c6ba3
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_compiler.h
@@ -0,0 +1,201 @@
+/**************************************************************************//**
+ * @file     cmsis_compiler.h
+ * @brief    CMSIS compiler specific macros, functions, instructions
+ * @version  V1.0.2
+ * @date     10. January 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef __CMSIS_COMPILER_H
+#define __CMSIS_COMPILER_H
+
+#include <stdint.h>
+
+/*
+ * Arm Compiler 4/5
+ */
+#if   defined ( __CC_ARM )
+  #include "cmsis_armcc.h"
+
+
+/*
+ * Arm Compiler 6 (armclang)
+ */
+#elif defined (__ARMCC_VERSION) && (__ARMCC_VERSION >= 6010050)
+  #include "cmsis_armclang.h"
+
+
+/*
+ * GNU Compiler
+ */
+#elif defined ( __GNUC__ )
+  #include "cmsis_gcc.h"
+
+
+/*
+ * IAR Compiler
+ */
+#elif defined ( __ICCARM__ )
+  #include "cmsis_iccarm.h"
+
+
+/*
+ * TI Arm Compiler
+ */
+#elif defined ( __TI_ARM__ )
+  #include <cmsis_ccs.h>
+
+  #ifndef   __ASM
+    #define __ASM                     __asm
+  #endif
+  #ifndef   __INLINE
+    #define __INLINE                  inline
+  #endif
+  #ifndef   __STATIC_INLINE
+    #define __STATIC_INLINE           static inline
+  #endif
+  #ifndef   __STATIC_INLINE
+    #define __STATIC_INLINE           static inline
+  #endif
+  #ifndef   __STATIC_FORCEINLINE
+    #define __STATIC_FORCEINLINE      __STATIC_INLINE
+  #endif
+  #ifndef   __NO_RETURN
+    #define __NO_RETURN               __attribute__((noreturn))
+  #endif
+  #ifndef   CMSIS_DEPRECATED
+    #define CMSIS_DEPRECATED          __attribute__((deprecated))
+  #endif
+  #ifndef   __USED
+    #define __USED                    __attribute__((used))
+  #endif
+  #ifndef   __WEAK
+    #define __WEAK                    __attribute__((weak))
+  #endif
+  #ifndef   __UNALIGNED_UINT32
+    struct __attribute__((packed)) T_UINT32 { uint32_t v; };
+    #define __UNALIGNED_UINT32(x)     (((struct T_UINT32 *)(x))->v)
+  #endif
+  #ifndef   __ALIGNED
+    #define __ALIGNED(x)              __attribute__((aligned(x)))
+  #endif
+  #ifndef   __PACKED
+    #define __PACKED                  __attribute__((packed))
+  #endif
+
+
+/*
+ * TASKING Compiler
+ */
+#elif defined ( __TASKING__ )
+  /*
+   * The CMSIS functions have been implemented as intrinsics in the compiler.
+   * Please use "carm -?i" to get an up to date list of all intrinsics,
+   * Including the CMSIS ones.
+   */
+
+  #ifndef   __ASM
+    #define __ASM                     __asm
+  #endif
+  #ifndef   __INLINE
+    #define __INLINE                  inline
+  #endif
+  #ifndef   __STATIC_INLINE
+    #define __STATIC_INLINE           static inline
+  #endif
+  #ifndef   __STATIC_FORCEINLINE
+    #define __STATIC_FORCEINLINE      __STATIC_INLINE
+  #endif
+  #ifndef   __NO_RETURN
+    #define __NO_RETURN               __attribute__((noreturn))
+  #endif
+  #ifndef   CMSIS_DEPRECATED
+    #define CMSIS_DEPRECATED          __attribute__((deprecated))
+  #endif
+  #ifndef   __USED
+    #define __USED                    __attribute__((used))
+  #endif
+  #ifndef   __WEAK
+    #define __WEAK                    __attribute__((weak))
+  #endif
+  #ifndef   __UNALIGNED_UINT32
+    struct __packed__ T_UINT32 { uint32_t v; };
+    #define __UNALIGNED_UINT32(x)     (((struct T_UINT32 *)(x))->v)
+  #endif
+  #ifndef   __ALIGNED
+    #define __ALIGNED(x)              __align(x)
+  #endif
+  #ifndef   __PACKED
+    #define __PACKED                  __packed__
+  #endif
+
+
+/*
+ * COSMIC Compiler
+ */
+#elif defined ( __CSMC__ )
+   #include <cmsis_csm.h>
+
+ #ifndef   __ASM
+    #define __ASM                     _asm
+  #endif
+  #ifndef   __INLINE
+    #define __INLINE                  inline
+  #endif
+  #ifndef   __STATIC_INLINE
+    #define __STATIC_INLINE           static inline
+  #endif
+  #ifndef   __STATIC_FORCEINLINE
+    #define __STATIC_FORCEINLINE      __STATIC_INLINE
+  #endif
+  #ifndef   __NO_RETURN
+    // NO RETURN is automatically detected hence no warning here
+    #define __NO_RETURN
+  #endif
+  #ifndef   __USED
+    #warning No compiler specific solution for __USED. __USED is ignored.
+    #define __USED
+  #endif
+  #ifndef   CMSIS_DEPRECATED
+    #warning No compiler specific solution for CMSIS_DEPRECATED. CMSIS_DEPRECATED is ignored.
+    #define CMSIS_DEPRECATED
+  #endif
+  #ifndef   __WEAK
+    #define __WEAK                    __weak
+  #endif
+  #ifndef   __UNALIGNED_UINT32
+    @packed struct T_UINT32 { uint32_t v; };
+    #define __UNALIGNED_UINT32(x)     (((struct T_UINT32 *)(x))->v)
+  #endif
+  #ifndef   __ALIGNED
+    #warning No compiler specific solution for __ALIGNED. __ALIGNED is ignored.
+    #define __ALIGNED(x)
+  #endif
+  #ifndef   __PACKED
+    #define __PACKED                  @packed
+  #endif
+
+
+#else
+  #error Unknown compiler.
+#endif
+
+
+#endif /* __CMSIS_COMPILER_H */
+
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_cp15.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_cp15.h
new file mode 100644
index 00000000..891bec2a
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_cp15.h
@@ -0,0 +1,514 @@
+/**************************************************************************//**
+ * @file     cmsis_cp15.h
+ * @brief    CMSIS compiler specific macros, functions, instructions
+ * @version  V1.0.1
+ * @date     07. Sep 2017
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2017 ARM Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header   /* treat file as system include file */
+#endif
+
+#ifndef __CMSIS_CP15_H
+#define __CMSIS_CP15_H
+
+/** \brief  Get ACTLR
+    \return               Auxiliary Control register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_ACTLR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 1, 0, 1);
+  return(result);
+}
+
+/** \brief  Set ACTLR
+    \param [in]    actlr  Auxiliary Control value to set
+ */
+__STATIC_FORCEINLINE void __set_ACTLR(uint32_t actlr)
+{
+  __set_CP(15, 0, actlr, 1, 0, 1);
+}
+
+/** \brief  Get CPACR
+    \return               Coprocessor Access Control register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CPACR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 1, 0, 2);
+  return result;
+}
+
+/** \brief  Set CPACR
+    \param [in]    cpacr  Coprocessor Access Control value to set
+ */
+__STATIC_FORCEINLINE void __set_CPACR(uint32_t cpacr)
+{
+  __set_CP(15, 0, cpacr, 1, 0, 2);
+}
+
+/** \brief  Get DFSR
+    \return               Data Fault Status Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_DFSR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 5, 0, 0);
+  return result;
+}
+
+/** \brief  Set DFSR
+    \param [in]    dfsr  Data Fault Status value to set
+ */
+__STATIC_FORCEINLINE void __set_DFSR(uint32_t dfsr)
+{
+  __set_CP(15, 0, dfsr, 5, 0, 0);
+}
+
+/** \brief  Get IFSR
+    \return               Instruction Fault Status Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 5, 0, 1);
+  return result;
+}
+
+/** \brief  Set IFSR
+    \param [in]    ifsr  Instruction Fault Status value to set
+ */
+__STATIC_FORCEINLINE void __set_IFSR(uint32_t ifsr)
+{
+  __set_CP(15, 0, ifsr, 5, 0, 1);
+}
+
+/** \brief  Get ISR
+    \return               Interrupt Status Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_ISR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 12, 1, 0);
+  return result;
+}
+
+/** \brief  Get CBAR
+    \return               Configuration Base Address register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CBAR(void)
+{
+  uint32_t result;
+  __get_CP(15, 4, result, 15, 0, 0);
+  return result;
+}
+
+/** \brief  Get TTBR0
+
+    This function returns the value of the Translation Table Base Register 0.
+
+    \return               Translation Table Base Register 0 value
+ */
+__STATIC_FORCEINLINE uint32_t __get_TTBR0(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 2, 0, 0);
+  return result;
+}
+
+/** \brief  Set TTBR0
+
+    This function assigns the given value to the Translation Table Base Register 0.
+
+    \param [in]    ttbr0  Translation Table Base Register 0 value to set
+ */
+__STATIC_FORCEINLINE void __set_TTBR0(uint32_t ttbr0)
+{
+  __set_CP(15, 0, ttbr0, 2, 0, 0);
+}
+
+/** \brief  Get DACR
+
+    This function returns the value of the Domain Access Control Register.
+
+    \return               Domain Access Control Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_DACR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 3, 0, 0);
+  return result;
+}
+
+/** \brief  Set DACR
+
+    This function assigns the given value to the Domain Access Control Register.
+
+    \param [in]    dacr   Domain Access Control Register value to set
+ */
+__STATIC_FORCEINLINE void __set_DACR(uint32_t dacr)
+{
+  __set_CP(15, 0, dacr, 3, 0, 0);
+}
+
+/** \brief  Set SCTLR
+
+    This function assigns the given value to the System Control Register.
+
+    \param [in]    sctlr  System Control Register value to set
+ */
+__STATIC_FORCEINLINE void __set_SCTLR(uint32_t sctlr)
+{
+  __set_CP(15, 0, sctlr, 1, 0, 0);
+}
+
+/** \brief  Get SCTLR
+    \return               System Control Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_SCTLR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 1, 0, 0);
+  return result;
+}
+
+/** \brief  Set ACTRL
+    \param [in]    actrl  Auxiliary Control Register value to set
+ */
+__STATIC_FORCEINLINE void __set_ACTRL(uint32_t actrl)
+{
+  __set_CP(15, 0, actrl, 1, 0, 1);
+}
+
+/** \brief  Get ACTRL
+    \return               Auxiliary Control Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_ACTRL(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 1, 0, 1);
+  return result;
+}
+
+/** \brief  Get MPIDR
+
+    This function returns the value of the Multiprocessor Affinity Register.
+
+    \return               Multiprocessor Affinity Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_MPIDR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 0, 0, 5);
+  return result;
+}
+
+/** \brief  Get VBAR
+
+    This function returns the value of the Vector Base Address Register.
+
+    \return               Vector Base Address Register
+ */
+__STATIC_FORCEINLINE uint32_t __get_VBAR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 12, 0, 0);
+  return result;
+}
+
+/** \brief  Set VBAR
+
+    This function assigns the given value to the Vector Base Address Register.
+
+    \param [in]    vbar  Vector Base Address Register value to set
+ */
+__STATIC_FORCEINLINE void __set_VBAR(uint32_t vbar)
+{
+  __set_CP(15, 0, vbar, 12, 0, 0);
+}
+
+/** \brief  Get MVBAR
+
+    This function returns the value of the Monitor Vector Base Address Register.
+
+    \return               Monitor Vector Base Address Register
+ */
+__STATIC_FORCEINLINE uint32_t __get_MVBAR(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 12, 0, 1);
+  return result;
+}
+
+/** \brief  Set MVBAR
+
+    This function assigns the given value to the Monitor Vector Base Address Register.
+
+    \param [in]    mvbar  Monitor Vector Base Address Register value to set
+ */
+__STATIC_FORCEINLINE void __set_MVBAR(uint32_t mvbar)
+{
+  __set_CP(15, 0, mvbar, 12, 0, 1);
+}
+
+#if (defined(__CORTEX_A) && (__CORTEX_A == 7U) && \
+    defined(__TIM_PRESENT) && (__TIM_PRESENT == 1U)) || \
+    defined(DOXYGEN)
+
+/** \brief  Set CNTFRQ
+
+  This function assigns the given value to PL1 Physical Timer Counter Frequency Register (CNTFRQ).
+
+  \param [in]    value  CNTFRQ Register value to set
+*/
+__STATIC_FORCEINLINE void __set_CNTFRQ(uint32_t value)
+{
+  __set_CP(15, 0, value, 14, 0, 0);
+}
+
+/** \brief  Get CNTFRQ
+
+    This function returns the value of the PL1 Physical Timer Counter Frequency Register (CNTFRQ).
+
+    \return               CNTFRQ Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CNTFRQ(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 14, 0 , 0);
+  return result;
+}
+
+/** \brief  Set CNTP_TVAL
+
+  This function assigns the given value to PL1 Physical Timer Value Register (CNTP_TVAL).
+
+  \param [in]    value  CNTP_TVAL Register value to set
+*/
+__STATIC_FORCEINLINE void __set_CNTP_TVAL(uint32_t value)
+{
+  __set_CP(15, 0, value, 14, 2, 0);
+}
+
+/** \brief  Get CNTP_TVAL
+
+    This function returns the value of the PL1 Physical Timer Value Register (CNTP_TVAL).
+
+    \return               CNTP_TVAL Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CNTP_TVAL(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 14, 2, 0);
+  return result;
+}
+
+/** \brief  Get CNTPCT
+
+    This function returns the value of the 64 bits PL1 Physical Count Register (CNTPCT).
+
+    \return               CNTPCT Register value
+ */
+__STATIC_FORCEINLINE uint64_t __get_CNTPCT(void)
+{
+  uint64_t result;
+  __get_CP64(15, 0, result, 14);
+  return result;
+}
+
+/** \brief  Set CNTP_CVAL
+
+  This function assigns the given value to 64bits PL1 Physical Timer CompareValue Register (CNTP_CVAL).
+
+  \param [in]    value  CNTP_CVAL Register value to set
+*/
+__STATIC_FORCEINLINE void __set_CNTP_CVAL(uint64_t value)
+{
+  __set_CP64(15, 2, value, 14);
+}
+
+/** \brief  Get CNTP_CVAL
+
+    This function returns the value of the 64 bits PL1 Physical Timer CompareValue Register (CNTP_CVAL).
+
+    \return               CNTP_CVAL Register value
+ */
+__STATIC_FORCEINLINE uint64_t __get_CNTP_CVAL(void)
+{
+  uint64_t result;
+  __get_CP64(15, 2, result, 14);
+  return result;
+}
+
+/** \brief  Set CNTP_CTL
+
+  This function assigns the given value to PL1 Physical Timer Control Register (CNTP_CTL).
+
+  \param [in]    value  CNTP_CTL Register value to set
+*/
+__STATIC_FORCEINLINE void __set_CNTP_CTL(uint32_t value)
+{
+  __set_CP(15, 0, value, 14, 2, 1);
+}
+
+/** \brief  Get CNTP_CTL register
+    \return               CNTP_CTL Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CNTP_CTL(void)
+{
+  uint32_t result;
+  __get_CP(15, 0, result, 14, 2, 1);
+  return result;
+}
+
+#endif
+
+/** \brief  Set TLBIALL
+
+  TLB Invalidate All
+ */
+__STATIC_FORCEINLINE void __set_TLBIALL(uint32_t value)
+{
+  __set_CP(15, 0, value, 8, 7, 0);
+}
+
+/** \brief  Set BPIALL.
+
+  Branch Predictor Invalidate All
+ */
+__STATIC_FORCEINLINE void __set_BPIALL(uint32_t value)
+{
+  __set_CP(15, 0, value, 7, 5, 6);
+}
+
+/** \brief  Set ICIALLU
+
+  Instruction Cache Invalidate All
+ */
+__STATIC_FORCEINLINE void __set_ICIALLU(uint32_t value)
+{
+  __set_CP(15, 0, value, 7, 5, 0);
+}
+
+/** \brief  Set DCCMVAC
+
+  Data cache clean
+ */
+__STATIC_FORCEINLINE void __set_DCCMVAC(uint32_t value)
+{
+  __set_CP(15, 0, value, 7, 10, 1);
+}
+
+/** \brief  Set DCIMVAC
+
+  Data cache invalidate
+ */
+__STATIC_FORCEINLINE void __set_DCIMVAC(uint32_t value)
+{
+  __set_CP(15, 0, value, 7, 6, 1);
+}
+
+/** \brief  Set DCCIMVAC
+
+  Data cache clean and invalidate
+ */
+__STATIC_FORCEINLINE void __set_DCCIMVAC(uint32_t value)
+{
+  __set_CP(15, 0, value, 7, 14, 1);
+}
+
+/** \brief  Set CSSELR
+ */
+__STATIC_FORCEINLINE void __set_CSSELR(uint32_t value)
+{
+//  __ASM volatile("MCR p15, 2, %0, c0, c0, 0" : : "r"(value) : "memory");
+  __set_CP(15, 2, value, 0, 0, 0);
+}
+
+/** \brief  Get CSSELR
+    \return CSSELR Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CSSELR(void)
+{
+  uint32_t result;
+//  __ASM volatile("MRC p15, 2, %0, c0, c0, 0" : "=r"(result) : : "memory");
+  __get_CP(15, 2, result, 0, 0, 0);
+  return result;
+}
+
+/** \brief  Set CCSIDR
+    \deprecated CCSIDR itself is read-only. Use __set_CSSELR to select cache level instead.
+ */
+CMSIS_DEPRECATED
+__STATIC_FORCEINLINE void __set_CCSIDR(uint32_t value)
+{
+  __set_CSSELR(value);
+}
+
+/** \brief  Get CCSIDR
+    \return CCSIDR Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CCSIDR(void)
+{
+  uint32_t result;
+//  __ASM volatile("MRC p15, 1, %0, c0, c0, 0" : "=r"(result) : : "memory");
+  __get_CP(15, 1, result, 0, 0, 0);
+  return result;
+}
+
+/** \brief  Get CLIDR
+    \return CLIDR Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
+{
+  uint32_t result;
+//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
+  __get_CP(15, 1, result, 0, 0, 1);
+  return result;
+}
+
+/** \brief  Set DCISW
+ */
+__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
+{
+//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
+  __set_CP(15, 0, value, 7, 6, 2);
+}
+
+/** \brief  Set DCCSW
+ */
+__STATIC_FORCEINLINE void __set_DCCSW(uint32_t value)
+{
+//  __ASM volatile("MCR p15, 0, %0, c7, c10, 2" : : "r"(value) : "memory")
+  __set_CP(15, 0, value, 7, 10, 2);
+}
+
+/** \brief  Set DCCISW
+ */
+__STATIC_FORCEINLINE void __set_DCCISW(uint32_t value)
+{
+//  __ASM volatile("MCR p15, 0, %0, c7, c14, 2" : : "r"(value) : "memory")
+  __set_CP(15, 0, value, 7, 14, 2);
+}
+
+#endif
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_gcc.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_gcc.h
new file mode 100644
index 00000000..5b32b9e7
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_gcc.h
@@ -0,0 +1,698 @@
+/**************************************************************************//**
+ * @file     cmsis_gcc.h
+ * @brief    CMSIS compiler specific macros, functions, instructions
+ * @version  V1.0.2
+ * @date     09. April 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef __CMSIS_GCC_H
+#define __CMSIS_GCC_H
+
+/* ignore some GCC warnings */
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wsign-conversion"
+#pragma GCC diagnostic ignored "-Wconversion"
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+
+/* Fallback for __has_builtin */
+#ifndef __has_builtin
+  #define __has_builtin(x) (0)
+#endif
+
+/* CMSIS compiler specific defines */
+#ifndef   __ASM
+  #define __ASM                                  asm
+#endif
+#ifndef   __INLINE
+  #define __INLINE                               inline
+#endif
+#ifndef   __FORCEINLINE
+  #define __FORCEINLINE                          __attribute__((always_inline))
+#endif
+#ifndef   __STATIC_INLINE
+  #define __STATIC_INLINE                        static inline
+#endif
+#ifndef   __STATIC_FORCEINLINE
+  #define __STATIC_FORCEINLINE                   __attribute__((always_inline)) static inline
+#endif
+#ifndef   __NO_RETURN
+  #define __NO_RETURN                            __attribute__((__noreturn__))
+#endif
+#ifndef   CMSIS_DEPRECATED
+ #define  CMSIS_DEPRECATED                       __attribute__((deprecated))
+#endif
+#ifndef   __USED
+  #define __USED                                 __attribute__((used))
+#endif
+#ifndef   __WEAK
+  #define __WEAK                                 __attribute__((weak))
+#endif
+#ifndef   __PACKED
+  #define __PACKED                               __attribute__((packed, aligned(1)))
+#endif
+#ifndef   __PACKED_STRUCT
+  #define __PACKED_STRUCT                        struct __attribute__((packed, aligned(1)))
+#endif
+#ifndef   __UNALIGNED_UINT16_WRITE
+  #pragma GCC diagnostic push
+  #pragma GCC diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT16_WRITE)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT16_WRITE */
+  __PACKED_STRUCT T_UINT16_WRITE { uint16_t v; };
+  #pragma GCC diagnostic pop
+  #define __UNALIGNED_UINT16_WRITE(addr, val)    (void)((((struct T_UINT16_WRITE *)(void *)(addr))->v) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT16_READ
+  #pragma GCC diagnostic push
+  #pragma GCC diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT16_READ)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT16_READ */
+  __PACKED_STRUCT T_UINT16_READ { uint16_t v; };
+  #pragma GCC diagnostic pop
+  #define __UNALIGNED_UINT16_READ(addr)          (((const struct T_UINT16_READ *)(const void *)(addr))->v)
+#endif
+#ifndef   __UNALIGNED_UINT32_WRITE
+  #pragma GCC diagnostic push
+  #pragma GCC diagnostic ignored "-Wpacked"
+/*lint -esym(9058, T_UINT32_WRITE)*/ /* disable MISRA 2012 Rule 2.4 for T_UINT32_WRITE */
+  __PACKED_STRUCT T_UINT32_WRITE { uint32_t v; };
+  #pragma GCC diagnostic pop
+  #define __UNALIGNED_UINT32_WRITE(addr, val)    (void)((((struct T_UINT32_WRITE *)(void *)(addr))->v) = (val))
+#endif
+#ifndef   __UNALIGNED_UINT32_READ
+  #pragma GCC diagnostic push
+  #pragma GCC diagnostic ignored "-Wpacked"
+  __PACKED_STRUCT T_UINT32_READ { uint32_t v; };
+  #pragma GCC diagnostic pop
+  #define __UNALIGNED_UINT32_READ(addr)          (((const struct T_UINT32_READ *)(const void *)(addr))->v)
+#endif
+#ifndef   __ALIGNED
+  #define __ALIGNED(x)                           __attribute__((aligned(x)))
+#endif
+#ifndef   __RESTRICT
+  #define __RESTRICT                             __restrict
+#endif
+
+/* ##########################  Core Instruction Access  ######################### */
+/**
+  \brief   No Operation
+ */
+#define __NOP()                             __ASM volatile ("nop")
+
+/**
+  \brief   Wait For Interrupt
+ */
+#define __WFI()                             __ASM volatile ("wfi")
+
+/**
+  \brief   Wait For Event
+ */
+#define __WFE()                             __ASM volatile ("wfe")
+
+/**
+  \brief   Send Event
+ */
+#define __SEV()                             __ASM volatile ("sev")
+
+/**
+  \brief   Instruction Synchronization Barrier
+  \details Instruction Synchronization Barrier flushes the pipeline in the processor,
+           so that all instructions following the ISB are fetched from cache or memory,
+           after the instruction has been completed.
+ */
+__STATIC_FORCEINLINE  void __ISB(void)
+{
+  __ASM volatile ("isb 0xF":::"memory");
+}
+
+
+/**
+  \brief   Data Synchronization Barrier
+  \details Acts as a special kind of Data Memory Barrier.
+           It completes when all explicit memory accesses before this instruction complete.
+ */
+__STATIC_FORCEINLINE  void __DSB(void)
+{
+  __ASM volatile ("dsb 0xF":::"memory");
+}
+
+/**
+  \brief   Data Memory Barrier
+  \details Ensures the apparent order of the explicit memory operations before
+           and after the instruction, without ensuring their completion.
+ */
+__STATIC_FORCEINLINE  void __DMB(void)
+{
+  __ASM volatile ("dmb 0xF":::"memory");
+}
+
+/**
+  \brief   Reverse byte order (32 bit)
+  \details Reverses the byte order in unsigned integer value. For example, 0x12345678 becomes 0x78563412.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+__STATIC_FORCEINLINE  uint32_t __REV(uint32_t value)
+{
+#if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ >= 5)
+  return __builtin_bswap32(value);
+#else
+  uint32_t result;
+
+  __ASM volatile ("rev %0, %1" : "=r" (result) : "r" (value) );
+  return result;
+#endif
+}
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order within each halfword of a word. For example, 0x12345678 becomes 0x34127856.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+#ifndef __NO_EMBEDDED_ASM
+__attribute__((section(".rev16_text"))) __STATIC_INLINE uint32_t __REV16(uint32_t value)
+{
+  uint32_t result;
+  __ASM volatile("rev16 %0, %1" : "=r" (result) : "r" (value));
+  return result;
+}
+#endif
+
+/**
+  \brief   Reverse byte order (16 bit)
+  \details Reverses the byte order in a 16-bit value and returns the signed 16-bit result. For example, 0x0080 becomes 0x8000.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+__STATIC_FORCEINLINE  int16_t __REVSH(int16_t value)
+{
+#if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)
+  return (int16_t)__builtin_bswap16(value);
+#else
+  int16_t result;
+
+  __ASM volatile ("revsh %0, %1" : "=r" (result) : "r" (value) );
+  return result;
+#endif
+}
+
+/**
+  \brief   Rotate Right in unsigned value (32 bit)
+  \details Rotate Right (immediate) provides the value of the contents of a register rotated by a variable number of bits.
+  \param [in]    op1  Value to rotate
+  \param [in]    op2  Number of Bits to rotate
+  \return               Rotated value
+ */
+__STATIC_FORCEINLINE  uint32_t __ROR(uint32_t op1, uint32_t op2)
+{
+  op2 %= 32U;
+  if (op2 == 0U) {
+    return op1;
+  }
+  return (op1 >> op2) | (op1 << (32U - op2));
+}
+
+
+/**
+  \brief   Breakpoint
+  \param [in]    value  is ignored by the processor.
+                 If required, a debugger can use it to store additional information about the breakpoint.
+ */
+#define __BKPT(value)                       __ASM volatile ("bkpt "#value)
+
+/**
+  \brief   Reverse bit order of value
+  \details Reverses the bit order of the given value.
+  \param [in]    value  Value to reverse
+  \return               Reversed value
+ */
+__STATIC_FORCEINLINE  uint32_t __RBIT(uint32_t value)
+{
+  uint32_t result;
+
+#if ((defined (__ARM_ARCH_7M__      ) && (__ARM_ARCH_7M__      == 1)) || \
+     (defined (__ARM_ARCH_7EM__     ) && (__ARM_ARCH_7EM__     == 1)) || \
+     (defined (__ARM_ARCH_8M_MAIN__ ) && (__ARM_ARCH_8M_MAIN__ == 1))    )
+   __ASM volatile ("rbit %0, %1" : "=r" (result) : "r" (value) );
+#else
+  int32_t s = (4U /*sizeof(v)*/ * 8U) - 1U; /* extra shift needed at end */
+
+  result = value;                      /* r will be reversed bits of v; first get LSB of v */
+  for (value >>= 1U; value; value >>= 1U)
+  {
+    result <<= 1U;
+    result |= value & 1U;
+    s--;
+  }
+  result <<= s;                        /* shift when v's highest bits are zero */
+#endif
+  return result;
+}
+
+/**
+  \brief   Count leading zeros
+  \param [in]  value  Value to count the leading zeros
+  \return             number of leading zeros in value
+ */
+__STATIC_FORCEINLINE uint8_t __CLZ(uint32_t value)
+{
+  /* Even though __builtin_clz produces a CLZ instruction on ARM, formally
+     __builtin_clz(0) is undefined behaviour, so handle this case specially.
+     This guarantees ARM-compatible results if happening to compile on a non-ARM
+     target, and ensures the compiler doesn't decide to activate any
+     optimisations using the logic "value was passed to __builtin_clz, so it
+     is non-zero".
+     ARM GCC 7.3 and possibly earlier will optimise this test away, leaving a
+     single CLZ instruction.
+   */
+  if (value == 0U)
+  {
+    return 32U;
+  }
+  return __builtin_clz(value);
+}
+
+/**
+  \brief   LDR Exclusive (8 bit)
+  \details Executes a exclusive LDR instruction for 8 bit value.
+  \param [in]    ptr  Pointer to data
+  \return             value of type uint8_t at (*ptr)
+ */
+__STATIC_FORCEINLINE  uint8_t __LDREXB(volatile uint8_t *addr)
+{
+    uint32_t result;
+
+#if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)
+   __ASM volatile ("ldrexb %0, %1" : "=r" (result) : "Q" (*addr) );
+#else
+    /* Prior to GCC 4.8, "Q" will be expanded to [rx, #0] which is not
+       accepted by assembler. So has to use following less efficient pattern.
+    */
+   __ASM volatile ("ldrexb %0, [%1]" : "=r" (result) : "r" (addr) : "memory" );
+#endif
+   return ((uint8_t) result);    /* Add explicit type cast here */
+}
+
+
+/**
+  \brief   LDR Exclusive (16 bit)
+  \details Executes a exclusive LDR instruction for 16 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint16_t at (*ptr)
+ */
+__STATIC_FORCEINLINE  uint16_t __LDREXH(volatile uint16_t *addr)
+{
+    uint32_t result;
+
+#if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)
+   __ASM volatile ("ldrexh %0, %1" : "=r" (result) : "Q" (*addr) );
+#else
+    /* Prior to GCC 4.8, "Q" will be expanded to [rx, #0] which is not
+       accepted by assembler. So has to use following less efficient pattern.
+    */
+   __ASM volatile ("ldrexh %0, [%1]" : "=r" (result) : "r" (addr) : "memory" );
+#endif
+   return ((uint16_t) result);    /* Add explicit type cast here */
+}
+
+
+/**
+  \brief   LDR Exclusive (32 bit)
+  \details Executes a exclusive LDR instruction for 32 bit values.
+  \param [in]    ptr  Pointer to data
+  \return        value of type uint32_t at (*ptr)
+ */
+__STATIC_FORCEINLINE  uint32_t __LDREXW(volatile uint32_t *addr)
+{
+    uint32_t result;
+
+   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
+   return(result);
+}
+
+
+/**
+  \brief   STR Exclusive (8 bit)
+  \details Executes a exclusive STR instruction for 8 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+__STATIC_FORCEINLINE  uint32_t __STREXB(uint8_t value, volatile uint8_t *addr)
+{
+   uint32_t result;
+
+   __ASM volatile ("strexb %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" ((uint32_t)value) );
+   return(result);
+}
+
+
+/**
+  \brief   STR Exclusive (16 bit)
+  \details Executes a exclusive STR instruction for 16 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+__STATIC_FORCEINLINE  uint32_t __STREXH(uint16_t value, volatile uint16_t *addr)
+{
+   uint32_t result;
+
+   __ASM volatile ("strexh %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" ((uint32_t)value) );
+   return(result);
+}
+
+
+/**
+  \brief   STR Exclusive (32 bit)
+  \details Executes a exclusive STR instruction for 32 bit values.
+  \param [in]  value  Value to store
+  \param [in]    ptr  Pointer to location
+  \return          0  Function succeeded
+  \return          1  Function failed
+ */
+__STATIC_FORCEINLINE  uint32_t __STREXW(uint32_t value, volatile uint32_t *addr)
+{
+   uint32_t result;
+
+   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
+   return(result);
+}
+
+
+/**
+  \brief   Remove the exclusive lock
+  \details Removes the exclusive lock which is created by LDREX.
+ */
+__STATIC_FORCEINLINE  void __CLREX(void)
+{
+  __ASM volatile ("clrex" ::: "memory");
+}
+
+/**
+  \brief   Signed Saturate
+  \details Saturates a signed value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (1..32)
+  \return             Saturated value
+ */
+#define __SSAT(ARG1,ARG2) \
+__extension__ \
+({                          \
+  int32_t __RES, __ARG1 = (ARG1); \
+  __ASM ("ssat %0, %1, %2" : "=r" (__RES) :  "I" (ARG2), "r" (__ARG1) ); \
+  __RES; \
+ })
+
+
+/**
+  \brief   Unsigned Saturate
+  \details Saturates an unsigned value.
+  \param [in]  value  Value to be saturated
+  \param [in]    sat  Bit position to saturate to (0..31)
+  \return             Saturated value
+ */
+#define __USAT(ARG1,ARG2) \
+__extension__ \
+({                          \
+  uint32_t __RES, __ARG1 = (ARG1); \
+  __ASM ("usat %0, %1, %2" : "=r" (__RES) :  "I" (ARG2), "r" (__ARG1) ); \
+  __RES; \
+ })
+
+/* ###########################  Core Function Access  ########################### */
+
+/**
+  \brief   Enable IRQ Interrupts
+  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
+           Can only be executed in Privileged modes.
+ */
+__STATIC_FORCEINLINE void __enable_irq(void)
+{
+  __ASM volatile ("cpsie i" : : : "memory");
+}
+
+/**
+  \brief   Disable IRQ Interrupts
+  \details Disables IRQ interrupts by setting the I-bit in the CPSR.
+  Can only be executed in Privileged modes.
+ */
+__STATIC_FORCEINLINE  void __disable_irq(void)
+{
+  __ASM volatile ("cpsid i" : : : "memory");
+}
+
+/**
+  \brief   Get FPSCR
+  \details Returns the current value of the Floating Point Status/Control register.
+  \return Floating Point Status/Control register value
+*/
+__STATIC_FORCEINLINE  uint32_t __get_FPSCR(void)
+{
+  #if ((defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)) && \
+       (defined (__FPU_USED   ) && (__FPU_USED    == 1U))     )
+  #if __has_builtin(__builtin_arm_get_fpscr) 
+  // Re-enable using built-in when GCC has been fixed
+  // || (__GNUC__ > 7) || (__GNUC__ == 7 && __GNUC_MINOR__ >= 2)
+    /* see https://gcc.gnu.org/ml/gcc-patches/2017-04/msg00443.html */
+    return __builtin_arm_get_fpscr();
+  #else
+    uint32_t result;
+
+    __ASM volatile ("VMRS %0, fpscr" : "=r" (result) );
+    return(result);
+  #endif
+  #else
+    return(0U);
+  #endif
+}
+
+/**
+  \brief   Set FPSCR
+  \details Assigns the given value to the Floating Point Status/Control register.
+  \param [in] fpscr  Floating Point Status/Control value to set
+*/
+__STATIC_FORCEINLINE void __set_FPSCR(uint32_t fpscr)
+{
+  #if ((defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)) && \
+       (defined (__FPU_USED   ) && (__FPU_USED    == 1U))     )
+  #if __has_builtin(__builtin_arm_set_fpscr)
+  // Re-enable using built-in when GCC has been fixed
+  // || (__GNUC__ > 7) || (__GNUC__ == 7 && __GNUC_MINOR__ >= 2)
+    /* see https://gcc.gnu.org/ml/gcc-patches/2017-04/msg00443.html */
+    __builtin_arm_set_fpscr(fpscr);
+  #else
+    __ASM volatile ("VMSR fpscr, %0" : : "r" (fpscr) : "vfpcc", "memory");
+  #endif
+  #else
+    (void)fpscr;
+  #endif
+}
+
+/** \brief  Get CPSR Register
+    \return               CPSR Register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_CPSR(void)
+{
+  uint32_t result;
+  __ASM volatile("MRS %0, cpsr" : "=r" (result) );
+  return(result);
+}
+
+/** \brief  Set CPSR Register
+    \param [in]    cpsr  CPSR value to set
+ */
+__STATIC_FORCEINLINE void __set_CPSR(uint32_t cpsr)
+{
+__ASM volatile ("MSR cpsr, %0" : : "r" (cpsr) : "memory");
+}
+
+/** \brief  Get Mode
+    \return                Processor Mode
+ */
+__STATIC_FORCEINLINE uint32_t __get_mode(void)
+{
+    return (__get_CPSR() & 0x1FU);
+}
+
+/** \brief  Set Mode
+    \param [in]    mode  Mode value to set
+ */
+__STATIC_FORCEINLINE void __set_mode(uint32_t mode)
+{
+  __ASM volatile("MSR  cpsr_c, %0" : : "r" (mode) : "memory");
+}
+
+/** \brief  Get Stack Pointer
+    \return Stack Pointer value
+ */
+__STATIC_FORCEINLINE uint32_t __get_SP(void)
+{
+  uint32_t result;
+  __ASM volatile("MOV  %0, sp" : "=r" (result) : : "memory");
+  return result;
+}
+
+/** \brief  Set Stack Pointer
+    \param [in]    stack  Stack Pointer value to set
+ */
+__STATIC_FORCEINLINE void __set_SP(uint32_t stack)
+{
+  __ASM volatile("MOV  sp, %0" : : "r" (stack) : "memory");
+}
+
+/** \brief  Get USR/SYS Stack Pointer
+    \return USR/SYS Stack Pointer value
+ */
+__STATIC_FORCEINLINE uint32_t __get_SP_usr(void)
+{
+  uint32_t cpsr = __get_CPSR();
+  uint32_t result;
+  __ASM volatile(
+    "CPS     #0x1F  \n"
+    "MOV     %0, sp   " : "=r"(result) : : "memory"
+   );
+  __set_CPSR(cpsr);
+  __ISB();
+  return result;
+}
+
+/** \brief  Set USR/SYS Stack Pointer
+    \param [in]    topOfProcStack  USR/SYS Stack Pointer value to set
+ */
+__STATIC_FORCEINLINE void __set_SP_usr(uint32_t topOfProcStack)
+{
+  uint32_t cpsr = __get_CPSR();
+  __ASM volatile(
+    "CPS     #0x1F  \n"
+    "MOV     sp, %0   " : : "r" (topOfProcStack) : "memory"
+   );
+  __set_CPSR(cpsr);
+  __ISB();
+}
+
+/** \brief  Get FPEXC
+    \return               Floating Point Exception Control register value
+ */
+__STATIC_FORCEINLINE uint32_t __get_FPEXC(void)
+{
+#if (__FPU_PRESENT == 1)
+  uint32_t result;
+  __ASM volatile("VMRS %0, fpexc" : "=r" (result) );
+  return(result);
+#else
+  return(0);
+#endif
+}
+
+/** \brief  Set FPEXC
+    \param [in]    fpexc  Floating Point Exception Control value to set
+ */
+__STATIC_FORCEINLINE void __set_FPEXC(uint32_t fpexc)
+{
+#if (__FPU_PRESENT == 1)
+  __ASM volatile ("VMSR fpexc, %0" : : "r" (fpexc) : "memory");
+#endif
+}
+
+/*
+ * Include common core functions to access Coprocessor 15 registers
+ */
+
+#define __get_CP(cp, op1, Rt, CRn, CRm, op2) __ASM volatile("MRC p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : "=r" (Rt) : : "memory" )
+#define __set_CP(cp, op1, Rt, CRn, CRm, op2) __ASM volatile("MCR p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : : "r" (Rt) : "memory" )
+#define __get_CP64(cp, op1, Rt, CRm) __ASM volatile("MRRC p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : "=r" (Rt) : : "memory" )
+#define __set_CP64(cp, op1, Rt, CRm) __ASM volatile("MCRR p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : : "r" (Rt) : "memory" )
+
+#include "cmsis_cp15.h"
+
+/** \brief  Enable Floating Point Unit
+
+  Critical section, called from undef handler, so systick is disabled
+ */
+__STATIC_INLINE void __FPU_Enable(void)
+{
+  __ASM volatile(
+    //Permit access to VFP/NEON, registers by modifying CPACR
+    "        MRC     p15,0,R1,c1,c0,2  \n"
+    "        ORR     R1,R1,#0x00F00000 \n"
+    "        MCR     p15,0,R1,c1,c0,2  \n"
+
+    //Ensure that subsequent instructions occur in the context of VFP/NEON access permitted
+    "        ISB                       \n"
+
+    //Enable VFP/NEON
+    "        VMRS    R1,FPEXC          \n"
+    "        ORR     R1,R1,#0x40000000 \n"
+    "        VMSR    FPEXC,R1          \n"
+
+    //Initialise VFP/NEON registers to 0
+    "        MOV     R2,#0             \n"
+
+    //Initialise D16 registers to 0
+    "        VMOV    D0, R2,R2         \n"
+    "        VMOV    D1, R2,R2         \n"
+    "        VMOV    D2, R2,R2         \n"
+    "        VMOV    D3, R2,R2         \n"
+    "        VMOV    D4, R2,R2         \n"
+    "        VMOV    D5, R2,R2         \n"
+    "        VMOV    D6, R2,R2         \n"
+    "        VMOV    D7, R2,R2         \n"
+    "        VMOV    D8, R2,R2         \n"
+    "        VMOV    D9, R2,R2         \n"
+    "        VMOV    D10,R2,R2         \n"
+    "        VMOV    D11,R2,R2         \n"
+    "        VMOV    D12,R2,R2         \n"
+    "        VMOV    D13,R2,R2         \n"
+    "        VMOV    D14,R2,R2         \n"
+    "        VMOV    D15,R2,R2         \n"
+
+#if (defined(__ARM_NEON) && (__ARM_NEON == 1))
+    //Initialise D32 registers to 0
+    "        VMOV    D16,R2,R2         \n"
+    "        VMOV    D17,R2,R2         \n"
+    "        VMOV    D18,R2,R2         \n"
+    "        VMOV    D19,R2,R2         \n"
+    "        VMOV    D20,R2,R2         \n"
+    "        VMOV    D21,R2,R2         \n"
+    "        VMOV    D22,R2,R2         \n"
+    "        VMOV    D23,R2,R2         \n"
+    "        VMOV    D24,R2,R2         \n"
+    "        VMOV    D25,R2,R2         \n"
+    "        VMOV    D26,R2,R2         \n"
+    "        VMOV    D27,R2,R2         \n"
+    "        VMOV    D28,R2,R2         \n"
+    "        VMOV    D29,R2,R2         \n"
+    "        VMOV    D30,R2,R2         \n"
+    "        VMOV    D31,R2,R2         \n"
+#endif
+
+    //Initialise FPSCR to a known state
+    "        VMRS    R2,FPSCR          \n"
+    "        LDR     R3,=0x00086060    \n" //Mask off all bits that do not have to be preserved. Non-preserved bits can/should be zero.
+    "        AND     R2,R2,R3          \n"
+    "        VMSR    FPSCR,R2            "
+  );
+}
+
+#pragma GCC diagnostic pop
+
+#endif /* __CMSIS_GCC_H */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_iccarm.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_iccarm.h
new file mode 100644
index 00000000..51ff7c4b
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_iccarm.h
@@ -0,0 +1,564 @@
+/**************************************************************************//**
+ * @file     cmsis_iccarm.h
+ * @brief    CMSIS compiler ICCARM (IAR Compiler for Arm) header file
+ * @version  V5.0.6
+ * @date     02. March 2018
+ ******************************************************************************/
+
+//------------------------------------------------------------------------------
+//
+// Copyright (c) 2017-2018 IAR Systems
+//
+// Licensed under the Apache License, Version 2.0 (the "License")
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+//------------------------------------------------------------------------------
+
+
+#ifndef __CMSIS_ICCARM_H__
+#define __CMSIS_ICCARM_H__
+
+#ifndef __ICCARM__
+  #error This file should only be compiled by ICCARM
+#endif
+
+#pragma system_include
+
+#define __IAR_FT _Pragma("inline=forced") __intrinsic
+
+#if (__VER__ >= 8000000)
+  #define __ICCARM_V8 1
+#else
+  #define __ICCARM_V8 0
+#endif
+
+#pragma language=extended
+
+#ifndef __ALIGNED
+  #if __ICCARM_V8
+    #define __ALIGNED(x) __attribute__((aligned(x)))
+  #elif (__VER__ >= 7080000)
+    /* Needs IAR language extensions */
+    #define __ALIGNED(x) __attribute__((aligned(x)))
+  #else
+    #warning No compiler specific solution for __ALIGNED.__ALIGNED is ignored.
+    #define __ALIGNED(x)
+  #endif
+#endif
+
+
+/* Define compiler macros for CPU architecture, used in CMSIS 5.
+ */
+#if __ARM_ARCH_7A__
+/* Macro already defined */
+#else
+  #if defined(__ARM7A__)
+    #define __ARM_ARCH_7A__ 1
+  #endif
+#endif
+
+#ifndef __ASM
+  #define __ASM __asm
+#endif
+
+#ifndef __INLINE
+  #define __INLINE inline
+#endif
+
+#ifndef   __NO_RETURN
+  #if __ICCARM_V8
+    #define __NO_RETURN __attribute__((__noreturn__))
+  #else
+    #define __NO_RETURN _Pragma("object_attribute=__noreturn")
+  #endif
+#endif
+
+#ifndef   __PACKED
+  /* Needs IAR language extensions */
+  #if __ICCARM_V8
+    #define __PACKED __attribute__((packed, aligned(1)))
+  #else
+    #define __PACKED __packed
+  #endif
+#endif
+
+#ifndef   __PACKED_STRUCT
+  /* Needs IAR language extensions */
+  #if __ICCARM_V8
+    #define __PACKED_STRUCT struct __attribute__((packed, aligned(1)))
+  #else
+    #define __PACKED_STRUCT __packed struct
+  #endif
+#endif
+
+#ifndef   __PACKED_UNION
+  /* Needs IAR language extensions */
+  #if __ICCARM_V8
+    #define __PACKED_UNION union __attribute__((packed, aligned(1)))
+  #else
+    #define __PACKED_UNION __packed union
+  #endif
+#endif
+
+#ifndef   __RESTRICT
+  #if __ICCARM_V8
+    #define __RESTRICT            __restrict
+  #else
+    /* Needs IAR language extensions */
+    #define __RESTRICT            restrict
+  #endif
+#endif
+
+#ifndef   __STATIC_INLINE
+  #define __STATIC_INLINE       static inline
+#endif
+
+#ifndef   __FORCEINLINE
+  #define __FORCEINLINE         _Pragma("inline=forced")
+#endif
+
+#ifndef   __STATIC_FORCEINLINE
+  #define __STATIC_FORCEINLINE  __FORCEINLINE __STATIC_INLINE
+#endif
+
+#ifndef   CMSIS_DEPRECATED
+  #define CMSIS_DEPRECATED      __attribute__((deprecated))
+#endif
+
+#ifndef __UNALIGNED_UINT16_READ
+  #pragma language=save
+  #pragma language=extended
+  __IAR_FT uint16_t __iar_uint16_read(void const *ptr)
+  {
+    return *(__packed uint16_t*)(ptr);
+  }
+  #pragma language=restore
+  #define __UNALIGNED_UINT16_READ(PTR) __iar_uint16_read(PTR)
+#endif
+
+
+#ifndef __UNALIGNED_UINT16_WRITE
+  #pragma language=save
+  #pragma language=extended
+  __IAR_FT void __iar_uint16_write(void const *ptr, uint16_t val)
+  {
+    *(__packed uint16_t*)(ptr) = val;;
+  }
+  #pragma language=restore
+  #define __UNALIGNED_UINT16_WRITE(PTR,VAL) __iar_uint16_write(PTR,VAL)
+#endif
+
+#ifndef __UNALIGNED_UINT32_READ
+  #pragma language=save
+  #pragma language=extended
+  __IAR_FT uint32_t __iar_uint32_read(void const *ptr)
+  {
+    return *(__packed uint32_t*)(ptr);
+  }
+  #pragma language=restore
+  #define __UNALIGNED_UINT32_READ(PTR) __iar_uint32_read(PTR)
+#endif
+
+#ifndef __UNALIGNED_UINT32_WRITE
+  #pragma language=save
+  #pragma language=extended
+  __IAR_FT void __iar_uint32_write(void const *ptr, uint32_t val)
+  {
+    *(__packed uint32_t*)(ptr) = val;;
+  }
+  #pragma language=restore
+  #define __UNALIGNED_UINT32_WRITE(PTR,VAL) __iar_uint32_write(PTR,VAL)
+#endif
+
+#if 0
+#ifndef __UNALIGNED_UINT32   /* deprecated */
+  #pragma language=save
+  #pragma language=extended
+  __packed struct  __iar_u32 { uint32_t v; };
+  #pragma language=restore
+  #define __UNALIGNED_UINT32(PTR) (((struct __iar_u32 *)(PTR))->v)
+#endif
+#endif
+
+#ifndef   __USED
+  #if __ICCARM_V8
+    #define __USED __attribute__((used))
+  #else
+    #define __USED _Pragma("__root")
+  #endif
+#endif
+
+#ifndef   __WEAK
+  #if __ICCARM_V8
+    #define __WEAK __attribute__((weak))
+  #else
+    #define __WEAK _Pragma("__weak")
+  #endif
+#endif
+
+
+#ifndef __ICCARM_INTRINSICS_VERSION__
+  #define __ICCARM_INTRINSICS_VERSION__  0
+#endif
+
+#if __ICCARM_INTRINSICS_VERSION__ == 2
+
+  #if defined(__CLZ)
+    #undef __CLZ
+  #endif
+  #if defined(__REVSH)
+    #undef __REVSH
+  #endif
+  #if defined(__RBIT)
+    #undef __RBIT
+  #endif
+  #if defined(__SSAT)
+    #undef __SSAT
+  #endif
+  #if defined(__USAT)
+    #undef __USAT
+  #endif
+
+  #include "iccarm_builtin.h"
+
+  #define __enable_irq        __iar_builtin_enable_interrupt
+  #define __disable_irq       __iar_builtin_disable_interrupt
+  #define __enable_fault_irq    __iar_builtin_enable_fiq
+  #define __disable_fault_irq   __iar_builtin_disable_fiq
+  #define __arm_rsr           __iar_builtin_rsr
+  #define __arm_wsr           __iar_builtin_wsr
+
+  #if __FPU_PRESENT
+    #define __get_FPSCR()             (__arm_rsr("FPSCR"))
+  #else
+    #define __get_FPSCR()             ( 0 )
+  #endif
+
+  #define __set_FPSCR(VALUE)          (__arm_wsr("FPSCR", VALUE))
+
+  #define __get_CPSR()                (__arm_rsr("CPSR"))
+  #define __get_mode()                (__get_CPSR() & 0x1FU)
+
+  #define __set_CPSR(VALUE)           (__arm_wsr("CPSR", (VALUE)))
+  #define __set_mode(VALUE)           (__arm_wsr("CPSR_c", (VALUE)))
+
+
+  #define __get_FPEXC()       (__arm_rsr("FPEXC"))
+  #define __set_FPEXC(VALUE)    (__arm_wsr("FPEXC", VALUE))
+
+  #define __get_CP(cp, op1, RT, CRn, CRm, op2) \
+    ((RT) = __arm_rsr("p" # cp ":" # op1 ":c" # CRn ":c" # CRm ":" # op2))
+
+  #define __set_CP(cp, op1, RT, CRn, CRm, op2) \
+    (__arm_wsr("p" # cp ":" # op1 ":c" # CRn ":c" # CRm ":" # op2, (RT)))
+
+  #define __get_CP64(cp, op1, Rt, CRm) \
+    __ASM volatile("MRRC p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : "=r" (Rt) : : "memory" )
+
+  #define __set_CP64(cp, op1, Rt, CRm) \
+    __ASM volatile("MCRR p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : : "r" (Rt) : "memory" )
+
+  #include "cmsis_cp15.h"
+
+  #define __NOP     __iar_builtin_no_operation
+
+  #define __CLZ     __iar_builtin_CLZ
+  #define __CLREX   __iar_builtin_CLREX
+
+  #define __DMB     __iar_builtin_DMB
+  #define __DSB     __iar_builtin_DSB
+  #define __ISB     __iar_builtin_ISB
+
+  #define __LDREXB  __iar_builtin_LDREXB
+  #define __LDREXH  __iar_builtin_LDREXH
+  #define __LDREXW  __iar_builtin_LDREX
+
+  #define __RBIT    __iar_builtin_RBIT
+  #define __REV     __iar_builtin_REV
+  #define __REV16   __iar_builtin_REV16
+
+  __IAR_FT int16_t __REVSH(int16_t val)
+  {
+    return (int16_t) __iar_builtin_REVSH(val);
+  }
+
+  #define __ROR     __iar_builtin_ROR
+  #define __RRX     __iar_builtin_RRX
+
+  #define __SEV     __iar_builtin_SEV
+
+  #define __SSAT    __iar_builtin_SSAT
+
+  #define __STREXB  __iar_builtin_STREXB
+  #define __STREXH  __iar_builtin_STREXH
+  #define __STREXW  __iar_builtin_STREX
+
+  #define __USAT    __iar_builtin_USAT
+
+  #define __WFE     __iar_builtin_WFE
+  #define __WFI     __iar_builtin_WFI
+
+  #define __SADD8   __iar_builtin_SADD8
+  #define __QADD8   __iar_builtin_QADD8
+  #define __SHADD8  __iar_builtin_SHADD8
+  #define __UADD8   __iar_builtin_UADD8
+  #define __UQADD8  __iar_builtin_UQADD8
+  #define __UHADD8  __iar_builtin_UHADD8
+  #define __SSUB8   __iar_builtin_SSUB8
+  #define __QSUB8   __iar_builtin_QSUB8
+  #define __SHSUB8  __iar_builtin_SHSUB8
+  #define __USUB8   __iar_builtin_USUB8
+  #define __UQSUB8  __iar_builtin_UQSUB8
+  #define __UHSUB8  __iar_builtin_UHSUB8
+  #define __SADD16  __iar_builtin_SADD16
+  #define __QADD16  __iar_builtin_QADD16
+  #define __SHADD16 __iar_builtin_SHADD16
+  #define __UADD16  __iar_builtin_UADD16
+  #define __UQADD16 __iar_builtin_UQADD16
+  #define __UHADD16 __iar_builtin_UHADD16
+  #define __SSUB16  __iar_builtin_SSUB16
+  #define __QSUB16  __iar_builtin_QSUB16
+  #define __SHSUB16 __iar_builtin_SHSUB16
+  #define __USUB16  __iar_builtin_USUB16
+  #define __UQSUB16 __iar_builtin_UQSUB16
+  #define __UHSUB16 __iar_builtin_UHSUB16
+  #define __SASX    __iar_builtin_SASX
+  #define __QASX    __iar_builtin_QASX
+  #define __SHASX   __iar_builtin_SHASX
+  #define __UASX    __iar_builtin_UASX
+  #define __UQASX   __iar_builtin_UQASX
+  #define __UHASX   __iar_builtin_UHASX
+  #define __SSAX    __iar_builtin_SSAX
+  #define __QSAX    __iar_builtin_QSAX
+  #define __SHSAX   __iar_builtin_SHSAX
+  #define __USAX    __iar_builtin_USAX
+  #define __UQSAX   __iar_builtin_UQSAX
+  #define __UHSAX   __iar_builtin_UHSAX
+  #define __USAD8   __iar_builtin_USAD8
+  #define __USADA8  __iar_builtin_USADA8
+  #define __SSAT16  __iar_builtin_SSAT16
+  #define __USAT16  __iar_builtin_USAT16
+  #define __UXTB16  __iar_builtin_UXTB16
+  #define __UXTAB16 __iar_builtin_UXTAB16
+  #define __SXTB16  __iar_builtin_SXTB16
+  #define __SXTAB16 __iar_builtin_SXTAB16
+  #define __SMUAD   __iar_builtin_SMUAD
+  #define __SMUADX  __iar_builtin_SMUADX
+  #define __SMMLA   __iar_builtin_SMMLA
+  #define __SMLAD   __iar_builtin_SMLAD
+  #define __SMLADX  __iar_builtin_SMLADX
+  #define __SMLALD  __iar_builtin_SMLALD
+  #define __SMLALDX __iar_builtin_SMLALDX
+  #define __SMUSD   __iar_builtin_SMUSD
+  #define __SMUSDX  __iar_builtin_SMUSDX
+  #define __SMLSD   __iar_builtin_SMLSD
+  #define __SMLSDX  __iar_builtin_SMLSDX
+  #define __SMLSLD  __iar_builtin_SMLSLD
+  #define __SMLSLDX __iar_builtin_SMLSLDX
+  #define __SEL     __iar_builtin_SEL
+  #define __QADD    __iar_builtin_QADD
+  #define __QSUB    __iar_builtin_QSUB
+  #define __PKHBT   __iar_builtin_PKHBT
+  #define __PKHTB   __iar_builtin_PKHTB
+
+#else /* __ICCARM_INTRINSICS_VERSION__ == 2 */
+
+  #if !__FPU_PRESENT
+  #define __get_FPSCR __cmsis_iar_get_FPSR_not_active
+  #endif
+
+  #ifdef __INTRINSICS_INCLUDED
+  #error intrinsics.h is already included previously!
+  #endif
+
+  #include <intrinsics.h>
+
+  #if !__FPU_PRESENT
+  #define __get_FPSCR() (0)
+  #endif
+
+  #pragma diag_suppress=Pe940
+  #pragma diag_suppress=Pe177
+
+  #define __enable_irq        __enable_interrupt
+  #define __disable_irq       __disable_interrupt
+  #define __enable_fault_irq    __enable_fiq
+  #define __disable_fault_irq   __disable_fiq
+  #define __NOP               __no_operation
+
+  #define __get_xPSR          __get_PSR
+
+  __IAR_FT void __set_mode(uint32_t mode)
+  {
+    __ASM volatile("MSR  cpsr_c, %0" : : "r" (mode) : "memory");
+  }
+
+  __IAR_FT uint32_t __LDREXW(uint32_t volatile *ptr)
+  {
+    return __LDREX((unsigned long *)ptr);
+  }
+
+  __IAR_FT uint32_t __STREXW(uint32_t value, uint32_t volatile *ptr)
+  {
+    return __STREX(value, (unsigned long *)ptr);
+  }
+
+
+  __IAR_FT uint32_t __RRX(uint32_t value)
+  {
+    uint32_t result;
+    __ASM("RRX      %0, %1" : "=r"(result) : "r" (value) : "cc");
+    return(result);
+  }
+
+
+  __IAR_FT uint32_t __ROR(uint32_t op1, uint32_t op2)
+  {
+    return (op1 >> op2) | (op1 << ((sizeof(op1)*8)-op2));
+  }
+
+  __IAR_FT uint32_t __get_FPEXC(void)
+  {
+  #if (__FPU_PRESENT == 1)
+    uint32_t result;
+    __ASM volatile("VMRS %0, fpexc" : "=r" (result) : : "memory");
+    return(result);
+  #else
+    return(0);
+  #endif
+  }
+
+  __IAR_FT void __set_FPEXC(uint32_t fpexc)
+  {
+  #if (__FPU_PRESENT == 1)
+    __ASM volatile ("VMSR fpexc, %0" : : "r" (fpexc) : "memory");
+  #endif
+  }
+
+
+  #define __get_CP(cp, op1, Rt, CRn, CRm, op2) \
+    __ASM volatile("MRC p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : "=r" (Rt) : : "memory" )
+  #define __set_CP(cp, op1, Rt, CRn, CRm, op2) \
+    __ASM volatile("MCR p" # cp ", " # op1 ", %0, c" # CRn ", c" # CRm ", " # op2 : : "r" (Rt) : "memory" )
+  #define __get_CP64(cp, op1, Rt, CRm) \
+    __ASM volatile("MRRC p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : "=r" (Rt) : : "memory" )
+  #define __set_CP64(cp, op1, Rt, CRm) \
+    __ASM volatile("MCRR p" # cp ", " # op1 ", %Q0, %R0, c" # CRm  : : "r" (Rt) : "memory" )
+
+  #include "cmsis_cp15.h"
+
+#endif   /* __ICCARM_INTRINSICS_VERSION__ == 2 */
+
+#define __BKPT(value)    __asm volatile ("BKPT     %0" : : "i"(value))
+
+
+__IAR_FT uint32_t __get_SP_usr(void)
+{
+  uint32_t cpsr;
+  uint32_t result;
+  __ASM volatile(
+    "MRS     %0, cpsr   \n"
+    "CPS     #0x1F      \n" // no effect in USR mode
+    "MOV     %1, sp     \n"
+    "MSR     cpsr_c, %2 \n" // no effect in USR mode
+    "ISB" :  "=r"(cpsr), "=r"(result) : "r"(cpsr) : "memory"
+   );
+  return result;
+}
+
+__IAR_FT void __set_SP_usr(uint32_t topOfProcStack)
+{
+  uint32_t cpsr;
+  __ASM volatile(
+    "MRS     %0, cpsr   \n"
+    "CPS     #0x1F      \n" // no effect in USR mode
+    "MOV     sp, %1     \n"
+    "MSR     cpsr_c, %2 \n" // no effect in USR mode
+    "ISB" : "=r"(cpsr) : "r" (topOfProcStack), "r"(cpsr) : "memory"
+   );
+}
+
+#define __get_mode()                (__get_CPSR() & 0x1FU)
+
+__STATIC_INLINE
+void __FPU_Enable(void)
+{
+  __ASM volatile(
+    //Permit access to VFP/NEON, registers by modifying CPACR
+    "        MRC     p15,0,R1,c1,c0,2  \n"
+    "        ORR     R1,R1,#0x00F00000 \n"
+    "        MCR     p15,0,R1,c1,c0,2  \n"
+
+    //Ensure that subsequent instructions occur in the context of VFP/NEON access permitted
+    "        ISB                       \n"
+
+    //Enable VFP/NEON
+    "        VMRS    R1,FPEXC          \n"
+    "        ORR     R1,R1,#0x40000000 \n"
+    "        VMSR    FPEXC,R1          \n"
+
+    //Initialise VFP/NEON registers to 0
+    "        MOV     R2,#0             \n"
+
+    //Initialise D16 registers to 0
+    "        VMOV    D0, R2,R2         \n"
+    "        VMOV    D1, R2,R2         \n"
+    "        VMOV    D2, R2,R2         \n"
+    "        VMOV    D3, R2,R2         \n"
+    "        VMOV    D4, R2,R2         \n"
+    "        VMOV    D5, R2,R2         \n"
+    "        VMOV    D6, R2,R2         \n"
+    "        VMOV    D7, R2,R2         \n"
+    "        VMOV    D8, R2,R2         \n"
+    "        VMOV    D9, R2,R2         \n"
+    "        VMOV    D10,R2,R2         \n"
+    "        VMOV    D11,R2,R2         \n"
+    "        VMOV    D12,R2,R2         \n"
+    "        VMOV    D13,R2,R2         \n"
+    "        VMOV    D14,R2,R2         \n"
+    "        VMOV    D15,R2,R2         \n"
+
+#ifdef __ARM_ADVANCED_SIMD__
+    //Initialise D32 registers to 0
+    "        VMOV    D16,R2,R2         \n"
+    "        VMOV    D17,R2,R2         \n"
+    "        VMOV    D18,R2,R2         \n"
+    "        VMOV    D19,R2,R2         \n"
+    "        VMOV    D20,R2,R2         \n"
+    "        VMOV    D21,R2,R2         \n"
+    "        VMOV    D22,R2,R2         \n"
+    "        VMOV    D23,R2,R2         \n"
+    "        VMOV    D24,R2,R2         \n"
+    "        VMOV    D25,R2,R2         \n"
+    "        VMOV    D26,R2,R2         \n"
+    "        VMOV    D27,R2,R2         \n"
+    "        VMOV    D28,R2,R2         \n"
+    "        VMOV    D29,R2,R2         \n"
+    "        VMOV    D30,R2,R2         \n"
+    "        VMOV    D31,R2,R2         \n"
+#endif
+
+    //Initialise FPSCR to a known state
+    "        VMRS    R2,FPSCR          \n"
+    "        MOV32   R3,#0x00086060    \n" //Mask off all bits that do not have to be preserved. Non-preserved bits can/should be zero.
+    "        AND     R2,R2,R3          \n"
+    "        VMSR    FPSCR,R2          \n");
+}
+
+
+
+#undef __IAR_FT
+#undef __ICCARM_V8
+
+#pragma diag_default=Pe940
+#pragma diag_default=Pe177
+
+#endif /* __CMSIS_ICCARM_H__ */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_rcar_gen3.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_rcar_gen3.h
new file mode 100644
index 00000000..bb8b4b01
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_rcar_gen3.h
@@ -0,0 +1,51 @@
+/**************************************************************************//**
+ * @file     cmsis_rcar_gen3.h
+ * @brief    CMSIS for Cortex-R7 on Renesas R-Car Gen3 devices
+ ******************************************************************************/
+/*
+ * Copyright (c) 2019 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * ARM don't currently provide CMSIS for Cortex-R cores.
+ * We want the code for CP15 access, instructions and memory barriers so we can
+ * setup the caches, etc.
+ * We also want to program the MPU, whihc is a bit similar to Cortex-M devices,
+ * so we have modified CMSIS code to do this.
+ */
+#ifndef __CMSIS_RCAR_GEN3_H
+#define __CMSIS_RCAR_GEN3_H
+
+/* FPU */
+#define __FPU_PRESENT           1
+
+/* MPU */
+#define __MPU_PRESENT           1
+
+/* GIC */
+#define __GIC_PRESENT           1
+#define GIC_DISTRIBUTOR_BASE	0xF1110000U
+#define GIC_INTERFACE_BASE	0xF1120000U
+#define IRQ_GIC_LINE_COUNT	511
+/* Not going to list all the interrupts */
+typedef	unsigned int IRQn_Type;
+
+#include "core_ca.h"
+#include "core_cr7.h"
+
+#endif /* __CMSIS_RCAR_GEN3_H */
+
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/cmsis_version.h b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_version.h
new file mode 100644
index 00000000..660f612a
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/cmsis_version.h
@@ -0,0 +1,39 @@
+/**************************************************************************//**
+ * @file     cmsis_version.h
+ * @brief    CMSIS Core(M) Version definitions
+ * @version  V5.0.2
+ * @date     19. April 2017
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2017 ARM Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header   /* treat file as system include file */
+#endif
+
+#ifndef __CMSIS_VERSION_H
+#define __CMSIS_VERSION_H
+
+/*  CMSIS Version definitions */
+#define __CM_CMSIS_VERSION_MAIN  ( 5U)                                      /*!< [31:16] CMSIS Core(M) main version */
+#define __CM_CMSIS_VERSION_SUB   ( 1U)                                      /*!< [15:0]  CMSIS Core(M) sub version */
+#define __CM_CMSIS_VERSION       ((__CM_CMSIS_VERSION_MAIN << 16U) | \
+                                   __CM_CMSIS_VERSION_SUB           )       /*!< CMSIS Core(M) version number */
+#endif
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/core_ca.h b/machines/cortex-r/armv7/RCar/CMSIS/core_ca.h
new file mode 100644
index 00000000..0baf9781
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/core_ca.h
@@ -0,0 +1,2610 @@
+/**************************************************************************//**
+ * @file     core_ca.h
+ * @brief    CMSIS Cortex-A Core Peripheral Access Layer Header File
+ * @version  V1.0.1
+ * @date     07. May 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2017 ARM Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header   /* treat file as system include file */
+#endif
+
+#ifndef __CORE_CA_H_GENERIC
+#define __CORE_CA_H_GENERIC
+
+#ifdef __cplusplus
+ extern "C" {
+#endif
+
+/*******************************************************************************
+ *                 CMSIS definitions
+ ******************************************************************************/
+
+/*  CMSIS CA definitions */
+#define __CA_CMSIS_VERSION_MAIN  (1U)                                      /*!< \brief [31:16] CMSIS-Core(A) main version   */
+#define __CA_CMSIS_VERSION_SUB   (1U)                                      /*!< \brief [15:0]  CMSIS-Core(A) sub version    */
+#define __CA_CMSIS_VERSION       ((__CA_CMSIS_VERSION_MAIN << 16U) | \
+                                   __CA_CMSIS_VERSION_SUB          )       /*!< \brief CMSIS-Core(A) version number         */
+
+#if defined ( __CC_ARM )
+  #if defined __TARGET_FPU_VFP
+    #if (__FPU_PRESENT == 1)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined (__ARMCC_VERSION) && (__ARMCC_VERSION >= 6010050)
+  #if defined __ARM_PCS_VFP
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __ICCARM__ )
+  #if defined __ARMVFP__
+    #if (__FPU_PRESENT == 1)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __TMS470__ )
+  #if defined __TI_VFP_SUPPORT__
+    #if (__FPU_PRESENT == 1)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __GNUC__ )
+  #if defined (__VFP_FP__) && !defined(__SOFTFP__)
+    #if (__FPU_PRESENT == 1)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __TASKING__ )
+  #if defined __FPU_VFP__
+    #if (__FPU_PRESENT == 1)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+#endif
+
+#include "cmsis_compiler.h"               /* CMSIS compiler specific defines */
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __CORE_CA_H_GENERIC */
+
+#ifndef __CMSIS_GENERIC
+
+#ifndef __CORE_CA_H_DEPENDANT
+#define __CORE_CA_H_DEPENDANT
+
+#ifdef __cplusplus
+ extern "C" {
+#endif
+
+ /* check device defines and use defaults */
+#if defined __CHECK_DEVICE_DEFINES
+  #ifndef __CA_REV
+    #define __CA_REV              0x0000U
+    #warning "__CA_REV not defined in device header file; using default!"
+  #endif
+  
+  #ifndef __FPU_PRESENT
+    #define __FPU_PRESENT             0U
+    #warning "__FPU_PRESENT not defined in device header file; using default!"
+  #endif
+    
+  #ifndef __GIC_PRESENT
+    #define __GIC_PRESENT             1U
+    #warning "__GIC_PRESENT not defined in device header file; using default!"
+  #endif
+  
+  #ifndef __TIM_PRESENT
+    #define __TIM_PRESENT             1U
+    #warning "__TIM_PRESENT not defined in device header file; using default!"
+  #endif
+  
+  #ifndef __L2C_PRESENT
+    #define __L2C_PRESENT             0U
+    #warning "__L2C_PRESENT not defined in device header file; using default!"
+  #endif
+#endif
+
+/* IO definitions (access restrictions to peripheral registers) */
+#ifdef __cplusplus
+  #define   __I     volatile             /*!< \brief Defines 'read only' permissions */
+#else
+  #define   __I     volatile const       /*!< \brief Defines 'read only' permissions */
+#endif
+#define     __O     volatile             /*!< \brief Defines 'write only' permissions */
+#define     __IO    volatile             /*!< \brief Defines 'read / write' permissions */
+
+/* following defines should be used for structure members */
+#define     __IM     volatile const      /*!< \brief Defines 'read only' structure member permissions */
+#define     __OM     volatile            /*!< \brief Defines 'write only' structure member permissions */
+#define     __IOM    volatile            /*!< \brief Defines 'read / write' structure member permissions */
+#define RESERVED(N, T) T RESERVED##N;    // placeholder struct members used for "reserved" areas
+
+ /*******************************************************************************
+  *                 Register Abstraction
+   Core Register contain:
+   - CPSR
+   - CP15 Registers
+   - L2C-310 Cache Controller
+   - Generic Interrupt Controller Distributor
+   - Generic Interrupt Controller Interface
+  ******************************************************************************/
+
+/* Core Register CPSR */
+typedef union
+{
+  struct
+  {
+    uint32_t M:5;                        /*!< \brief bit:  0.. 4  Mode field */
+    uint32_t T:1;                        /*!< \brief bit:      5  Thumb execution state bit */
+    uint32_t F:1;                        /*!< \brief bit:      6  FIQ mask bit */
+    uint32_t I:1;                        /*!< \brief bit:      7  IRQ mask bit */
+    uint32_t A:1;                        /*!< \brief bit:      8  Asynchronous abort mask bit */
+    uint32_t E:1;                        /*!< \brief bit:      9  Endianness execution state bit */
+    uint32_t IT1:6;                      /*!< \brief bit: 10..15  If-Then execution state bits 2-7 */
+    uint32_t GE:4;                       /*!< \brief bit: 16..19  Greater than or Equal flags */
+    RESERVED(0:4, uint32_t)              
+    uint32_t J:1;                        /*!< \brief bit:     24  Jazelle bit */
+    uint32_t IT0:2;                      /*!< \brief bit: 25..26  If-Then execution state bits 0-1 */
+    uint32_t Q:1;                        /*!< \brief bit:     27  Saturation condition flag */
+    uint32_t V:1;                        /*!< \brief bit:     28  Overflow condition code flag */
+    uint32_t C:1;                        /*!< \brief bit:     29  Carry condition code flag */
+    uint32_t Z:1;                        /*!< \brief bit:     30  Zero condition code flag */
+    uint32_t N:1;                        /*!< \brief bit:     31  Negative condition code flag */
+  } b;                                   /*!< \brief Structure used for bit  access */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} CPSR_Type;
+
+
+
+/* CPSR Register Definitions */
+#define CPSR_N_Pos                       31U                                    /*!< \brief CPSR: N Position */
+#define CPSR_N_Msk                       (1UL << CPSR_N_Pos)                    /*!< \brief CPSR: N Mask */
+
+#define CPSR_Z_Pos                       30U                                    /*!< \brief CPSR: Z Position */
+#define CPSR_Z_Msk                       (1UL << CPSR_Z_Pos)                    /*!< \brief CPSR: Z Mask */
+
+#define CPSR_C_Pos                       29U                                    /*!< \brief CPSR: C Position */
+#define CPSR_C_Msk                       (1UL << CPSR_C_Pos)                    /*!< \brief CPSR: C Mask */
+
+#define CPSR_V_Pos                       28U                                    /*!< \brief CPSR: V Position */
+#define CPSR_V_Msk                       (1UL << CPSR_V_Pos)                    /*!< \brief CPSR: V Mask */
+
+#define CPSR_Q_Pos                       27U                                    /*!< \brief CPSR: Q Position */
+#define CPSR_Q_Msk                       (1UL << CPSR_Q_Pos)                    /*!< \brief CPSR: Q Mask */
+
+#define CPSR_IT0_Pos                     25U                                    /*!< \brief CPSR: IT0 Position */
+#define CPSR_IT0_Msk                     (3UL << CPSR_IT0_Pos)                  /*!< \brief CPSR: IT0 Mask */
+
+#define CPSR_J_Pos                       24U                                    /*!< \brief CPSR: J Position */
+#define CPSR_J_Msk                       (1UL << CPSR_J_Pos)                    /*!< \brief CPSR: J Mask */
+
+#define CPSR_GE_Pos                      16U                                    /*!< \brief CPSR: GE Position */
+#define CPSR_GE_Msk                      (0xFUL << CPSR_GE_Pos)                 /*!< \brief CPSR: GE Mask */
+
+#define CPSR_IT1_Pos                     10U                                    /*!< \brief CPSR: IT1 Position */
+#define CPSR_IT1_Msk                     (0x3FUL << CPSR_IT1_Pos)               /*!< \brief CPSR: IT1 Mask */
+
+#define CPSR_E_Pos                       9U                                     /*!< \brief CPSR: E Position */
+#define CPSR_E_Msk                       (1UL << CPSR_E_Pos)                    /*!< \brief CPSR: E Mask */
+
+#define CPSR_A_Pos                       8U                                     /*!< \brief CPSR: A Position */
+#define CPSR_A_Msk                       (1UL << CPSR_A_Pos)                    /*!< \brief CPSR: A Mask */
+
+#define CPSR_I_Pos                       7U                                     /*!< \brief CPSR: I Position */
+#define CPSR_I_Msk                       (1UL << CPSR_I_Pos)                    /*!< \brief CPSR: I Mask */
+
+#define CPSR_F_Pos                       6U                                     /*!< \brief CPSR: F Position */
+#define CPSR_F_Msk                       (1UL << CPSR_F_Pos)                    /*!< \brief CPSR: F Mask */
+
+#define CPSR_T_Pos                       5U                                     /*!< \brief CPSR: T Position */
+#define CPSR_T_Msk                       (1UL << CPSR_T_Pos)                    /*!< \brief CPSR: T Mask */
+
+#define CPSR_M_Pos                       0U                                     /*!< \brief CPSR: M Position */
+#define CPSR_M_Msk                       (0x1FUL << CPSR_M_Pos)                 /*!< \brief CPSR: M Mask */
+
+#define CPSR_M_USR                       0x10U                                  /*!< \brief CPSR: M User mode (PL0) */
+#define CPSR_M_FIQ                       0x11U                                  /*!< \brief CPSR: M Fast Interrupt mode (PL1) */
+#define CPSR_M_IRQ                       0x12U                                  /*!< \brief CPSR: M Interrupt mode (PL1) */
+#define CPSR_M_SVC                       0x13U                                  /*!< \brief CPSR: M Supervisor mode (PL1) */
+#define CPSR_M_MON                       0x16U                                  /*!< \brief CPSR: M Monitor mode (PL1) */
+#define CPSR_M_ABT                       0x17U                                  /*!< \brief CPSR: M Abort mode (PL1) */
+#define CPSR_M_HYP                       0x1AU                                  /*!< \brief CPSR: M Hypervisor mode (PL2) */
+#define CPSR_M_UND                       0x1BU                                  /*!< \brief CPSR: M Undefined mode (PL1) */
+#define CPSR_M_SYS                       0x1FU                                  /*!< \brief CPSR: M System mode (PL1) */
+
+/* CP15 Register SCTLR */
+typedef union
+{
+  struct
+  {
+    uint32_t M:1;                        /*!< \brief bit:     0  MMU enable */
+    uint32_t A:1;                        /*!< \brief bit:     1  Alignment check enable */
+    uint32_t C:1;                        /*!< \brief bit:     2  Cache enable */
+    RESERVED(0:2, uint32_t)              
+    uint32_t CP15BEN:1;                  /*!< \brief bit:     5  CP15 barrier enable */
+    RESERVED(1:1, uint32_t)              
+    uint32_t B:1;                        /*!< \brief bit:     7  Endianness model */
+    RESERVED(2:2, uint32_t)              
+    uint32_t SW:1;                       /*!< \brief bit:    10  SWP and SWPB enable */
+    uint32_t Z:1;                        /*!< \brief bit:    11  Branch prediction enable */
+    uint32_t I:1;                        /*!< \brief bit:    12  Instruction cache enable */
+    uint32_t V:1;                        /*!< \brief bit:    13  Vectors bit */
+    uint32_t RR:1;                       /*!< \brief bit:    14  Round Robin select */
+    RESERVED(3:2, uint32_t)              
+    uint32_t HA:1;                       /*!< \brief bit:    17  Hardware Access flag enable */
+    RESERVED(4:1, uint32_t)              
+    uint32_t WXN:1;                      /*!< \brief bit:    19  Write permission implies XN */
+    uint32_t UWXN:1;                     /*!< \brief bit:    20  Unprivileged write permission implies PL1 XN */
+    uint32_t FI:1;                       /*!< \brief bit:    21  Fast interrupts configuration enable */
+    uint32_t U:1;                        /*!< \brief bit:    22  Alignment model */
+    RESERVED(5:1, uint32_t)              
+    uint32_t VE:1;                       /*!< \brief bit:    24  Interrupt Vectors Enable */
+    uint32_t EE:1;                       /*!< \brief bit:    25  Exception Endianness */
+    RESERVED(6:1, uint32_t)              
+    uint32_t NMFI:1;                     /*!< \brief bit:    27  Non-maskable FIQ (NMFI) support */
+    uint32_t TRE:1;                      /*!< \brief bit:    28  TEX remap enable. */
+    uint32_t AFE:1;                      /*!< \brief bit:    29  Access flag enable */
+    uint32_t TE:1;                       /*!< \brief bit:    30  Thumb Exception enable */
+    RESERVED(7:1, uint32_t)              
+  } b;                                   /*!< \brief Structure used for bit  access */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} SCTLR_Type;
+
+#define SCTLR_TE_Pos                     30U                                    /*!< \brief SCTLR: TE Position */
+#define SCTLR_TE_Msk                     (1UL << SCTLR_TE_Pos)                  /*!< \brief SCTLR: TE Mask */
+
+#define SCTLR_AFE_Pos                    29U                                    /*!< \brief SCTLR: AFE Position */
+#define SCTLR_AFE_Msk                    (1UL << SCTLR_AFE_Pos)                 /*!< \brief SCTLR: AFE Mask */
+
+#define SCTLR_TRE_Pos                    28U                                    /*!< \brief SCTLR: TRE Position */
+#define SCTLR_TRE_Msk                    (1UL << SCTLR_TRE_Pos)                 /*!< \brief SCTLR: TRE Mask */
+
+#define SCTLR_NMFI_Pos                   27U                                    /*!< \brief SCTLR: NMFI Position */
+#define SCTLR_NMFI_Msk                   (1UL << SCTLR_NMFI_Pos)                /*!< \brief SCTLR: NMFI Mask */
+
+#define SCTLR_EE_Pos                     25U                                    /*!< \brief SCTLR: EE Position */
+#define SCTLR_EE_Msk                     (1UL << SCTLR_EE_Pos)                  /*!< \brief SCTLR: EE Mask */
+
+#define SCTLR_VE_Pos                     24U                                    /*!< \brief SCTLR: VE Position */
+#define SCTLR_VE_Msk                     (1UL << SCTLR_VE_Pos)                  /*!< \brief SCTLR: VE Mask */
+
+#define SCTLR_U_Pos                      22U                                    /*!< \brief SCTLR: U Position */
+#define SCTLR_U_Msk                      (1UL << SCTLR_U_Pos)                   /*!< \brief SCTLR: U Mask */
+
+#define SCTLR_FI_Pos                     21U                                    /*!< \brief SCTLR: FI Position */
+#define SCTLR_FI_Msk                     (1UL << SCTLR_FI_Pos)                  /*!< \brief SCTLR: FI Mask */
+
+#define SCTLR_UWXN_Pos                   20U                                    /*!< \brief SCTLR: UWXN Position */
+#define SCTLR_UWXN_Msk                   (1UL << SCTLR_UWXN_Pos)                /*!< \brief SCTLR: UWXN Mask */
+
+#define SCTLR_WXN_Pos                    19U                                    /*!< \brief SCTLR: WXN Position */
+#define SCTLR_WXN_Msk                    (1UL << SCTLR_WXN_Pos)                 /*!< \brief SCTLR: WXN Mask */
+
+#define SCTLR_HA_Pos                     17U                                    /*!< \brief SCTLR: HA Position */
+#define SCTLR_HA_Msk                     (1UL << SCTLR_HA_Pos)                  /*!< \brief SCTLR: HA Mask */
+
+#define SCTLR_RR_Pos                     14U                                    /*!< \brief SCTLR: RR Position */
+#define SCTLR_RR_Msk                     (1UL << SCTLR_RR_Pos)                  /*!< \brief SCTLR: RR Mask */
+
+#define SCTLR_V_Pos                      13U                                    /*!< \brief SCTLR: V Position */
+#define SCTLR_V_Msk                      (1UL << SCTLR_V_Pos)                   /*!< \brief SCTLR: V Mask */
+
+#define SCTLR_I_Pos                      12U                                    /*!< \brief SCTLR: I Position */
+#define SCTLR_I_Msk                      (1UL << SCTLR_I_Pos)                   /*!< \brief SCTLR: I Mask */
+
+#define SCTLR_Z_Pos                      11U                                    /*!< \brief SCTLR: Z Position */
+#define SCTLR_Z_Msk                      (1UL << SCTLR_Z_Pos)                   /*!< \brief SCTLR: Z Mask */
+
+#define SCTLR_SW_Pos                     10U                                    /*!< \brief SCTLR: SW Position */
+#define SCTLR_SW_Msk                     (1UL << SCTLR_SW_Pos)                  /*!< \brief SCTLR: SW Mask */
+
+#define SCTLR_B_Pos                      7U                                     /*!< \brief SCTLR: B Position */
+#define SCTLR_B_Msk                      (1UL << SCTLR_B_Pos)                   /*!< \brief SCTLR: B Mask */
+
+#define SCTLR_CP15BEN_Pos                5U                                     /*!< \brief SCTLR: CP15BEN Position */
+#define SCTLR_CP15BEN_Msk                (1UL << SCTLR_CP15BEN_Pos)             /*!< \brief SCTLR: CP15BEN Mask */
+
+#define SCTLR_C_Pos                      2U                                     /*!< \brief SCTLR: C Position */
+#define SCTLR_C_Msk                      (1UL << SCTLR_C_Pos)                   /*!< \brief SCTLR: C Mask */
+
+#define SCTLR_A_Pos                      1U                                     /*!< \brief SCTLR: A Position */
+#define SCTLR_A_Msk                      (1UL << SCTLR_A_Pos)                   /*!< \brief SCTLR: A Mask */
+
+#define SCTLR_M_Pos                      0U                                     /*!< \brief SCTLR: M Position */
+#define SCTLR_M_Msk                      (1UL << SCTLR_M_Pos)                   /*!< \brief SCTLR: M Mask */
+
+/* CP15 Register ACTLR */
+typedef union
+{
+#if __CORTEX_A == 5 || defined(DOXYGEN)
+  /** \brief Structure used for bit access on Cortex-A5 */
+  struct
+  {
+    uint32_t FW:1;                      /*!< \brief bit:      0  Cache and TLB maintenance broadcast */
+    RESERVED(0:5, uint32_t)              
+    uint32_t SMP:1;                      /*!< \brief bit:     6  Enables coherent requests to the processor */
+    uint32_t EXCL:1;                     /*!< \brief bit:     7  Exclusive L1/L2 cache control */
+    RESERVED(1:2, uint32_t)
+    uint32_t DODMBS:1;                   /*!< \brief bit:    10  Disable optimized data memory barrier behavior */
+    uint32_t DWBST:1;                    /*!< \brief bit:    11  AXI data write bursts to Normal memory */
+    uint32_t RADIS:1;                    /*!< \brief bit:    12  L1 Data Cache read-allocate mode disable */
+    uint32_t L1PCTL:2;                   /*!< \brief bit:13..14  L1 Data prefetch control */    
+    uint32_t BP:2;                       /*!< \brief bit:16..15  Branch prediction policy */
+    uint32_t RSDIS:1;                    /*!< \brief bit:    17  Disable return stack operation */
+    uint32_t BTDIS:1;                    /*!< \brief bit:    18  Disable indirect Branch Target Address Cache (BTAC) */
+    RESERVED(3:9, uint32_t)             
+    uint32_t DBDI:1;                     /*!< \brief bit:    28  Disable branch dual issue */
+    RESERVED(7:3, uint32_t)              
+ } b;
+#endif  
+#if __CORTEX_A == 7 || defined(DOXYGEN)
+  /** \brief Structure used for bit access on Cortex-A7 */
+  struct
+  {
+    RESERVED(0:6, uint32_t)              
+    uint32_t SMP:1;                      /*!< \brief bit:     6  Enables coherent requests to the processor */
+    RESERVED(1:3, uint32_t)              
+    uint32_t DODMBS:1;                   /*!< \brief bit:    10  Disable optimized data memory barrier behavior */
+    uint32_t L2RADIS:1;                  /*!< \brief bit:    11  L2 Data Cache read-allocate mode disable */
+    uint32_t L1RADIS:1;                  /*!< \brief bit:    12  L1 Data Cache read-allocate mode disable */
+    uint32_t L1PCTL:2;                   /*!< \brief bit:13..14  L1 Data prefetch control */
+    uint32_t DDVM:1;                     /*!< \brief bit:    15  Disable Distributed Virtual Memory (DVM) transactions */
+    RESERVED(3:12, uint32_t)             
+    uint32_t DDI:1;                      /*!< \brief bit:    28  Disable dual issue */
+    RESERVED(7:3, uint32_t)              
+  } b;
+#endif  
+#if __CORTEX_A == 9 || defined(DOXYGEN)
+  /** \brief Structure used for bit access on Cortex-A9 */
+  struct
+  {
+    uint32_t FW:1;                       /*!< \brief bit:     0  Cache and TLB maintenance broadcast */
+    RESERVED(0:1, uint32_t)
+    uint32_t L1PE:1;                     /*!< \brief bit:     2  Dside prefetch */
+    uint32_t WFLZM:1;                    /*!< \brief bit:     3  Cache and TLB maintenance broadcast */
+    RESERVED(1:2, uint32_t)
+    uint32_t SMP:1;                      /*!< \brief bit:     6  Enables coherent requests to the processor */
+    uint32_t EXCL:1;                     /*!< \brief bit:     7  Exclusive L1/L2 cache control */
+    uint32_t AOW:1;                      /*!< \brief bit:     8  Enable allocation in one cache way only */
+    uint32_t PARITY:1;                   /*!< \brief bit:     9  Support for parity checking, if implemented */
+    RESERVED(7:22, uint32_t)              
+  } b;
+#endif  
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} ACTLR_Type;
+
+#define ACTLR_DDI_Pos                    28U                                     /*!< \brief ACTLR: DDI Position */
+#define ACTLR_DDI_Msk                    (1UL << ACTLR_DDI_Pos)                  /*!< \brief ACTLR: DDI Mask */
+
+#define ACTLR_DBDI_Pos                   28U                                     /*!< \brief ACTLR: DBDI Position */
+#define ACTLR_DBDI_Msk                   (1UL << ACTLR_DBDI_Pos)                 /*!< \brief ACTLR: DBDI Mask */
+
+#define ACTLR_BTDIS_Pos                  18U                                     /*!< \brief ACTLR: BTDIS Position */
+#define ACTLR_BTDIS_Msk                  (1UL << ACTLR_BTDIS_Pos)                /*!< \brief ACTLR: BTDIS Mask */
+
+#define ACTLR_RSDIS_Pos                  17U                                     /*!< \brief ACTLR: RSDIS Position */
+#define ACTLR_RSDIS_Msk                  (1UL << ACTLR_RSDIS_Pos)                /*!< \brief ACTLR: RSDIS Mask */
+
+#define ACTLR_BP_Pos                     15U                                     /*!< \brief ACTLR: BP Position */
+#define ACTLR_BP_Msk                     (3UL << ACTLR_BP_Pos)                   /*!< \brief ACTLR: BP Mask */
+
+#define ACTLR_DDVM_Pos                   15U                                     /*!< \brief ACTLR: DDVM Position */
+#define ACTLR_DDVM_Msk                   (1UL << ACTLR_DDVM_Pos)                 /*!< \brief ACTLR: DDVM Mask */
+
+#define ACTLR_L1PCTL_Pos                 13U                                     /*!< \brief ACTLR: L1PCTL Position */
+#define ACTLR_L1PCTL_Msk                 (3UL << ACTLR_L1PCTL_Pos)               /*!< \brief ACTLR: L1PCTL Mask */
+
+#define ACTLR_RADIS_Pos                  12U                                     /*!< \brief ACTLR: RADIS Position */
+#define ACTLR_RADIS_Msk                  (1UL << ACTLR_RADIS_Pos)                /*!< \brief ACTLR: RADIS Mask */
+
+#define ACTLR_L1RADIS_Pos                12U                                     /*!< \brief ACTLR: L1RADIS Position */
+#define ACTLR_L1RADIS_Msk                (1UL << ACTLR_L1RADIS_Pos)              /*!< \brief ACTLR: L1RADIS Mask */
+
+#define ACTLR_DWBST_Pos                  11U                                     /*!< \brief ACTLR: DWBST Position */
+#define ACTLR_DWBST_Msk                  (1UL << ACTLR_DWBST_Pos)                /*!< \brief ACTLR: DWBST Mask */
+
+#define ACTLR_L2RADIS_Pos                11U                                     /*!< \brief ACTLR: L2RADIS Position */
+#define ACTLR_L2RADIS_Msk                (1UL << ACTLR_L2RADIS_Pos)              /*!< \brief ACTLR: L2RADIS Mask */
+
+#define ACTLR_DODMBS_Pos                 10U                                     /*!< \brief ACTLR: DODMBS Position */
+#define ACTLR_DODMBS_Msk                 (1UL << ACTLR_DODMBS_Pos)               /*!< \brief ACTLR: DODMBS Mask */
+
+#define ACTLR_PARITY_Pos                 9U                                      /*!< \brief ACTLR: PARITY Position */
+#define ACTLR_PARITY_Msk                 (1UL << ACTLR_PARITY_Pos)               /*!< \brief ACTLR: PARITY Mask */
+
+#define ACTLR_AOW_Pos                    8U                                      /*!< \brief ACTLR: AOW Position */
+#define ACTLR_AOW_Msk                    (1UL << ACTLR_AOW_Pos)                  /*!< \brief ACTLR: AOW Mask */
+
+#define ACTLR_EXCL_Pos                   7U                                      /*!< \brief ACTLR: EXCL Position */
+#define ACTLR_EXCL_Msk                   (1UL << ACTLR_EXCL_Pos)                 /*!< \brief ACTLR: EXCL Mask */
+
+#define ACTLR_SMP_Pos                    6U                                      /*!< \brief ACTLR: SMP Position */
+#define ACTLR_SMP_Msk                    (1UL << ACTLR_SMP_Pos)                  /*!< \brief ACTLR: SMP Mask */
+
+#define ACTLR_WFLZM_Pos                  3U                                      /*!< \brief ACTLR: WFLZM Position */
+#define ACTLR_WFLZM_Msk                  (1UL << ACTLR_WFLZM_Pos)                /*!< \brief ACTLR: WFLZM Mask */
+
+#define ACTLR_L1PE_Pos                   2U                                      /*!< \brief ACTLR: L1PE Position */
+#define ACTLR_L1PE_Msk                   (1UL << ACTLR_L1PE_Pos)                 /*!< \brief ACTLR: L1PE Mask */
+
+#define ACTLR_FW_Pos                     0U                                      /*!< \brief ACTLR: FW Position */
+#define ACTLR_FW_Msk                     (1UL << ACTLR_FW_Pos)                   /*!< \brief ACTLR: FW Mask */
+
+/* CP15 Register CPACR */
+typedef union
+{
+  struct
+  {
+    uint32_t CP0:2;                      /*!< \brief bit:  0..1  Access rights for coprocessor 0 */
+    uint32_t CP1:2;                      /*!< \brief bit:  2..3  Access rights for coprocessor 1 */
+    uint32_t CP2:2;                      /*!< \brief bit:  4..5  Access rights for coprocessor 2 */
+    uint32_t CP3:2;                      /*!< \brief bit:  6..7  Access rights for coprocessor 3 */
+    uint32_t CP4:2;                      /*!< \brief bit:  8..9  Access rights for coprocessor 4 */
+    uint32_t CP5:2;                      /*!< \brief bit:10..11  Access rights for coprocessor 5 */
+    uint32_t CP6:2;                      /*!< \brief bit:12..13  Access rights for coprocessor 6 */
+    uint32_t CP7:2;                      /*!< \brief bit:14..15  Access rights for coprocessor 7 */
+    uint32_t CP8:2;                      /*!< \brief bit:16..17  Access rights for coprocessor 8 */
+    uint32_t CP9:2;                      /*!< \brief bit:18..19  Access rights for coprocessor 9 */
+    uint32_t CP10:2;                     /*!< \brief bit:20..21  Access rights for coprocessor 10 */
+    uint32_t CP11:2;                     /*!< \brief bit:22..23  Access rights for coprocessor 11 */
+    uint32_t CP12:2;                     /*!< \brief bit:24..25  Access rights for coprocessor 11 */
+    uint32_t CP13:2;                     /*!< \brief bit:26..27  Access rights for coprocessor 11 */
+    uint32_t TRCDIS:1;                   /*!< \brief bit:    28  Disable CP14 access to trace registers */
+    RESERVED(0:1, uint32_t)              
+    uint32_t D32DIS:1;                   /*!< \brief bit:    30  Disable use of registers D16-D31 of the VFP register file */
+    uint32_t ASEDIS:1;                   /*!< \brief bit:    31  Disable Advanced SIMD Functionality */
+  } b;                                   /*!< \brief Structure used for bit  access */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} CPACR_Type;
+
+#define CPACR_ASEDIS_Pos                 31U                                    /*!< \brief CPACR: ASEDIS Position */
+#define CPACR_ASEDIS_Msk                 (1UL << CPACR_ASEDIS_Pos)              /*!< \brief CPACR: ASEDIS Mask */
+
+#define CPACR_D32DIS_Pos                 30U                                    /*!< \brief CPACR: D32DIS Position */
+#define CPACR_D32DIS_Msk                 (1UL << CPACR_D32DIS_Pos)              /*!< \brief CPACR: D32DIS Mask */
+
+#define CPACR_TRCDIS_Pos                 28U                                    /*!< \brief CPACR: D32DIS Position */
+#define CPACR_TRCDIS_Msk                 (1UL << CPACR_D32DIS_Pos)              /*!< \brief CPACR: D32DIS Mask */
+
+#define CPACR_CP_Pos_(n)                 (n*2U)                                 /*!< \brief CPACR: CPn Position */
+#define CPACR_CP_Msk_(n)                 (3UL << CPACR_CP_Pos_(n))              /*!< \brief CPACR: CPn Mask */
+
+#define CPACR_CP_NA                      0U                                     /*!< \brief CPACR CPn field: Access denied. */
+#define CPACR_CP_PL1                     1U                                     /*!< \brief CPACR CPn field: Accessible from PL1 only. */
+#define CPACR_CP_FA                      3U                                     /*!< \brief CPACR CPn field: Full access. */
+
+/* CP15 Register DFSR */
+typedef union
+{
+  struct
+  {
+    uint32_t FS0:4;                      /*!< \brief bit: 0.. 3  Fault Status bits bit 0-3 */
+    uint32_t Domain:4;                   /*!< \brief bit: 4.. 7  Fault on which domain */
+    RESERVED(0:1, uint32_t)              
+    uint32_t LPAE:1;                     /*!< \brief bit:     9  Large Physical Address Extension */
+    uint32_t FS1:1;                      /*!< \brief bit:    10  Fault Status bits bit 4 */
+    uint32_t WnR:1;                      /*!< \brief bit:    11  Write not Read bit */
+    uint32_t ExT:1;                      /*!< \brief bit:    12  External abort type */
+    uint32_t CM:1;                       /*!< \brief bit:    13  Cache maintenance fault */
+    RESERVED(1:18, uint32_t)             
+  } s;                                   /*!< \brief Structure used for bit  access in short format */
+  struct
+  {
+    uint32_t STATUS:5;                   /*!< \brief bit: 0.. 5  Fault Status bits */
+    RESERVED(0:3, uint32_t)              
+    uint32_t LPAE:1;                     /*!< \brief bit:     9  Large Physical Address Extension */
+    RESERVED(1:1, uint32_t)              
+    uint32_t WnR:1;                      /*!< \brief bit:    11  Write not Read bit */
+    uint32_t ExT:1;                      /*!< \brief bit:    12  External abort type */
+    uint32_t CM:1;                       /*!< \brief bit:    13  Cache maintenance fault */
+    RESERVED(2:18, uint32_t)             
+  } l;                                   /*!< \brief Structure used for bit  access in long format */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} DFSR_Type;
+
+#define DFSR_CM_Pos                      13U                                    /*!< \brief DFSR: CM Position */
+#define DFSR_CM_Msk                      (1UL << DFSR_CM_Pos)                   /*!< \brief DFSR: CM Mask */
+
+#define DFSR_Ext_Pos                     12U                                    /*!< \brief DFSR: Ext Position */
+#define DFSR_Ext_Msk                     (1UL << DFSR_Ext_Pos)                  /*!< \brief DFSR: Ext Mask */
+
+#define DFSR_WnR_Pos                     11U                                    /*!< \brief DFSR: WnR Position */
+#define DFSR_WnR_Msk                     (1UL << DFSR_WnR_Pos)                  /*!< \brief DFSR: WnR Mask */
+
+#define DFSR_FS1_Pos                     10U                                    /*!< \brief DFSR: FS1 Position */
+#define DFSR_FS1_Msk                     (1UL << DFSR_FS1_Pos)                  /*!< \brief DFSR: FS1 Mask */
+
+#define DFSR_LPAE_Pos                    9U                                    /*!< \brief DFSR: LPAE Position */
+#define DFSR_LPAE_Msk                    (1UL << DFSR_LPAE_Pos)                /*!< \brief DFSR: LPAE Mask */
+
+#define DFSR_Domain_Pos                  4U                                     /*!< \brief DFSR: Domain Position */
+#define DFSR_Domain_Msk                  (0xFUL << DFSR_Domain_Pos)             /*!< \brief DFSR: Domain Mask */
+
+#define DFSR_FS0_Pos                     0U                                     /*!< \brief DFSR: FS0 Position */
+#define DFSR_FS0_Msk                     (0xFUL << DFSR_FS0_Pos)                /*!< \brief DFSR: FS0 Mask */
+
+#define DFSR_STATUS_Pos                  0U                                     /*!< \brief DFSR: STATUS Position */
+#define DFSR_STATUS_Msk                  (0x3FUL << DFSR_STATUS_Pos)            /*!< \brief DFSR: STATUS Mask */
+
+/* CP15 Register IFSR */
+typedef union
+{
+  struct
+  {
+    uint32_t FS0:4;                      /*!< \brief bit: 0.. 3  Fault Status bits bit 0-3 */
+    RESERVED(0:5, uint32_t)              
+    uint32_t LPAE:1;                     /*!< \brief bit:     9  Large Physical Address Extension */
+    uint32_t FS1:1;                      /*!< \brief bit:    10  Fault Status bits bit 4 */
+    RESERVED(1:1, uint32_t)              
+    uint32_t ExT:1;                      /*!< \brief bit:    12  External abort type */
+    RESERVED(2:19, uint32_t)             
+  } s;                                   /*!< \brief Structure used for bit access in short format */
+  struct
+  {
+    uint32_t STATUS:6;                   /*!< \brief bit: 0.. 5  Fault Status bits */
+    RESERVED(0:3, uint32_t)              
+    uint32_t LPAE:1;                     /*!< \brief bit:     9  Large Physical Address Extension */
+    RESERVED(1:2, uint32_t)              
+    uint32_t ExT:1;                      /*!< \brief bit:    12  External abort type */
+    RESERVED(2:19, uint32_t)             
+  } l;                                   /*!< \brief Structure used for bit access in long format */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} IFSR_Type;
+
+#define IFSR_ExT_Pos                     12U                                    /*!< \brief IFSR: ExT Position */
+#define IFSR_ExT_Msk                     (1UL << IFSR_ExT_Pos)                  /*!< \brief IFSR: ExT Mask */
+
+#define IFSR_FS1_Pos                     10U                                    /*!< \brief IFSR: FS1 Position */
+#define IFSR_FS1_Msk                     (1UL << IFSR_FS1_Pos)                  /*!< \brief IFSR: FS1 Mask */
+
+#define IFSR_LPAE_Pos                    9U                                     /*!< \brief IFSR: LPAE Position */
+#define IFSR_LPAE_Msk                    (0x1UL << IFSR_LPAE_Pos)               /*!< \brief IFSR: LPAE Mask */
+
+#define IFSR_FS0_Pos                     0U                                     /*!< \brief IFSR: FS0 Position */
+#define IFSR_FS0_Msk                     (0xFUL << IFSR_FS0_Pos)                /*!< \brief IFSR: FS0 Mask */
+
+#define IFSR_STATUS_Pos                  0U                                     /*!< \brief IFSR: STATUS Position */
+#define IFSR_STATUS_Msk                  (0x3FUL << IFSR_STATUS_Pos)            /*!< \brief IFSR: STATUS Mask */
+
+/* CP15 Register ISR */
+typedef union
+{
+  struct
+  {
+    RESERVED(0:6, uint32_t)              
+    uint32_t F:1;                        /*!< \brief bit:     6  FIQ pending bit */
+    uint32_t I:1;                        /*!< \brief bit:     7  IRQ pending bit */
+    uint32_t A:1;                        /*!< \brief bit:     8  External abort pending bit */
+    RESERVED(1:23, uint32_t)             
+  } b;                                   /*!< \brief Structure used for bit  access */
+  uint32_t w;                            /*!< \brief Type      used for word access */
+} ISR_Type;
+
+#define ISR_A_Pos                        13U                                    /*!< \brief ISR: A Position */
+#define ISR_A_Msk                        (1UL << ISR_A_Pos)                     /*!< \brief ISR: A Mask */
+
+#define ISR_I_Pos                        12U                                    /*!< \brief ISR: I Position */
+#define ISR_I_Msk                        (1UL << ISR_I_Pos)                     /*!< \brief ISR: I Mask */
+
+#define ISR_F_Pos                        11U                                    /*!< \brief ISR: F Position */
+#define ISR_F_Msk                        (1UL << ISR_F_Pos)                     /*!< \brief ISR: F Mask */
+
+/* DACR Register */
+#define DACR_D_Pos_(n)                   (2U*n)                                 /*!< \brief DACR: Dn Position */
+#define DACR_D_Msk_(n)                   (3UL << DACR_D_Pos_(n))                /*!< \brief DACR: Dn Mask */
+#define DACR_Dn_NOACCESS                 0U                                     /*!< \brief DACR Dn field: No access */
+#define DACR_Dn_CLIENT                   1U                                     /*!< \brief DACR Dn field: Client */
+#define DACR_Dn_MANAGER                  3U                                     /*!< \brief DACR Dn field: Manager */
+
+/**
+  \brief     Mask and shift a bit field value for use in a register bit range.
+  \param [in] field  Name of the register bit field.
+  \param [in] value  Value of the bit field. This parameter is interpreted as an uint32_t type.
+  \return           Masked and shifted value.
+*/
+#define _VAL2FLD(field, value)    (((uint32_t)(value) << field ## _Pos) & field ## _Msk)
+
+/**
+  \brief     Mask and shift a register value to extract a bit filed value.
+  \param [in] field  Name of the register bit field.
+  \param [in] value  Value of register. This parameter is interpreted as an uint32_t type.
+  \return           Masked and shifted bit field value.
+*/
+#define _FLD2VAL(field, value)    (((uint32_t)(value) & field ## _Msk) >> field ## _Pos)
+
+
+/**
+ \brief  Union type to access the L2C_310 Cache Controller.
+*/
+#if (__L2C_PRESENT == 1U) || defined(DOXYGEN)
+typedef struct
+{
+  __IM  uint32_t CACHE_ID;                   /*!< \brief Offset: 0x0000 (R/ ) Cache ID Register               */
+  __IM  uint32_t CACHE_TYPE;                 /*!< \brief Offset: 0x0004 (R/ ) Cache Type Register             */
+        RESERVED(0[0x3e], uint32_t)
+  __IOM uint32_t CONTROL;                    /*!< \brief Offset: 0x0100 (R/W) Control Register                */
+  __IOM uint32_t AUX_CNT;                    /*!< \brief Offset: 0x0104 (R/W) Auxiliary Control               */
+        RESERVED(1[0x3e], uint32_t)
+  __IOM uint32_t EVENT_CONTROL;              /*!< \brief Offset: 0x0200 (R/W) Event Counter Control           */
+  __IOM uint32_t EVENT_COUNTER1_CONF;        /*!< \brief Offset: 0x0204 (R/W) Event Counter 1 Configuration   */
+  __IOM uint32_t EVENT_COUNTER0_CONF;        /*!< \brief Offset: 0x0208 (R/W) Event Counter 1 Configuration   */
+        RESERVED(2[0x2], uint32_t)
+  __IOM uint32_t INTERRUPT_MASK;             /*!< \brief Offset: 0x0214 (R/W) Interrupt Mask                  */
+  __IM  uint32_t MASKED_INT_STATUS;          /*!< \brief Offset: 0x0218 (R/ ) Masked Interrupt Status         */
+  __IM  uint32_t RAW_INT_STATUS;             /*!< \brief Offset: 0x021c (R/ ) Raw Interrupt Status            */
+  __OM  uint32_t INTERRUPT_CLEAR;            /*!< \brief Offset: 0x0220 ( /W) Interrupt Clear                 */
+        RESERVED(3[0x143], uint32_t)
+  __IOM uint32_t CACHE_SYNC;                 /*!< \brief Offset: 0x0730 (R/W) Cache Sync                      */
+        RESERVED(4[0xf], uint32_t)
+  __IOM uint32_t INV_LINE_PA;                /*!< \brief Offset: 0x0770 (R/W) Invalidate Line By PA           */
+        RESERVED(6[2], uint32_t)
+  __IOM uint32_t INV_WAY;                    /*!< \brief Offset: 0x077c (R/W) Invalidate by Way               */
+        RESERVED(5[0xc], uint32_t)
+  __IOM uint32_t CLEAN_LINE_PA;              /*!< \brief Offset: 0x07b0 (R/W) Clean Line by PA                */
+        RESERVED(7[1], uint32_t)
+  __IOM uint32_t CLEAN_LINE_INDEX_WAY;       /*!< \brief Offset: 0x07b8 (R/W) Clean Line by Index/Way         */
+  __IOM uint32_t CLEAN_WAY;                  /*!< \brief Offset: 0x07bc (R/W) Clean by Way                    */
+        RESERVED(8[0xc], uint32_t)
+  __IOM uint32_t CLEAN_INV_LINE_PA;          /*!< \brief Offset: 0x07f0 (R/W) Clean and Invalidate Line by PA  */
+        RESERVED(9[1], uint32_t)
+  __IOM uint32_t CLEAN_INV_LINE_INDEX_WAY;   /*!< \brief Offset: 0x07f8 (R/W) Clean and Invalidate Line by Index/Way  */
+  __IOM uint32_t CLEAN_INV_WAY;              /*!< \brief Offset: 0x07fc (R/W) Clean and Invalidate by Way     */
+        RESERVED(10[0x40], uint32_t)
+  __IOM uint32_t DATA_LOCK_0_WAY;            /*!< \brief Offset: 0x0900 (R/W) Data Lockdown 0 by Way          */
+  __IOM uint32_t INST_LOCK_0_WAY;            /*!< \brief Offset: 0x0904 (R/W) Instruction Lockdown 0 by Way   */
+  __IOM uint32_t DATA_LOCK_1_WAY;            /*!< \brief Offset: 0x0908 (R/W) Data Lockdown 1 by Way          */
+  __IOM uint32_t INST_LOCK_1_WAY;            /*!< \brief Offset: 0x090c (R/W) Instruction Lockdown 1 by Way   */
+  __IOM uint32_t DATA_LOCK_2_WAY;            /*!< \brief Offset: 0x0910 (R/W) Data Lockdown 2 by Way          */
+  __IOM uint32_t INST_LOCK_2_WAY;            /*!< \brief Offset: 0x0914 (R/W) Instruction Lockdown 2 by Way   */
+  __IOM uint32_t DATA_LOCK_3_WAY;            /*!< \brief Offset: 0x0918 (R/W) Data Lockdown 3 by Way          */
+  __IOM uint32_t INST_LOCK_3_WAY;            /*!< \brief Offset: 0x091c (R/W) Instruction Lockdown 3 by Way   */
+  __IOM uint32_t DATA_LOCK_4_WAY;            /*!< \brief Offset: 0x0920 (R/W) Data Lockdown 4 by Way          */
+  __IOM uint32_t INST_LOCK_4_WAY;            /*!< \brief Offset: 0x0924 (R/W) Instruction Lockdown 4 by Way   */
+  __IOM uint32_t DATA_LOCK_5_WAY;            /*!< \brief Offset: 0x0928 (R/W) Data Lockdown 5 by Way          */
+  __IOM uint32_t INST_LOCK_5_WAY;            /*!< \brief Offset: 0x092c (R/W) Instruction Lockdown 5 by Way   */
+  __IOM uint32_t DATA_LOCK_6_WAY;            /*!< \brief Offset: 0x0930 (R/W) Data Lockdown 5 by Way          */
+  __IOM uint32_t INST_LOCK_6_WAY;            /*!< \brief Offset: 0x0934 (R/W) Instruction Lockdown 5 by Way   */
+  __IOM uint32_t DATA_LOCK_7_WAY;            /*!< \brief Offset: 0x0938 (R/W) Data Lockdown 6 by Way          */
+  __IOM uint32_t INST_LOCK_7_WAY;            /*!< \brief Offset: 0x093c (R/W) Instruction Lockdown 6 by Way   */
+        RESERVED(11[0x4], uint32_t)
+  __IOM uint32_t LOCK_LINE_EN;               /*!< \brief Offset: 0x0950 (R/W) Lockdown by Line Enable         */
+  __IOM uint32_t UNLOCK_ALL_BY_WAY;          /*!< \brief Offset: 0x0954 (R/W) Unlock All Lines by Way         */
+        RESERVED(12[0xaa], uint32_t)
+  __IOM uint32_t ADDRESS_FILTER_START;       /*!< \brief Offset: 0x0c00 (R/W) Address Filtering Start         */
+  __IOM uint32_t ADDRESS_FILTER_END;         /*!< \brief Offset: 0x0c04 (R/W) Address Filtering End           */
+        RESERVED(13[0xce], uint32_t)
+  __IOM uint32_t DEBUG_CONTROL;              /*!< \brief Offset: 0x0f40 (R/W) Debug Control Register          */
+} L2C_310_TypeDef;
+
+#define L2C_310           ((L2C_310_TypeDef *)L2C_310_BASE) /*!< \brief L2C_310 register set access pointer */
+#endif
+
+#if (__GIC_PRESENT == 1U) || defined(DOXYGEN)
+    
+/** \brief  Structure type to access the Generic Interrupt Controller Distributor (GICD)
+*/
+typedef struct
+{
+  __IOM uint32_t CTLR;                 /*!< \brief  Offset: 0x000 (R/W) Distributor Control Register */
+  __IM  uint32_t TYPER;                /*!< \brief  Offset: 0x004 (R/ ) Interrupt Controller Type Register */
+  __IM  uint32_t IIDR;                 /*!< \brief  Offset: 0x008 (R/ ) Distributor Implementer Identification Register */
+        RESERVED(0, uint32_t)
+  __IOM uint32_t STATUSR;              /*!< \brief  Offset: 0x010 (R/W) Error Reporting Status Register, optional */
+        RESERVED(1[11], uint32_t)
+  __OM  uint32_t SETSPI_NSR;           /*!< \brief  Offset: 0x040 ( /W) Set SPI Register */
+        RESERVED(2, uint32_t)
+  __OM  uint32_t CLRSPI_NSR;           /*!< \brief  Offset: 0x048 ( /W) Clear SPI Register */
+        RESERVED(3, uint32_t)
+  __OM  uint32_t SETSPI_SR;            /*!< \brief  Offset: 0x050 ( /W) Set SPI, Secure Register */
+        RESERVED(4, uint32_t)
+  __OM  uint32_t CLRSPI_SR;            /*!< \brief  Offset: 0x058 ( /W) Clear SPI, Secure Register */
+        RESERVED(5[9], uint32_t)
+  __IOM uint32_t IGROUPR[32];          /*!< \brief  Offset: 0x080 (R/W) Interrupt Group Registers */
+  __IOM uint32_t ISENABLER[32];        /*!< \brief  Offset: 0x100 (R/W) Interrupt Set-Enable Registers */
+  __IOM uint32_t ICENABLER[32];        /*!< \brief  Offset: 0x180 (R/W) Interrupt Clear-Enable Registers */
+  __IOM uint32_t ISPENDR[32];          /*!< \brief  Offset: 0x200 (R/W) Interrupt Set-Pending Registers */
+  __IOM uint32_t ICPENDR[32];          /*!< \brief  Offset: 0x280 (R/W) Interrupt Clear-Pending Registers */
+  __IOM uint32_t ISACTIVER[32];        /*!< \brief  Offset: 0x300 (R/W) Interrupt Set-Active Registers */
+  __IOM uint32_t ICACTIVER[32];        /*!< \brief  Offset: 0x380 (R/W) Interrupt Clear-Active Registers */
+  __IOM uint32_t IPRIORITYR[255];      /*!< \brief  Offset: 0x400 (R/W) Interrupt Priority Registers */
+        RESERVED(6, uint32_t)
+  __IOM uint32_t  ITARGETSR[255];      /*!< \brief  Offset: 0x800 (R/W) Interrupt Targets Registers */
+        RESERVED(7, uint32_t)
+  __IOM uint32_t ICFGR[64];            /*!< \brief  Offset: 0xC00 (R/W) Interrupt Configuration Registers */
+  __IOM uint32_t IGRPMODR[32];         /*!< \brief  Offset: 0xD00 (R/W) Interrupt Group Modifier Registers */
+        RESERVED(8[32], uint32_t)
+  __IOM uint32_t NSACR[64];            /*!< \brief  Offset: 0xE00 (R/W) Non-secure Access Control Registers */
+  __OM  uint32_t SGIR;                 /*!< \brief  Offset: 0xF00 ( /W) Software Generated Interrupt Register */
+        RESERVED(9[3], uint32_t)
+  __IOM uint32_t CPENDSGIR[4];         /*!< \brief  Offset: 0xF10 (R/W) SGI Clear-Pending Registers */
+  __IOM uint32_t SPENDSGIR[4];         /*!< \brief  Offset: 0xF20 (R/W) SGI Set-Pending Registers */
+        RESERVED(10[5236], uint32_t)
+  __IOM uint64_t IROUTER[988];         /*!< \brief  Offset: 0x6100(R/W) Interrupt Routing Registers */
+}  GICDistributor_Type;
+
+/** \brief  Structure type to access the Generic Interrupt Controller Interface (GICC)
+*/
+typedef struct
+{
+  __IOM uint32_t CTLR;                 /*!< \brief  Offset: 0x000 (R/W) CPU Interface Control Register */
+  __IOM uint32_t PMR;                  /*!< \brief  Offset: 0x004 (R/W) Interrupt Priority Mask Register */
+  __IOM uint32_t BPR;                  /*!< \brief  Offset: 0x008 (R/W) Binary Point Register */
+  __IM  uint32_t IAR;                  /*!< \brief  Offset: 0x00C (R/ ) Interrupt Acknowledge Register */
+  __OM  uint32_t EOIR;                 /*!< \brief  Offset: 0x010 ( /W) End Of Interrupt Register */
+  __IM  uint32_t RPR;                  /*!< \brief  Offset: 0x014 (R/ ) Running Priority Register */
+  __IM  uint32_t HPPIR;                /*!< \brief  Offset: 0x018 (R/ ) Highest Priority Pending Interrupt Register */
+  __IOM uint32_t ABPR;                 /*!< \brief  Offset: 0x01C (R/W) Aliased Binary Point Register */
+  __IM  uint32_t AIAR;                 /*!< \brief  Offset: 0x020 (R/ ) Aliased Interrupt Acknowledge Register */
+  __OM  uint32_t AEOIR;                /*!< \brief  Offset: 0x024 ( /W) Aliased End Of Interrupt Register */
+  __IM  uint32_t AHPPIR;               /*!< \brief  Offset: 0x028 (R/ ) Aliased Highest Priority Pending Interrupt Register */
+  __IOM uint32_t STATUSR;              /*!< \brief  Offset: 0x02C (R/W) Error Reporting Status Register, optional */
+        RESERVED(1[40], uint32_t)
+  __IOM uint32_t APR[4];               /*!< \brief  Offset: 0x0D0 (R/W) Active Priority Register */
+  __IOM uint32_t NSAPR[4];             /*!< \brief  Offset: 0x0E0 (R/W) Non-secure Active Priority Register */
+        RESERVED(2[3], uint32_t)
+  __IM  uint32_t IIDR;                 /*!< \brief  Offset: 0x0FC (R/ ) CPU Interface Identification Register */
+        RESERVED(3[960], uint32_t)
+  __OM  uint32_t DIR;                  /*!< \brief  Offset: 0x1000( /W) Deactivate Interrupt Register */
+}  GICInterface_Type;
+
+#endif
+
+#if (__TIM_PRESENT == 1U) || defined(DOXYGEN)
+#if ((__CORTEX_A == 5U) || (__CORTEX_A == 9U)) || defined(DOXYGEN)
+/** \brief Structure type to access the Private Timer
+*/
+typedef struct
+{
+  __IOM uint32_t LOAD;            //!< \brief  Offset: 0x000 (R/W) Private Timer Load Register
+  __IOM uint32_t COUNTER;         //!< \brief  Offset: 0x004 (R/W) Private Timer Counter Register
+  __IOM uint32_t CONTROL;         //!< \brief  Offset: 0x008 (R/W) Private Timer Control Register
+  __IOM uint32_t ISR;             //!< \brief  Offset: 0x00C (R/W) Private Timer Interrupt Status Register
+        RESERVED(0[4], uint32_t)
+  __IOM uint32_t WLOAD;           //!< \brief  Offset: 0x020 (R/W) Watchdog Load Register
+  __IOM uint32_t WCOUNTER;        //!< \brief  Offset: 0x024 (R/W) Watchdog Counter Register
+  __IOM uint32_t WCONTROL;        //!< \brief  Offset: 0x028 (R/W) Watchdog Control Register
+  __IOM uint32_t WISR;            //!< \brief  Offset: 0x02C (R/W) Watchdog Interrupt Status Register
+  __IOM uint32_t WRESET;          //!< \brief  Offset: 0x030 (R/W) Watchdog Reset Status Register
+  __OM  uint32_t WDISABLE;        //!< \brief  Offset: 0x034 ( /W) Watchdog Disable Register
+} Timer_Type;
+#define PTIM ((Timer_Type *) TIMER_BASE )   /*!< \brief Timer register struct */
+#endif
+#endif
+
+ /*******************************************************************************
+  *                Hardware Abstraction Layer
+   Core Function Interface contains:
+   - L1 Cache Functions
+   - L2C-310 Cache Controller Functions 
+   - PL1 Timer Functions
+   - GIC Functions
+   - MMU Functions
+  ******************************************************************************/
+ 
+/* ##########################  L1 Cache functions  ################################# */
+
+/** \brief Enable Caches by setting I and C bits in SCTLR register.
+*/
+__STATIC_FORCEINLINE void L1C_EnableCaches(void) {
+  __set_SCTLR( __get_SCTLR() | SCTLR_I_Msk | SCTLR_C_Msk);
+  __ISB();
+}
+
+/** \brief Disable Caches by clearing I and C bits in SCTLR register.
+*/
+__STATIC_FORCEINLINE void L1C_DisableCaches(void) {
+  __set_SCTLR( __get_SCTLR() & (~SCTLR_I_Msk) & (~SCTLR_C_Msk));
+  __ISB();
+}
+
+/** \brief  Enable Branch Prediction by setting Z bit in SCTLR register.
+*/
+__STATIC_FORCEINLINE void L1C_EnableBTAC(void) {
+  __set_SCTLR( __get_SCTLR() | SCTLR_Z_Msk);
+  __ISB();
+}
+
+/** \brief  Disable Branch Prediction by clearing Z bit in SCTLR register.
+*/
+__STATIC_FORCEINLINE void L1C_DisableBTAC(void) {
+  __set_SCTLR( __get_SCTLR() & (~SCTLR_Z_Msk));
+  __ISB();
+}
+
+/** \brief  Invalidate entire branch predictor array
+*/
+__STATIC_FORCEINLINE void L1C_InvalidateBTAC(void) {
+  __set_BPIALL(0);
+  __DSB();     //ensure completion of the invalidation
+  __ISB();     //ensure instruction fetch path sees new state
+}
+
+/** \brief  Invalidate the whole instruction cache
+*/
+__STATIC_FORCEINLINE void L1C_InvalidateICacheAll(void) {
+  __set_ICIALLU(0);
+  __DSB();     //ensure completion of the invalidation
+  __ISB();     //ensure instruction fetch path sees new I cache state
+}
+
+/** \brief  Clean data cache line by address.
+* \param [in] va Pointer to data to clear the cache for.
+*/
+__STATIC_FORCEINLINE void L1C_CleanDCacheMVA(void *va) {
+  __set_DCCMVAC((uint32_t)va);
+  __DMB();     //ensure the ordering of data cache maintenance operations and their effects
+}
+
+/** \brief  Invalidate data cache line by address.
+* \param [in] va Pointer to data to invalidate the cache for.
+*/
+__STATIC_FORCEINLINE void L1C_InvalidateDCacheMVA(void *va) {
+  __set_DCIMVAC((uint32_t)va);
+  __DMB();     //ensure the ordering of data cache maintenance operations and their effects
+}
+
+/** \brief  Clean and Invalidate data cache by address.
+* \param [in] va Pointer to data to invalidate the cache for.
+*/
+__STATIC_FORCEINLINE void L1C_CleanInvalidateDCacheMVA(void *va) {
+  __set_DCCIMVAC((uint32_t)va);
+  __DMB();     //ensure the ordering of data cache maintenance operations and their effects
+}
+
+/** \brief Calculate log2 rounded up
+*  - log(0)  => 0
+*  - log(1)  => 0
+*  - log(2)  => 1
+*  - log(3)  => 2
+*  - log(4)  => 2
+*  - log(5)  => 3
+*        :      :
+*  - log(16) => 4
+*  - log(32) => 5
+*        :      :
+* \param [in] n input value parameter 
+* \return log2(n)
+*/
+__STATIC_FORCEINLINE uint8_t __log2_up(uint32_t n)
+{
+  if (n < 2U) {
+    return 0U;
+  }
+  uint8_t log = 0U;
+  uint32_t t = n;
+  while(t > 1U)
+  {
+    log++;
+    t >>= 1U;
+  }
+  if (n & 1U) { log++; }
+  return log;
+}
+
+/** \brief  Apply cache maintenance to given cache level.
+* \param [in] level cache level to be maintained
+* \param [in] maint 0 - invalidate, 1 - clean, otherwise - invalidate and clean
+*/
+__STATIC_FORCEINLINE void __L1C_MaintainDCacheSetWay(uint32_t level, uint32_t maint)
+{
+  uint32_t Dummy;
+  uint32_t ccsidr;
+  uint32_t num_sets;
+  uint32_t num_ways;
+  uint32_t shift_way;
+  uint32_t log2_linesize;
+   int32_t log2_num_ways;
+
+  Dummy = level << 1U;
+  /* set csselr, select ccsidr register */
+  __set_CSSELR(Dummy);
+  /* get current ccsidr register */
+  ccsidr = __get_CCSIDR();
+  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
+  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
+  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
+  log2_num_ways = __log2_up(num_ways);
+  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
+    return; // FATAL ERROR
+  }
+  shift_way = 32U - (uint32_t)log2_num_ways;
+  for(int32_t way = num_ways-1; way >= 0; way--)
+  {
+    for(int32_t set = num_sets-1; set >= 0; set--)
+    {
+      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
+      switch (maint)
+      {
+        case 0U: __set_DCISW(Dummy);  break;
+        case 1U: __set_DCCSW(Dummy);  break;
+        default: __set_DCCISW(Dummy); break;
+      }
+    }
+  }
+  __DMB();
+}
+
+/** \brief  Clean and Invalidate the entire data or unified cache
+* Generic mechanism for cleaning/invalidating the entire data or unified cache to the point of coherency
+* \param [in] op 0 - invalidate, 1 - clean, otherwise - invalidate and clean
+*/
+__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
+  uint32_t clidr;
+  uint32_t cache_type;
+  clidr =  __get_CLIDR();
+  for(uint32_t i = 0U; i<7U; i++)
+  {
+    cache_type = (clidr >> i*3U) & 0x7UL;
+    if ((cache_type >= 2U) && (cache_type <= 4U))
+    {
+      __L1C_MaintainDCacheSetWay(i, op);
+    }
+  }
+}
+
+/** \brief  Clean and Invalidate the entire data or unified cache
+* Generic mechanism for cleaning/invalidating the entire data or unified cache to the point of coherency
+* \param [in] op 0 - invalidate, 1 - clean, otherwise - invalidate and clean
+* \deprecated Use generic L1C_CleanInvalidateCache instead.
+*/
+CMSIS_DEPRECATED
+__STATIC_FORCEINLINE void __L1C_CleanInvalidateCache(uint32_t op) {
+  L1C_CleanInvalidateCache(op);
+}
+
+/** \brief  Invalidate the whole data cache.
+*/
+__STATIC_FORCEINLINE void L1C_InvalidateDCacheAll(void) {
+  L1C_CleanInvalidateCache(0);
+}
+
+/** \brief  Clean the whole data cache.
+ */
+__STATIC_FORCEINLINE void L1C_CleanDCacheAll(void) {
+  L1C_CleanInvalidateCache(1);
+}
+
+/** \brief  Clean and invalidate the whole data cache.
+ */
+__STATIC_FORCEINLINE void L1C_CleanInvalidateDCacheAll(void) {
+  L1C_CleanInvalidateCache(2);
+}
+
+/* ##########################  L2 Cache functions  ################################# */
+#if (__L2C_PRESENT == 1U) || defined(DOXYGEN)
+/** \brief Cache Sync operation by writing CACHE_SYNC register.
+*/
+__STATIC_INLINE void L2C_Sync(void)
+{
+  L2C_310->CACHE_SYNC = 0x0;
+}
+
+/** \brief Read cache controller cache ID from CACHE_ID register.
+ * \return L2C_310_TypeDef::CACHE_ID
+ */
+__STATIC_INLINE int L2C_GetID (void)
+{
+  return L2C_310->CACHE_ID;
+}
+
+/** \brief Read cache controller cache type from CACHE_TYPE register.
+*  \return L2C_310_TypeDef::CACHE_TYPE
+*/
+__STATIC_INLINE int L2C_GetType (void)
+{
+  return L2C_310->CACHE_TYPE;
+}
+
+/** \brief Invalidate all cache by way
+*/
+__STATIC_INLINE void L2C_InvAllByWay (void)
+{
+  unsigned int assoc;
+
+  if (L2C_310->AUX_CNT & (1U << 16U)) {
+    assoc = 16U;
+  } else {
+    assoc =  8U;
+  }
+  
+  L2C_310->INV_WAY = (1U << assoc) - 1U;
+  while(L2C_310->INV_WAY & ((1U << assoc) - 1U)); //poll invalidate
+
+  L2C_Sync();
+}
+
+/** \brief Clean and Invalidate all cache by way
+*/
+__STATIC_INLINE void L2C_CleanInvAllByWay (void)
+{
+  unsigned int assoc;
+
+  if (L2C_310->AUX_CNT & (1U << 16U)) {
+    assoc = 16U;
+  } else {
+    assoc =  8U;
+  }
+
+  L2C_310->CLEAN_INV_WAY = (1U << assoc) - 1U;
+  while(L2C_310->CLEAN_INV_WAY & ((1U << assoc) - 1U)); //poll invalidate
+
+  L2C_Sync();
+}
+
+/** \brief Enable Level 2 Cache
+*/
+__STATIC_INLINE void L2C_Enable(void)
+{
+  L2C_310->CONTROL = 0;
+  L2C_310->INTERRUPT_CLEAR = 0x000001FFuL;
+  L2C_310->DEBUG_CONTROL = 0;
+  L2C_310->DATA_LOCK_0_WAY = 0;
+  L2C_310->CACHE_SYNC = 0;
+  L2C_310->CONTROL = 0x01;
+  L2C_Sync();
+}
+
+/** \brief Disable Level 2 Cache
+*/
+__STATIC_INLINE void L2C_Disable(void)
+{
+  L2C_310->CONTROL = 0x00;
+  L2C_Sync();
+}
+
+/** \brief Invalidate cache by physical address
+* \param [in] pa Pointer to data to invalidate cache for.
+*/
+__STATIC_INLINE void L2C_InvPa (void *pa)
+{
+  L2C_310->INV_LINE_PA = (unsigned int)pa;
+  L2C_Sync();
+}
+
+/** \brief Clean cache by physical address
+* \param [in] pa Pointer to data to invalidate cache for.
+*/
+__STATIC_INLINE void L2C_CleanPa (void *pa)
+{
+  L2C_310->CLEAN_LINE_PA = (unsigned int)pa;
+  L2C_Sync();
+}
+
+/** \brief Clean and invalidate cache by physical address
+* \param [in] pa Pointer to data to invalidate cache for.
+*/
+__STATIC_INLINE void L2C_CleanInvPa (void *pa)
+{
+  L2C_310->CLEAN_INV_LINE_PA = (unsigned int)pa;
+  L2C_Sync();
+}
+#endif
+
+/* ##########################  GIC functions  ###################################### */
+#if (__GIC_PRESENT == 1U) || defined(DOXYGEN)
+  
+/** \brief  Enable the interrupt distributor using the GIC's CTLR register.
+*/
+__STATIC_INLINE void GIC_EnableDistributor(GICDistributor_Type *GICDistributor)
+{
+  GICDistributor->CTLR |= 1U;
+}
+
+/** \brief Disable the interrupt distributor using the GIC's CTLR register.
+*/
+__STATIC_INLINE void GIC_DisableDistributor(GICDistributor_Type *GICDistributor)
+{
+  GICDistributor->CTLR &=~1U;
+}
+
+/** \brief Read the GIC's TYPER register.
+* \return GICDistributor_Type::TYPER
+*/
+__STATIC_INLINE uint32_t GIC_DistributorInfo(GICDistributor_Type *GICDistributor)
+{
+  return (GICDistributor->TYPER);
+}
+
+/** \brief Reads the GIC's IIDR register.
+* \return GICDistributor_Type::IIDR
+*/
+__STATIC_INLINE uint32_t GIC_DistributorImplementer(GICDistributor_Type *GICDistributor)
+{
+  return (GICDistributor->IIDR);
+}
+
+/** \brief Sets the GIC's ITARGETSR register for the given interrupt.
+* \param [in] IRQn Interrupt to be configured.
+* \param [in] cpu_target CPU interfaces to assign this interrupt to.
+*/
+__STATIC_INLINE void GIC_SetTarget(GICDistributor_Type *GICDistributor, IRQn_Type IRQn, uint32_t cpu_target)
+{
+  uint32_t mask = GICDistributor->ITARGETSR[IRQn / 4U] & ~(0xFFUL << ((IRQn % 4U) * 8U));
+  GICDistributor->ITARGETSR[IRQn / 4U] = mask | ((cpu_target & 0xFFUL) << ((IRQn % 4U) * 8U));
+}
+
+/** \brief Read the GIC's ITARGETSR register.
+* \param [in] IRQn Interrupt to acquire the configuration for.
+* \return GICDistributor_Type::ITARGETSR
+*/
+__STATIC_INLINE uint32_t GIC_GetTarget(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  return (GICDistributor->ITARGETSR[IRQn / 4U] >> ((IRQn % 4U) * 8U)) & 0xFFUL;
+}
+
+/** \brief Enable the CPU's interrupt interface.
+*/
+__STATIC_INLINE void GIC_EnableInterface(GICInterface_Type *GICInterface)
+{
+  GICInterface->CTLR |= 1U; //enable interface
+}
+
+/** \brief Disable the CPU's interrupt interface.
+*/
+__STATIC_INLINE void GIC_DisableInterface(GICInterface_Type *GICInterface)
+{
+  GICInterface->CTLR &=~1U; //disable distributor
+}
+
+/** \brief Read the CPU's IAR register.
+* \return GICInterface_Type::IAR
+*/
+__STATIC_INLINE IRQn_Type GIC_AcknowledgePending(GICInterface_Type *GICInterface)
+{
+  return (IRQn_Type)(GICInterface->IAR);
+}
+
+/** \brief Writes the given interrupt number to the CPU's EOIR register.
+* \param [in] IRQn The interrupt to be signaled as finished.
+*/
+__STATIC_INLINE void GIC_EndInterrupt(GICInterface_Type *GICInterface, IRQn_Type IRQn)
+{
+  GICInterface->EOIR = IRQn;
+}
+
+/** \brief Enables the given interrupt using GIC's ISENABLER register.
+* \param [in] IRQn The interrupt to be enabled.
+*/
+__STATIC_INLINE void GIC_EnableIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  GICDistributor->ISENABLER[IRQn / 32U] = 1U << (IRQn % 32U);
+}
+
+/** \brief Get interrupt enable status using GIC's ISENABLER register.
+* \param [in] IRQn The interrupt to be queried.
+* \return 0 - interrupt is not enabled, 1 - interrupt is enabled.
+*/
+__STATIC_INLINE uint32_t GIC_GetEnableIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  return (GICDistributor->ISENABLER[IRQn / 32U] >> (IRQn % 32U)) & 1UL;
+}
+
+/** \brief Disables the given interrupt using GIC's ICENABLER register.
+* \param [in] IRQn The interrupt to be disabled.
+*/
+__STATIC_INLINE void GIC_DisableIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  GICDistributor->ICENABLER[IRQn / 32U] = 1U << (IRQn % 32U);
+}
+
+/** \brief Get interrupt pending status from GIC's ISPENDR register.
+* \param [in] IRQn The interrupt to be queried.
+* \return 0 - interrupt is not pending, 1 - interrupt is pendig.
+*/
+__STATIC_INLINE uint32_t GIC_GetPendingIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  uint32_t pend;
+
+  if (IRQn >= 16U) {
+    pend = (GICDistributor->ISPENDR[IRQn / 32U] >> (IRQn % 32U)) & 1UL;
+  } else {
+    // INTID 0-15 Software Generated Interrupt
+    pend = (GICDistributor->SPENDSGIR[IRQn / 4U] >> ((IRQn % 4U) * 8U)) & 0xFFUL;
+    // No CPU identification offered
+    if (pend != 0U) {
+      pend = 1U;
+    } else {
+      pend = 0U;
+    }
+  }
+
+  return (pend);
+}
+
+/** \brief Sets the given interrupt as pending using GIC's ISPENDR register.
+* \param [in] IRQn The interrupt to be enabled.
+*/
+__STATIC_INLINE void GIC_SetPendingIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  if (IRQn >= 16U) {
+    GICDistributor->ISPENDR[IRQn / 32U] = 1U << (IRQn % 32U);
+  } else {
+    // INTID 0-15 Software Generated Interrupt
+    GICDistributor->SPENDSGIR[IRQn / 4U] = 1U << ((IRQn % 4U) * 8U);
+  }
+}
+
+/** \brief Clears the given interrupt from being pending using GIC's ICPENDR register.
+* \param [in] IRQn The interrupt to be enabled.
+*/
+__STATIC_INLINE void GIC_ClearPendingIRQ(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  if (IRQn >= 16U) {
+    GICDistributor->ICPENDR[IRQn / 32U] = 1U << (IRQn % 32U);
+  } else {
+    // INTID 0-15 Software Generated Interrupt
+    GICDistributor->CPENDSGIR[IRQn / 4U] = 1U << ((IRQn % 4U) * 8U);
+  }
+}
+
+/** \brief Sets the interrupt configuration using GIC's ICFGR register.
+* \param [in] IRQn The interrupt to be configured.
+* \param [in] int_config Int_config field value. Bit 0: Reserved (0 - N-N model, 1 - 1-N model for some GIC before v1)
+*                                           Bit 1: 0 - level sensitive, 1 - edge triggered
+*/
+__STATIC_INLINE void GIC_SetConfiguration(GICDistributor_Type *GICDistributor, IRQn_Type IRQn, uint32_t int_config)
+{
+  uint32_t icfgr = GICDistributor->ICFGR[IRQn / 16U];
+  uint32_t shift = (IRQn % 16U) << 1U;
+
+  icfgr &= (~(3U         << shift));
+  icfgr |= (  int_config << shift);
+
+  GICDistributor->ICFGR[IRQn / 16U] = icfgr;
+}
+
+/** \brief Get the interrupt configuration from the GIC's ICFGR register.
+* \param [in] IRQn Interrupt to acquire the configuration for.
+* \return Int_config field value. Bit 0: Reserved (0 - N-N model, 1 - 1-N model for some GIC before v1)
+*                                 Bit 1: 0 - level sensitive, 1 - edge triggered
+*/
+__STATIC_INLINE uint32_t GIC_GetConfiguration(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  return (GICDistributor->ICFGR[IRQn / 16U] >> ((IRQn % 16U) >> 1U));
+}
+
+/** \brief Set the priority for the given interrupt in the GIC's IPRIORITYR register.
+* \param [in] IRQn The interrupt to be configured.
+* \param [in] priority The priority for the interrupt, lower values denote higher priorities.
+*/
+__STATIC_INLINE void GIC_SetPriority(GICDistributor_Type *GICDistributor, IRQn_Type IRQn, uint32_t priority)
+{
+  uint32_t mask = GICDistributor->IPRIORITYR[IRQn / 4U] & ~(0xFFUL << ((IRQn % 4U) * 8U));
+  GICDistributor->IPRIORITYR[IRQn / 4U] = mask | ((priority & 0xFFUL) << ((IRQn % 4U) * 8U));
+}
+
+/** \brief Read the current interrupt priority from GIC's IPRIORITYR register.
+* \param [in] IRQn The interrupt to be queried.
+*/
+__STATIC_INLINE uint32_t GIC_GetPriority(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  return (GICDistributor->IPRIORITYR[IRQn / 4U] >> ((IRQn % 4U) * 8U)) & 0xFFUL;
+}
+
+/** \brief Set the interrupt priority mask using CPU's PMR register.
+* \param [in] priority Priority mask to be set.
+*/
+__STATIC_INLINE void GIC_SetInterfacePriorityMask(GICInterface_Type *GICInterface, uint32_t priority)
+{
+  GICInterface->PMR = priority & 0xFFUL; //set priority mask
+}
+
+/** \brief Read the current interrupt priority mask from CPU's PMR register.
+* \result GICInterface_Type::PMR
+*/
+__STATIC_INLINE uint32_t GIC_GetInterfacePriorityMask(GICInterface_Type *GICInterface)
+{
+  return GICInterface->PMR;
+}
+
+/** \brief Configures the group priority and subpriority split point using CPU's BPR register.
+* \param [in] binary_point Amount of bits used as subpriority.
+*/
+__STATIC_INLINE void GIC_SetBinaryPoint(GICInterface_Type *GICInterface, uint32_t binary_point)
+{
+  GICInterface->BPR = binary_point & 7U; //set binary point
+}
+
+/** \brief Read the current group priority and subpriority split point from CPU's BPR register.
+* \return GICInterface_Type::BPR
+*/
+__STATIC_INLINE uint32_t GIC_GetBinaryPoint(GICInterface_Type *GICInterface)
+{
+  return GICInterface->BPR;
+}
+
+/** \brief Get the status for a given interrupt.
+* \param [in] IRQn The interrupt to get status for.
+* \return 0 - not pending/active, 1 - pending, 2 - active, 3 - pending and active
+*/
+__STATIC_INLINE uint32_t GIC_GetIRQStatus(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  uint32_t pending, active;
+
+  active = ((GICDistributor->ISACTIVER[IRQn / 32U])  >> (IRQn % 32U)) & 1UL;
+  pending = ((GICDistributor->ISPENDR[IRQn / 32U]) >> (IRQn % 32U)) & 1UL;
+
+  return ((active<<1U) | pending);
+}
+
+/** \brief Generate a software interrupt using GIC's SGIR register.
+* \param [in] IRQn Software interrupt to be generated.
+* \param [in] target_list List of CPUs the software interrupt should be forwarded to.
+* \param [in] filter_list Filter to be applied to determine interrupt receivers.
+*/
+__STATIC_INLINE void GIC_SendSGI(GICDistributor_Type *GICDistributor, IRQn_Type IRQn, uint32_t target_list, uint32_t filter_list)
+{
+  GICDistributor->SGIR = ((filter_list & 3U) << 24U) | ((target_list & 0xFFUL) << 16U) | (IRQn & 0x0FUL);
+}
+
+/** \brief Get the interrupt number of the highest interrupt pending from CPU's HPPIR register.
+* \return GICInterface_Type::HPPIR
+*/
+__STATIC_INLINE uint32_t GIC_GetHighPendingIRQ(GICInterface_Type *GICInterface) 
+{ 
+  return GICInterface->HPPIR; 
+}
+
+/** \brief Provides information about the implementer and revision of the CPU interface.
+* \return GICInterface_Type::IIDR
+*/
+__STATIC_INLINE uint32_t GIC_GetInterfaceId(GICInterface_Type *GICInterface)
+{ 
+  return GICInterface->IIDR; 
+}
+
+/** \brief Set the interrupt group from the GIC's IGROUPR register.
+* \param [in] IRQn The interrupt to be queried.
+* \param [in] group Interrupt group number: 0 - Group 0, 1 - Group 1
+*/
+__STATIC_INLINE void GIC_SetGroup(GICDistributor_Type *GICDistributor, IRQn_Type IRQn, uint32_t group)
+{
+  uint32_t igroupr = GICDistributor->IGROUPR[IRQn / 32U];
+  uint32_t shift   = (IRQn % 32U);
+
+  igroupr &= (~(1U          << shift));
+  igroupr |= ( (group & 1U) << shift);
+
+  GICDistributor->IGROUPR[IRQn / 32U] = igroupr;
+}
+#define GIC_SetSecurity         GIC_SetGroup
+
+/** \brief Get the interrupt group from the GIC's IGROUPR register.
+* \param [in] IRQn The interrupt to be queried.
+* \return 0 - Group 0, 1 - Group 1
+*/
+__STATIC_INLINE uint32_t GIC_GetGroup(GICDistributor_Type *GICDistributor, IRQn_Type IRQn)
+{
+  return (GICDistributor->IGROUPR[IRQn / 32U] >> (IRQn % 32U)) & 1UL;
+}
+#define GIC_GetSecurity         GIC_GetGroup
+
+/** \brief Initialize the interrupt distributor.
+*/
+__STATIC_INLINE void GIC_DistInit(GICDistributor_Type *GICDistributor)
+{
+  uint32_t i;
+  uint32_t num_irq = 0U;
+  uint32_t priority_field;
+
+  //A reset sets all bits in the IGROUPRs corresponding to the SPIs to 0,
+  //configuring all of the interrupts as Secure.
+
+  //Disable interrupt forwarding
+  GIC_DisableDistributor(GICDistributor);
+  //Get the maximum number of interrupts that the GIC supports
+  num_irq = 32U * ((GIC_DistributorInfo(GICDistributor) & 0x1FU) + 1U);
+
+  /* Priority level is implementation defined.
+   To determine the number of priority bits implemented write 0xFF to an IPRIORITYR
+   priority field and read back the value stored.*/
+  GIC_SetPriority(GICDistributor, (IRQn_Type)0U, 0xFFU);
+  priority_field = GIC_GetPriority(GICDistributor, (IRQn_Type)0U);
+
+  for (i = 32U; i < num_irq; i++)
+  {
+      //Disable the SPI interrupt
+      GIC_DisableIRQ(GICDistributor, (IRQn_Type)i);
+      //Set level-sensitive (and N-N model)
+      GIC_SetConfiguration(GICDistributor, (IRQn_Type)i, 0U);
+      //Set priority
+      GIC_SetPriority(GICDistributor, (IRQn_Type)i, priority_field/2U);
+      //Set target list to CPU0
+      GIC_SetTarget(GICDistributor, (IRQn_Type)i, 1U);
+  }
+  //Enable distributor
+  GIC_EnableDistributor(GICDistributor);
+}
+
+/** \brief Initialize the CPU's interrupt interface
+*/
+__STATIC_INLINE void GIC_CPUInterfaceInit(GICDistributor_Type *GICDistributor, GICInterface_Type *GICInterface)
+{
+  uint32_t i;
+  uint32_t priority_field;
+
+  //A reset sets all bits in the IGROUPRs corresponding to the SPIs to 0,
+  //configuring all of the interrupts as Secure.
+
+  //Disable interrupt forwarding
+  GIC_DisableInterface(GICInterface);
+
+  /* Priority level is implementation defined.
+   To determine the number of priority bits implemented write 0xFF to an IPRIORITYR
+   priority field and read back the value stored.*/
+  GIC_SetPriority(GICDistributor, (IRQn_Type)0U, 0xFFU);
+  priority_field = GIC_GetPriority(GICDistributor, (IRQn_Type)0U);
+
+  //SGI and PPI
+  for (i = 0U; i < 32U; i++)
+  {
+    if(i > 15U) {
+      //Set level-sensitive (and N-N model) for PPI
+      GIC_SetConfiguration(GICDistributor, (IRQn_Type)i, 0U);
+    }
+    //Disable SGI and PPI interrupts
+    GIC_DisableIRQ(GICDistributor, (IRQn_Type)i);
+    //Set priority
+    GIC_SetPriority(GICDistributor, (IRQn_Type)i, priority_field/2U);
+  }
+  //Enable interface
+  GIC_EnableInterface(GICInterface);
+  //Set binary point to 0
+  GIC_SetBinaryPoint(GICInterface, 0U);
+  //Set priority mask
+  GIC_SetInterfacePriorityMask(GICInterface, 0xFFU);
+}
+
+/** \brief Initialize and enable the GIC
+*/
+__STATIC_INLINE void GIC_Enable(GICDistributor_Type *GICDistributor, GICInterface_Type *GICInterface)
+{
+  GIC_DistInit(GICDistributor);
+  GIC_CPUInterfaceInit(GICDistributor, GICInterface); //per CPU
+}
+#endif
+
+/* ##########################  Generic Timer functions  ############################ */
+#if (__TIM_PRESENT == 1U) || defined(DOXYGEN)
+  
+/* PL1 Physical Timer */
+#if (__CORTEX_A == 7U) || defined(DOXYGEN)
+  
+/** \brief Physical Timer Control register */
+typedef union
+{
+  struct
+  {
+    uint32_t ENABLE:1;      /*!< \brief bit: 0      Enables the timer. */
+    uint32_t IMASK:1;       /*!< \brief bit: 1      Timer output signal mask bit. */
+    uint32_t ISTATUS:1;     /*!< \brief bit: 2      The status of the timer. */
+    RESERVED(0:29, uint32_t)
+  } b;                      /*!< \brief Structure used for bit  access */
+  uint32_t w;               /*!< \brief Type      used for word access */
+} CNTP_CTL_Type;
+
+/** \brief Configures the frequency the timer shall run at.
+* \param [in] value The timer frequency in Hz.
+*/
+__STATIC_INLINE void PL1_SetCounterFrequency(uint32_t value)
+{
+  __set_CNTFRQ(value);
+  __ISB();
+}
+
+/** \brief Sets the reset value of the timer.
+* \param [in] value The value the timer is loaded with.
+*/
+__STATIC_INLINE void PL1_SetLoadValue(uint32_t value)
+{
+  __set_CNTP_TVAL(value);
+  __ISB();
+}
+
+/** \brief Get the current counter value.
+* \return Current counter value.
+*/
+__STATIC_INLINE uint32_t PL1_GetCurrentValue(void)
+{
+  return(__get_CNTP_TVAL());
+}
+
+/** \brief Get the current physical counter value.
+* \return Current physical counter value.
+*/
+__STATIC_INLINE uint64_t PL1_GetCurrentPhysicalValue(void)
+{
+  return(__get_CNTPCT());
+}
+
+/** \brief Set the physical compare value.
+* \param [in] value New physical timer compare value.
+*/
+__STATIC_INLINE void PL1_SetPhysicalCompareValue(uint64_t value)
+{
+  __set_CNTP_CVAL(value);
+  __ISB();
+}
+
+/** \brief Get the physical compare value.
+* \return Physical compare value.
+*/
+__STATIC_INLINE uint64_t PL1_GetPhysicalCompareValue(void)
+{
+  return(__get_CNTP_CVAL());
+}
+
+/** \brief Configure the timer by setting the control value.
+* \param [in] value New timer control value.
+*/
+__STATIC_INLINE void PL1_SetControl(uint32_t value)
+{
+  __set_CNTP_CTL(value);
+  __ISB();
+}
+
+/** \brief Get the control value.
+* \return Control value.
+*/
+__STATIC_INLINE uint32_t PL1_GetControl(void)
+{
+  return(__get_CNTP_CTL());
+}
+#endif
+
+/* Private Timer */
+#if ((__CORTEX_A == 5U) || (__CORTEX_A == 9U)) || defined(DOXYGEN)
+/** \brief Set the load value to timers LOAD register.
+* \param [in] value The load value to be set.
+*/
+__STATIC_INLINE void PTIM_SetLoadValue(uint32_t value)
+{
+  PTIM->LOAD = value;
+}
+
+/** \brief Get the load value from timers LOAD register.
+* \return Timer_Type::LOAD
+*/
+__STATIC_INLINE uint32_t PTIM_GetLoadValue(void)
+{
+  return(PTIM->LOAD);
+}
+
+/** \brief Set current counter value from its COUNTER register.
+*/
+__STATIC_INLINE void PTIM_SetCurrentValue(uint32_t value)
+{
+  PTIM->COUNTER = value;
+}
+
+/** \brief Get current counter value from timers COUNTER register.
+* \result Timer_Type::COUNTER
+*/
+__STATIC_INLINE uint32_t PTIM_GetCurrentValue(void)
+{
+  return(PTIM->COUNTER);
+}
+
+/** \brief Configure the timer using its CONTROL register.
+* \param [in] value The new configuration value to be set.
+*/
+__STATIC_INLINE void PTIM_SetControl(uint32_t value)
+{
+  PTIM->CONTROL = value;
+}
+
+/** ref Timer_Type::CONTROL Get the current timer configuration from its CONTROL register.
+* \return Timer_Type::CONTROL
+*/
+__STATIC_INLINE uint32_t PTIM_GetControl(void)
+{
+  return(PTIM->CONTROL);
+}
+
+/** ref Timer_Type::CONTROL Get the event flag in timers ISR register.
+* \return 0 - flag is not set, 1- flag is set
+*/
+__STATIC_INLINE uint32_t PTIM_GetEventFlag(void)
+{
+  return (PTIM->ISR & 1UL);
+}
+
+/** ref Timer_Type::CONTROL Clears the event flag in timers ISR register.
+*/
+__STATIC_INLINE void PTIM_ClearEventFlag(void)
+{
+  PTIM->ISR = 1;
+}
+#endif
+#endif
+
+/* ##########################  MMU functions  ###################################### */
+
+#define SECTION_DESCRIPTOR      (0x2)
+#define SECTION_MASK            (0xFFFFFFFC)
+
+#define SECTION_TEXCB_MASK      (0xFFFF8FF3)
+#define SECTION_B_SHIFT         (2)
+#define SECTION_C_SHIFT         (3)
+#define SECTION_TEX0_SHIFT      (12)
+#define SECTION_TEX1_SHIFT      (13)
+#define SECTION_TEX2_SHIFT      (14)
+
+#define SECTION_XN_MASK         (0xFFFFFFEF)
+#define SECTION_XN_SHIFT        (4)
+
+#define SECTION_DOMAIN_MASK     (0xFFFFFE1F)
+#define SECTION_DOMAIN_SHIFT    (5)
+
+#define SECTION_P_MASK          (0xFFFFFDFF)
+#define SECTION_P_SHIFT         (9)
+
+#define SECTION_AP_MASK         (0xFFFF73FF)
+#define SECTION_AP_SHIFT        (10)
+#define SECTION_AP2_SHIFT       (15)
+
+#define SECTION_S_MASK          (0xFFFEFFFF)
+#define SECTION_S_SHIFT         (16)
+
+#define SECTION_NG_MASK         (0xFFFDFFFF)
+#define SECTION_NG_SHIFT        (17)
+
+#define SECTION_NS_MASK         (0xFFF7FFFF)
+#define SECTION_NS_SHIFT        (19)
+
+#define PAGE_L1_DESCRIPTOR      (0x1)
+#define PAGE_L1_MASK            (0xFFFFFFFC)
+
+#define PAGE_L2_4K_DESC         (0x2)
+#define PAGE_L2_4K_MASK         (0xFFFFFFFD)
+
+#define PAGE_L2_64K_DESC        (0x1)
+#define PAGE_L2_64K_MASK        (0xFFFFFFFC)
+
+#define PAGE_4K_TEXCB_MASK      (0xFFFFFE33)
+#define PAGE_4K_B_SHIFT         (2)
+#define PAGE_4K_C_SHIFT         (3)
+#define PAGE_4K_TEX0_SHIFT      (6)
+#define PAGE_4K_TEX1_SHIFT      (7)
+#define PAGE_4K_TEX2_SHIFT      (8)
+
+#define PAGE_64K_TEXCB_MASK     (0xFFFF8FF3)
+#define PAGE_64K_B_SHIFT        (2)
+#define PAGE_64K_C_SHIFT        (3)
+#define PAGE_64K_TEX0_SHIFT     (12)
+#define PAGE_64K_TEX1_SHIFT     (13)
+#define PAGE_64K_TEX2_SHIFT     (14)
+
+#define PAGE_TEXCB_MASK         (0xFFFF8FF3)
+#define PAGE_B_SHIFT            (2)
+#define PAGE_C_SHIFT            (3)
+#define PAGE_TEX_SHIFT          (12)
+
+#define PAGE_XN_4K_MASK         (0xFFFFFFFE)
+#define PAGE_XN_4K_SHIFT        (0)
+#define PAGE_XN_64K_MASK        (0xFFFF7FFF)
+#define PAGE_XN_64K_SHIFT       (15)
+
+#define PAGE_DOMAIN_MASK        (0xFFFFFE1F)
+#define PAGE_DOMAIN_SHIFT       (5)
+
+#define PAGE_P_MASK             (0xFFFFFDFF)
+#define PAGE_P_SHIFT            (9)
+
+#define PAGE_AP_MASK            (0xFFFFFDCF)
+#define PAGE_AP_SHIFT           (4)
+#define PAGE_AP2_SHIFT          (9)
+
+#define PAGE_S_MASK             (0xFFFFFBFF)
+#define PAGE_S_SHIFT            (10)
+
+#define PAGE_NG_MASK            (0xFFFFF7FF)
+#define PAGE_NG_SHIFT           (11)
+
+#define PAGE_NS_MASK            (0xFFFFFFF7)
+#define PAGE_NS_SHIFT           (3)
+
+#define OFFSET_1M               (0x00100000)
+#define OFFSET_64K              (0x00010000)
+#define OFFSET_4K               (0x00001000)
+
+#define DESCRIPTOR_FAULT        (0x00000000)
+
+/* Attributes enumerations */
+
+/* Region size attributes */
+typedef enum
+{
+   SECTION,
+   PAGE_4k,
+   PAGE_64k,
+} mmu_region_size_Type;
+
+/* Region type attributes */
+typedef enum
+{
+   NORMAL,
+   DEVICE,
+   SHARED_DEVICE,
+   NON_SHARED_DEVICE,
+   STRONGLY_ORDERED
+} mmu_memory_Type;
+
+/* Region cacheability attributes */
+typedef enum
+{
+   NON_CACHEABLE,
+   WB_WA,
+   WT,
+   WB_NO_WA,
+} mmu_cacheability_Type;
+
+/* Region parity check attributes */
+typedef enum
+{
+   ECC_DISABLED,
+   ECC_ENABLED,
+} mmu_ecc_check_Type;
+
+/* Region execution attributes */
+typedef enum
+{
+   EXECUTE,
+   NON_EXECUTE,
+} mmu_execute_Type;
+
+/* Region global attributes */
+typedef enum
+{
+   GLOBAL,
+   NON_GLOBAL,
+} mmu_global_Type;
+
+/* Region shareability attributes */
+typedef enum
+{
+   NON_SHARED,
+   SHARED,
+} mmu_shared_Type;
+
+/* Region security attributes */
+typedef enum
+{
+   SECURE,
+   NON_SECURE,
+} mmu_secure_Type;
+
+/* Region access attributes */
+typedef enum
+{
+   NO_ACCESS,
+   RW,
+   READ,
+} mmu_access_Type;
+
+/* Memory Region definition */
+typedef struct RegionStruct {
+    mmu_region_size_Type rg_t;
+    mmu_memory_Type mem_t;
+    uint8_t domain;
+    mmu_cacheability_Type inner_norm_t;
+    mmu_cacheability_Type outer_norm_t;
+    mmu_ecc_check_Type e_t;
+    mmu_execute_Type xn_t;
+    mmu_global_Type g_t;
+    mmu_secure_Type sec_t;
+    mmu_access_Type priv_t;
+    mmu_access_Type user_t;
+    mmu_shared_Type sh_t;
+
+} mmu_region_attributes_Type;
+
+//Following macros define the descriptors and attributes
+//Sect_Normal. Outer & inner wb/wa, non-shareable, executable, rw, domain 0
+#define section_normal(descriptor_l1, region)     region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = WB_WA; \
+                                   region.outer_norm_t = WB_WA; \
+                                   region.mem_t = NORMAL; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Normal_NC. Outer & inner non-cacheable, non-shareable, executable, rw, domain 0
+#define section_normal_nc(descriptor_l1, region)     region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = NORMAL; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Normal_Cod. Outer & inner wb/wa, non-shareable, executable, ro, domain 0
+#define section_normal_cod(descriptor_l1, region) region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = WB_WA; \
+                                   region.outer_norm_t = WB_WA; \
+                                   region.mem_t = NORMAL; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = EXECUTE; \
+                                   region.priv_t = READ; \
+                                   region.user_t = READ; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Normal_RO. Sect_Normal_Cod, but not executable
+#define section_normal_ro(descriptor_l1, region)  region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = WB_WA; \
+                                   region.outer_norm_t = WB_WA; \
+                                   region.mem_t = NORMAL; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = READ; \
+                                   region.user_t = READ; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Normal_RW. Sect_Normal_Cod, but writeable and not executable
+#define section_normal_rw(descriptor_l1, region) region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = WB_WA; \
+                                   region.outer_norm_t = WB_WA; \
+                                   region.mem_t = NORMAL; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+//Sect_SO. Strongly-ordered (therefore shareable), not executable, rw, domain 0, base addr 0
+#define section_so(descriptor_l1, region) region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = STRONGLY_ORDERED; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Device_RO. Device, non-shareable, non-executable, ro, domain 0, base addr 0
+#define section_device_ro(descriptor_l1, region) region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = STRONGLY_ORDERED; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = READ; \
+                                   region.user_t = READ; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+
+//Sect_Device_RW. Sect_Device_RO, but writeable
+#define section_device_rw(descriptor_l1, region) region.rg_t = SECTION; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = STRONGLY_ORDERED; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetSectionDescriptor(&descriptor_l1, region);
+//Page_4k_Device_RW.  Shared device, not executable, rw, domain 0
+#define page4k_device_rw(descriptor_l1, descriptor_l2, region) region.rg_t = PAGE_4k; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = SHARED_DEVICE; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetPageDescriptor(&descriptor_l1, &descriptor_l2, region);
+
+//Page_64k_Device_RW.  Shared device, not executable, rw, domain 0
+#define page64k_device_rw(descriptor_l1, descriptor_l2, region)  region.rg_t = PAGE_64k; \
+                                   region.domain = 0x0; \
+                                   region.e_t = ECC_DISABLED; \
+                                   region.g_t = GLOBAL; \
+                                   region.inner_norm_t = NON_CACHEABLE; \
+                                   region.outer_norm_t = NON_CACHEABLE; \
+                                   region.mem_t = SHARED_DEVICE; \
+                                   region.sec_t = SECURE; \
+                                   region.xn_t = NON_EXECUTE; \
+                                   region.priv_t = RW; \
+                                   region.user_t = RW; \
+                                   region.sh_t = NON_SHARED; \
+                                   MMU_GetPageDescriptor(&descriptor_l1, &descriptor_l2, region);
+
+/** \brief  Set section execution-never attribute
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]                xn  Section execution-never attribute : EXECUTE , NON_EXECUTE.
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_XNSection(uint32_t *descriptor_l1, mmu_execute_Type xn)
+{
+  *descriptor_l1 &= SECTION_XN_MASK;
+  *descriptor_l1 |= ((xn & 0x1) << SECTION_XN_SHIFT);
+  return 0;
+}
+
+/** \brief  Set section domain
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]            domain  Section domain
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_DomainSection(uint32_t *descriptor_l1, uint8_t domain)
+{
+  *descriptor_l1 &= SECTION_DOMAIN_MASK;
+  *descriptor_l1 |= ((domain & 0xF) << SECTION_DOMAIN_SHIFT);
+  return 0;
+}
+
+/** \brief  Set section parity check
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]              p_bit Parity check: ECC_DISABLED, ECC_ENABLED
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_PSection(uint32_t *descriptor_l1, mmu_ecc_check_Type p_bit)
+{
+  *descriptor_l1 &= SECTION_P_MASK;
+  *descriptor_l1 |= ((p_bit & 0x1) << SECTION_P_SHIFT);
+  return 0;
+}
+
+/** \brief  Set section access privileges
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]              user  User Level Access: NO_ACCESS, RW, READ
+  \param [in]              priv  Privilege Level Access: NO_ACCESS, RW, READ
+  \param [in]               afe  Access flag enable
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_APSection(uint32_t *descriptor_l1, mmu_access_Type user, mmu_access_Type priv, uint32_t afe)
+{
+  uint32_t ap = 0;
+
+  if (afe == 0) { //full access
+    if ((priv == NO_ACCESS) && (user == NO_ACCESS)) { ap = 0x0; }
+    else if ((priv == RW) && (user == NO_ACCESS))   { ap = 0x1; }
+    else if ((priv == RW) && (user == READ))        { ap = 0x2; }
+    else if ((priv == RW) && (user == RW))          { ap = 0x3; }
+    else if ((priv == READ) && (user == NO_ACCESS)) { ap = 0x5; }
+    else if ((priv == READ) && (user == READ))      { ap = 0x7; }
+  }
+
+  else { //Simplified access
+    if ((priv == RW) && (user == NO_ACCESS))        { ap = 0x1; }
+    else if ((priv == RW) && (user == RW))          { ap = 0x3; }
+    else if ((priv == READ) && (user == NO_ACCESS)) { ap = 0x5; }
+    else if ((priv == READ) && (user == READ))      { ap = 0x7; }
+  }
+
+  *descriptor_l1 &= SECTION_AP_MASK;
+  *descriptor_l1 |= (ap & 0x3) << SECTION_AP_SHIFT;
+  *descriptor_l1 |= ((ap & 0x4)>>2) << SECTION_AP2_SHIFT;
+
+  return 0;
+}
+
+/** \brief  Set section shareability
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]             s_bit  Section shareability: NON_SHARED, SHARED
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_SharedSection(uint32_t *descriptor_l1, mmu_shared_Type s_bit)
+{
+  *descriptor_l1 &= SECTION_S_MASK;
+  *descriptor_l1 |= ((s_bit & 0x1) << SECTION_S_SHIFT);
+  return 0;
+}
+
+/** \brief  Set section Global attribute
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]             g_bit  Section attribute: GLOBAL, NON_GLOBAL
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_GlobalSection(uint32_t *descriptor_l1, mmu_global_Type g_bit)
+{
+  *descriptor_l1 &= SECTION_NG_MASK;
+  *descriptor_l1 |= ((g_bit & 0x1) << SECTION_NG_SHIFT);
+  return 0;
+}
+
+/** \brief  Set section Security attribute
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]             s_bit  Section Security attribute: SECURE, NON_SECURE
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_SecureSection(uint32_t *descriptor_l1, mmu_secure_Type s_bit)
+{
+  *descriptor_l1 &= SECTION_NS_MASK;
+  *descriptor_l1 |= ((s_bit & 0x1) << SECTION_NS_SHIFT);
+  return 0;
+}
+
+/* Page 4k or 64k */
+/** \brief  Set 4k/64k page execution-never attribute
+
+  \param [out]    descriptor_l2  L2 descriptor.
+  \param [in]                xn  Page execution-never attribute : EXECUTE , NON_EXECUTE.
+  \param [in]              page  Page size: PAGE_4k, PAGE_64k,
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_XNPage(uint32_t *descriptor_l2, mmu_execute_Type xn, mmu_region_size_Type page)
+{
+  if (page == PAGE_4k)
+  {
+      *descriptor_l2 &= PAGE_XN_4K_MASK;
+      *descriptor_l2 |= ((xn & 0x1) << PAGE_XN_4K_SHIFT);
+  }
+  else
+  {
+      *descriptor_l2 &= PAGE_XN_64K_MASK;
+      *descriptor_l2 |= ((xn & 0x1) << PAGE_XN_64K_SHIFT);
+  }
+  return 0;
+}
+
+/** \brief  Set 4k/64k page domain
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]            domain  Page domain
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_DomainPage(uint32_t *descriptor_l1, uint8_t domain)
+{
+  *descriptor_l1 &= PAGE_DOMAIN_MASK;
+  *descriptor_l1 |= ((domain & 0xf) << PAGE_DOMAIN_SHIFT);
+  return 0;
+}
+
+/** \brief  Set 4k/64k page parity check
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]              p_bit Parity check: ECC_DISABLED, ECC_ENABLED
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_PPage(uint32_t *descriptor_l1, mmu_ecc_check_Type p_bit)
+{
+  *descriptor_l1 &= SECTION_P_MASK;
+  *descriptor_l1 |= ((p_bit & 0x1) << SECTION_P_SHIFT);
+  return 0;
+}
+
+/** \brief  Set 4k/64k page access privileges
+
+  \param [out]    descriptor_l2  L2 descriptor.
+  \param [in]              user  User Level Access: NO_ACCESS, RW, READ
+  \param [in]              priv  Privilege Level Access: NO_ACCESS, RW, READ
+  \param [in]               afe  Access flag enable
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_APPage(uint32_t *descriptor_l2, mmu_access_Type user, mmu_access_Type priv, uint32_t afe)
+{
+  uint32_t ap = 0;
+
+  if (afe == 0) { //full access
+    if ((priv == NO_ACCESS) && (user == NO_ACCESS)) { ap = 0x0; }
+    else if ((priv == RW) && (user == NO_ACCESS))   { ap = 0x1; }
+    else if ((priv == RW) && (user == READ))        { ap = 0x2; }
+    else if ((priv == RW) && (user == RW))          { ap = 0x3; }
+    else if ((priv == READ) && (user == NO_ACCESS)) { ap = 0x5; }
+    else if ((priv == READ) && (user == READ))      { ap = 0x6; }
+  }
+
+  else { //Simplified access
+    if ((priv == RW) && (user == NO_ACCESS))        { ap = 0x1; }
+    else if ((priv == RW) && (user == RW))          { ap = 0x3; }
+    else if ((priv == READ) && (user == NO_ACCESS)) { ap = 0x5; }
+    else if ((priv == READ) && (user == READ))      { ap = 0x7; }
+  }
+
+  *descriptor_l2 &= PAGE_AP_MASK;
+  *descriptor_l2 |= (ap & 0x3) << PAGE_AP_SHIFT;
+  *descriptor_l2 |= ((ap & 0x4)>>2) << PAGE_AP2_SHIFT;
+
+  return 0;
+}
+
+/** \brief  Set 4k/64k page shareability
+
+  \param [out]    descriptor_l2  L2 descriptor.
+  \param [in]             s_bit  4k/64k page shareability: NON_SHARED, SHARED
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_SharedPage(uint32_t *descriptor_l2, mmu_shared_Type s_bit)
+{
+  *descriptor_l2 &= PAGE_S_MASK;
+  *descriptor_l2 |= ((s_bit & 0x1) << PAGE_S_SHIFT);
+  return 0;
+}
+
+/** \brief  Set 4k/64k page Global attribute
+
+  \param [out]    descriptor_l2  L2 descriptor.
+  \param [in]             g_bit  4k/64k page attribute: GLOBAL, NON_GLOBAL
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_GlobalPage(uint32_t *descriptor_l2, mmu_global_Type g_bit)
+{
+  *descriptor_l2 &= PAGE_NG_MASK;
+  *descriptor_l2 |= ((g_bit & 0x1) << PAGE_NG_SHIFT);
+  return 0;
+}
+
+/** \brief  Set 4k/64k page Security attribute
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]             s_bit  4k/64k page Security attribute: SECURE, NON_SECURE
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_SecurePage(uint32_t *descriptor_l1, mmu_secure_Type s_bit)
+{
+  *descriptor_l1 &= PAGE_NS_MASK;
+  *descriptor_l1 |= ((s_bit & 0x1) << PAGE_NS_SHIFT);
+  return 0;
+}
+
+/** \brief  Set Section memory attributes
+
+  \param [out]    descriptor_l1  L1 descriptor.
+  \param [in]               mem  Section memory type: NORMAL, DEVICE, SHARED_DEVICE, NON_SHARED_DEVICE, STRONGLY_ORDERED
+  \param [in]             outer  Outer cacheability: NON_CACHEABLE, WB_WA, WT, WB_NO_WA,
+  \param [in]             inner  Inner cacheability: NON_CACHEABLE, WB_WA, WT, WB_NO_WA,
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_MemorySection(uint32_t *descriptor_l1, mmu_memory_Type mem, mmu_cacheability_Type outer, mmu_cacheability_Type inner)
+{
+  *descriptor_l1 &= SECTION_TEXCB_MASK;
+
+  if (STRONGLY_ORDERED == mem)
+  {
+    return 0;
+  }
+  else if (SHARED_DEVICE == mem)
+  {
+    *descriptor_l1 |= (1 << SECTION_B_SHIFT);
+  }
+  else if (NON_SHARED_DEVICE == mem)
+  {
+    *descriptor_l1 |= (1 << SECTION_TEX1_SHIFT);
+  }
+  else if (NORMAL == mem)
+  {
+   *descriptor_l1 |= 1 << SECTION_TEX2_SHIFT;
+   switch(inner)
+   {
+      case NON_CACHEABLE:
+        break;
+      case WB_WA:
+        *descriptor_l1 |= (1 << SECTION_B_SHIFT);
+        break;
+      case WT:
+        *descriptor_l1 |= 1 << SECTION_C_SHIFT;
+        break;
+      case WB_NO_WA:
+        *descriptor_l1 |= (1 << SECTION_B_SHIFT) | (1 << SECTION_C_SHIFT);
+        break;
+    }
+    switch(outer)
+    {
+      case NON_CACHEABLE:
+        break;
+      case WB_WA:
+        *descriptor_l1 |= (1 << SECTION_TEX0_SHIFT);
+        break;
+      case WT:
+        *descriptor_l1 |= 1 << SECTION_TEX1_SHIFT;
+        break;
+      case WB_NO_WA:
+        *descriptor_l1 |= (1 << SECTION_TEX0_SHIFT) | (1 << SECTION_TEX1_SHIFT);
+        break;
+    }
+  }
+  return 0;
+}
+
+/** \brief  Set 4k/64k page memory attributes
+
+  \param [out]    descriptor_l2  L2 descriptor.
+  \param [in]               mem  4k/64k page memory type: NORMAL, DEVICE, SHARED_DEVICE, NON_SHARED_DEVICE, STRONGLY_ORDERED
+  \param [in]             outer  Outer cacheability: NON_CACHEABLE, WB_WA, WT, WB_NO_WA,
+  \param [in]             inner  Inner cacheability: NON_CACHEABLE, WB_WA, WT, WB_NO_WA,
+  \param [in]              page  Page size
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_MemoryPage(uint32_t *descriptor_l2, mmu_memory_Type mem, mmu_cacheability_Type outer, mmu_cacheability_Type inner, mmu_region_size_Type page)
+{
+  *descriptor_l2 &= PAGE_4K_TEXCB_MASK;
+
+  if (page == PAGE_64k)
+  {
+    //same as section
+    MMU_MemorySection(descriptor_l2, mem, outer, inner);
+  }
+  else
+  {
+    if (STRONGLY_ORDERED == mem)
+    {
+      return 0;
+    }
+    else if (SHARED_DEVICE == mem)
+    {
+      *descriptor_l2 |= (1 << PAGE_4K_B_SHIFT);
+    }
+    else if (NON_SHARED_DEVICE == mem)
+    {
+      *descriptor_l2 |= (1 << PAGE_4K_TEX1_SHIFT);
+    }
+    else if (NORMAL == mem)
+    {
+      *descriptor_l2 |= 1 << PAGE_4K_TEX2_SHIFT;
+      switch(inner)
+      {
+        case NON_CACHEABLE:
+          break;
+        case WB_WA:
+          *descriptor_l2 |= (1 << PAGE_4K_B_SHIFT);
+          break;
+        case WT:
+          *descriptor_l2 |= 1 << PAGE_4K_C_SHIFT;
+          break;
+        case WB_NO_WA:
+          *descriptor_l2 |= (1 << PAGE_4K_B_SHIFT) | (1 << PAGE_4K_C_SHIFT);
+          break;
+      }
+      switch(outer)
+      {
+        case NON_CACHEABLE:
+          break;
+        case WB_WA:
+          *descriptor_l2 |= (1 << PAGE_4K_TEX0_SHIFT);
+          break;
+        case WT:
+          *descriptor_l2 |= 1 << PAGE_4K_TEX1_SHIFT;
+          break;
+        case WB_NO_WA:
+          *descriptor_l2 |= (1 << PAGE_4K_TEX0_SHIFT) | (1 << PAGE_4K_TEX1_SHIFT);
+          break;
+      }
+    }
+  }
+
+  return 0;
+}
+
+/** \brief  Create a L1 section descriptor
+
+  \param [out]     descriptor  L1 descriptor
+  \param [in]      reg  Section attributes
+  
+  \return          0
+*/
+__STATIC_INLINE int MMU_GetSectionDescriptor(uint32_t *descriptor, mmu_region_attributes_Type reg)
+{
+  *descriptor  = 0;
+
+  MMU_MemorySection(descriptor, reg.mem_t, reg.outer_norm_t, reg.inner_norm_t);
+  MMU_XNSection(descriptor,reg.xn_t);
+  MMU_DomainSection(descriptor, reg.domain);
+  MMU_PSection(descriptor, reg.e_t);
+  MMU_APSection(descriptor, reg.priv_t, reg.user_t, 1);
+  MMU_SharedSection(descriptor,reg.sh_t);
+  MMU_GlobalSection(descriptor,reg.g_t);
+  MMU_SecureSection(descriptor,reg.sec_t);
+  *descriptor &= SECTION_MASK;
+  *descriptor |= SECTION_DESCRIPTOR;
+ 
+  return 0;
+}
+
+
+/** \brief  Create a L1 and L2 4k/64k page descriptor
+
+  \param [out]       descriptor  L1 descriptor
+  \param [out]      descriptor2  L2 descriptor
+  \param [in]               reg  4k/64k page attributes
+
+  \return          0
+*/
+__STATIC_INLINE int MMU_GetPageDescriptor(uint32_t *descriptor, uint32_t *descriptor2, mmu_region_attributes_Type reg)
+{
+  *descriptor  = 0;
+  *descriptor2 = 0;
+
+  switch (reg.rg_t)
+  {
+    case PAGE_4k:
+      MMU_MemoryPage(descriptor2, reg.mem_t, reg.outer_norm_t, reg.inner_norm_t, PAGE_4k);
+      MMU_XNPage(descriptor2, reg.xn_t, PAGE_4k);
+      MMU_DomainPage(descriptor, reg.domain);
+      MMU_PPage(descriptor, reg.e_t);
+      MMU_APPage(descriptor2, reg.priv_t, reg.user_t, 1);
+      MMU_SharedPage(descriptor2,reg.sh_t);
+      MMU_GlobalPage(descriptor2,reg.g_t);
+      MMU_SecurePage(descriptor,reg.sec_t);
+      *descriptor &= PAGE_L1_MASK;
+      *descriptor |= PAGE_L1_DESCRIPTOR;
+      *descriptor2 &= PAGE_L2_4K_MASK;
+      *descriptor2 |= PAGE_L2_4K_DESC;
+      break;
+
+    case PAGE_64k:
+      MMU_MemoryPage(descriptor2, reg.mem_t, reg.outer_norm_t, reg.inner_norm_t, PAGE_64k);
+      MMU_XNPage(descriptor2, reg.xn_t, PAGE_64k);
+      MMU_DomainPage(descriptor, reg.domain);
+      MMU_PPage(descriptor, reg.e_t);
+      MMU_APPage(descriptor2, reg.priv_t, reg.user_t, 1);
+      MMU_SharedPage(descriptor2,reg.sh_t);
+      MMU_GlobalPage(descriptor2,reg.g_t);
+      MMU_SecurePage(descriptor,reg.sec_t);
+      *descriptor &= PAGE_L1_MASK;
+      *descriptor |= PAGE_L1_DESCRIPTOR;
+      *descriptor2 &= PAGE_L2_64K_MASK;
+      *descriptor2 |= PAGE_L2_64K_DESC;
+      break;
+
+    case SECTION:
+      //error
+      break;
+  }
+  
+  return 0;
+}
+
+/** \brief  Create a 1MB Section
+
+  \param [in]               ttb  Translation table base address
+  \param [in]      base_address  Section base address
+  \param [in]             count  Number of sections to create
+  \param [in]     descriptor_l1  L1 descriptor (region attributes)
+
+*/
+__STATIC_INLINE void MMU_TTSection(uint32_t *ttb, uint32_t base_address, uint32_t count, uint32_t descriptor_l1)
+{
+  uint32_t offset;
+  uint32_t entry;
+  uint32_t i;
+
+  offset = base_address >> 20;
+  entry  = (base_address & 0xFFF00000) | descriptor_l1;
+
+  //4 bytes aligned
+  ttb = ttb + offset;
+
+  for (i = 0; i < count; i++ )
+  {
+    //4 bytes aligned
+    *ttb++ = entry;
+    entry += OFFSET_1M;
+  }
+}
+
+/** \brief  Create a 4k page entry
+
+  \param [in]               ttb  L1 table base address
+  \param [in]      base_address  4k base address
+  \param [in]             count  Number of 4k pages to create
+  \param [in]     descriptor_l1  L1 descriptor (region attributes)
+  \param [in]            ttb_l2  L2 table base address
+  \param [in]     descriptor_l2  L2 descriptor (region attributes)
+
+*/
+__STATIC_INLINE void MMU_TTPage4k(uint32_t *ttb, uint32_t base_address, uint32_t count, uint32_t descriptor_l1, uint32_t *ttb_l2, uint32_t descriptor_l2 )
+{
+
+  uint32_t offset, offset2;
+  uint32_t entry, entry2;
+  uint32_t i;
+
+  offset = base_address >> 20;
+  entry  = ((int)ttb_l2 & 0xFFFFFC00) | descriptor_l1;
+
+  //4 bytes aligned
+  ttb += offset;
+  //create l1_entry
+  *ttb = entry;
+
+  offset2 = (base_address & 0xff000) >> 12;
+  ttb_l2 += offset2;
+  entry2 = (base_address & 0xFFFFF000) | descriptor_l2;
+  for (i = 0; i < count; i++ )
+  {
+    //4 bytes aligned
+    *ttb_l2++ = entry2;
+    entry2 += OFFSET_4K;
+  }
+}
+
+/** \brief  Create a 64k page entry
+
+  \param [in]               ttb  L1 table base address
+  \param [in]      base_address  64k base address
+  \param [in]             count  Number of 64k pages to create
+  \param [in]     descriptor_l1  L1 descriptor (region attributes)
+  \param [in]            ttb_l2  L2 table base address
+  \param [in]     descriptor_l2  L2 descriptor (region attributes)
+
+*/
+__STATIC_INLINE void MMU_TTPage64k(uint32_t *ttb, uint32_t base_address, uint32_t count, uint32_t descriptor_l1, uint32_t *ttb_l2, uint32_t descriptor_l2 )
+{
+  uint32_t offset, offset2;
+  uint32_t entry, entry2;
+  uint32_t i,j;
+
+
+  offset = base_address >> 20;
+  entry  = ((int)ttb_l2 & 0xFFFFFC00) | descriptor_l1;
+
+  //4 bytes aligned
+  ttb += offset;
+  //create l1_entry
+  *ttb = entry;
+
+  offset2 = (base_address & 0xff000) >> 12;
+  ttb_l2 += offset2;
+  entry2 = (base_address & 0xFFFF0000) | descriptor_l2;
+  for (i = 0; i < count; i++ )
+  {
+    //create 16 entries
+    for (j = 0; j < 16; j++)
+    {
+      //4 bytes aligned
+      *ttb_l2++ = entry2;
+    }
+    entry2 += OFFSET_64K;
+  }
+}
+
+/** \brief  Enable MMU
+*/
+__STATIC_INLINE void MMU_Enable(void)
+{
+  // Set M bit 0 to enable the MMU
+  // Set AFE bit to enable simplified access permissions model
+  // Clear TRE bit to disable TEX remap and A bit to disable strict alignment fault checking
+  __set_SCTLR( (__get_SCTLR() & ~(1 << 28) & ~(1 << 1)) | 1 | (1 << 29));
+  __ISB();
+}
+
+/** \brief  Disable MMU
+*/
+__STATIC_INLINE void MMU_Disable(void)
+{
+  // Clear M bit 0 to disable the MMU
+  __set_SCTLR( __get_SCTLR() & ~1);
+  __ISB();
+}
+
+/** \brief  Invalidate entire unified TLB
+*/
+
+__STATIC_INLINE void MMU_InvalidateTLB(void)
+{
+  __set_TLBIALL(0);
+  __DSB();     //ensure completion of the invalidation
+  __ISB();     //ensure instruction fetch path sees new state
+}
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __CORE_CA_H_DEPENDANT */
+
+#endif /* __CMSIS_GENERIC */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/core_cr7.h b/machines/cortex-r/armv7/RCar/CMSIS/core_cr7.h
new file mode 100644
index 00000000..76d6c88c
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/core_cr7.h
@@ -0,0 +1,2677 @@
+/**************************************************************************//**
+ * @file     core_cm7.h
+ * @brief    CMSIS Cortex-M7 Core Peripheral Access Layer Header File
+ * @version  V5.2.5
+ * @date     12. Oktober 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2009-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Modified for Cortex-R for MPU code:
+ *  - Added '#ifdef HAS_NVIC' around NVIC code
+ *  - Modified MPU definitions
+ */
+
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header   /* treat file as system include file */
+#endif
+
+#ifndef __CORE_CM7_H_GENERIC
+#define __CORE_CM7_H_GENERIC
+
+#include <stdint.h>
+
+#ifdef __cplusplus
+ extern "C" {
+#endif
+
+/**
+  \page CMSIS_MISRA_Exceptions  MISRA-C:2004 Compliance Exceptions
+  CMSIS violates the following MISRA-C:2004 rules:
+
+   \li Required Rule 8.5, object/function definition in header file.<br>
+     Function definitions in header files are used to allow 'inlining'.
+
+   \li Required Rule 18.4, declaration of union type or object of union type: '{...}'.<br>
+     Unions are used for effective representation of core registers.
+
+   \li Advisory Rule 19.7, Function-like macro defined.<br>
+     Function-like macros are used to allow more efficient code.
+ */
+
+
+/*******************************************************************************
+ *                 CMSIS definitions
+ ******************************************************************************/
+/**
+  \ingroup Cortex_M7
+  @{
+ */
+
+#include "cmsis_version.h"
+
+/* CMSIS CM7 definitions */
+#define __CM7_CMSIS_VERSION_MAIN  (__CM_CMSIS_VERSION_MAIN)                  /*!< \deprecated [31:16] CMSIS HAL main version */
+#define __CM7_CMSIS_VERSION_SUB   ( __CM_CMSIS_VERSION_SUB)                  /*!< \deprecated [15:0]  CMSIS HAL sub version */
+#define __CM7_CMSIS_VERSION       ((__CM7_CMSIS_VERSION_MAIN << 16U) | \
+                                    __CM7_CMSIS_VERSION_SUB           )      /*!< \deprecated CMSIS HAL version number */
+
+#define __CORTEX_M                (7U)                                       /*!< Cortex-M Core */
+
+/** __FPU_USED indicates whether an FPU is used or not.
+    For this, __FPU_PRESENT has to be checked prior to making use of FPU specific registers and functions.
+*/
+#if defined ( __CC_ARM )
+  #if defined __TARGET_FPU_VFP
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined (__ARMCC_VERSION) && (__ARMCC_VERSION >= 6010050)
+  #if defined __ARM_FP
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #warning "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __GNUC__ )
+  #if defined (__VFP_FP__) && !defined(__SOFTFP__)
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __ICCARM__ )
+  #if defined __ARMVFP__
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __TI_ARM__ )
+  #if defined __TI_VFP_SUPPORT__
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __TASKING__ )
+  #if defined __FPU_VFP__
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#elif defined ( __CSMC__ )
+  #if ( __CSMC__ & 0x400U)
+    #if defined (__FPU_PRESENT) && (__FPU_PRESENT == 1U)
+      #define __FPU_USED       1U
+    #else
+      #error "Compiler generates FPU instructions for a device without an FPU (check __FPU_PRESENT)"
+      #define __FPU_USED       0U
+    #endif
+  #else
+    #define __FPU_USED         0U
+  #endif
+
+#endif
+
+#include "cmsis_compiler.h"               /* CMSIS compiler specific defines */
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __CORE_CM7_H_GENERIC */
+
+#ifndef __CMSIS_GENERIC
+
+#ifndef __CORE_CM7_H_DEPENDANT
+#define __CORE_CM7_H_DEPENDANT
+
+#ifdef __cplusplus
+ extern "C" {
+#endif
+
+/* check device defines and use defaults */
+#if defined __CHECK_DEVICE_DEFINES
+  #ifndef __CM7_REV
+    #define __CM7_REV               0x0000U
+    #warning "__CM7_REV not defined in device header file; using default!"
+  #endif
+
+  #ifndef __FPU_PRESENT
+    #define __FPU_PRESENT             0U
+    #warning "__FPU_PRESENT not defined in device header file; using default!"
+  #endif
+
+  #ifndef __MPU_PRESENT
+    #define __MPU_PRESENT             0U
+    #warning "__MPU_PRESENT not defined in device header file; using default!"
+  #endif
+
+  #ifndef __ICACHE_PRESENT
+    #define __ICACHE_PRESENT          0U
+    #warning "__ICACHE_PRESENT not defined in device header file; using default!"
+  #endif
+
+  #ifndef __DCACHE_PRESENT
+    #define __DCACHE_PRESENT          0U
+    #warning "__DCACHE_PRESENT not defined in device header file; using default!"
+  #endif
+
+  #ifndef __DTCM_PRESENT
+    #define __DTCM_PRESENT            0U
+    #warning "__DTCM_PRESENT        not defined in device header file; using default!"
+  #endif
+
+  #ifndef __NVIC_PRIO_BITS
+    #define __NVIC_PRIO_BITS          3U
+    #warning "__NVIC_PRIO_BITS not defined in device header file; using default!"
+  #endif
+
+  #ifndef __Vendor_SysTickConfig
+    #define __Vendor_SysTickConfig    0U
+    #warning "__Vendor_SysTickConfig not defined in device header file; using default!"
+  #endif
+#endif
+
+/* IO definitions (access restrictions to peripheral registers) */
+/**
+    \defgroup CMSIS_glob_defs CMSIS Global Defines
+
+    <strong>IO Type Qualifiers</strong> are used
+    \li to specify the access to peripheral variables.
+    \li for automatic generation of peripheral register debug information.
+*/
+#ifdef __cplusplus
+  #define   __I     volatile             /*!< Defines 'read only' permissions */
+#else
+  #define   __I     volatile const       /*!< Defines 'read only' permissions */
+#endif
+#define     __O     volatile             /*!< Defines 'write only' permissions */
+#define     __IO    volatile             /*!< Defines 'read / write' permissions */
+
+/* following defines should be used for structure members */
+#define     __IM     volatile const      /*! Defines 'read only' structure member permissions */
+#define     __OM     volatile            /*! Defines 'write only' structure member permissions */
+#define     __IOM    volatile            /*! Defines 'read / write' structure member permissions */
+
+/*@} end of group Cortex_M7 */
+
+
+
+/*******************************************************************************
+ *                 Register Abstraction
+  Core Register contain:
+  - Core Register
+  - Core NVIC Register
+  - Core SCB Register
+  - Core SysTick Register
+  - Core Debug Register
+  - Core MPU Register
+  - Core FPU Register
+ ******************************************************************************/
+/**
+  \defgroup CMSIS_core_register Defines and Type Definitions
+  \brief Type definitions and defines for Cortex-M processor based devices.
+*/
+
+/**
+  \ingroup    CMSIS_core_register
+  \defgroup   CMSIS_CORE  Status and Control Registers
+  \brief      Core Register type definitions.
+  @{
+ */
+
+/**
+  \brief  Union type to access the Application Program Status Register (APSR).
+ */
+typedef union
+{
+  struct
+  {
+    uint32_t _reserved0:16;              /*!< bit:  0..15  Reserved */
+    uint32_t GE:4;                       /*!< bit: 16..19  Greater than or Equal flags */
+    uint32_t _reserved1:7;               /*!< bit: 20..26  Reserved */
+    uint32_t Q:1;                        /*!< bit:     27  Saturation condition flag */
+    uint32_t V:1;                        /*!< bit:     28  Overflow condition code flag */
+    uint32_t C:1;                        /*!< bit:     29  Carry condition code flag */
+    uint32_t Z:1;                        /*!< bit:     30  Zero condition code flag */
+    uint32_t N:1;                        /*!< bit:     31  Negative condition code flag */
+  } b;                                   /*!< Structure used for bit  access */
+  uint32_t w;                            /*!< Type      used for word access */
+} APSR_Type;
+
+/* APSR Register Definitions */
+#define APSR_N_Pos                         31U                                            /*!< APSR: N Position */
+#define APSR_N_Msk                         (1UL << APSR_N_Pos)                            /*!< APSR: N Mask */
+
+#define APSR_Z_Pos                         30U                                            /*!< APSR: Z Position */
+#define APSR_Z_Msk                         (1UL << APSR_Z_Pos)                            /*!< APSR: Z Mask */
+
+#define APSR_C_Pos                         29U                                            /*!< APSR: C Position */
+#define APSR_C_Msk                         (1UL << APSR_C_Pos)                            /*!< APSR: C Mask */
+
+#define APSR_V_Pos                         28U                                            /*!< APSR: V Position */
+#define APSR_V_Msk                         (1UL << APSR_V_Pos)                            /*!< APSR: V Mask */
+
+#define APSR_Q_Pos                         27U                                            /*!< APSR: Q Position */
+#define APSR_Q_Msk                         (1UL << APSR_Q_Pos)                            /*!< APSR: Q Mask */
+
+#define APSR_GE_Pos                        16U                                            /*!< APSR: GE Position */
+#define APSR_GE_Msk                        (0xFUL << APSR_GE_Pos)                         /*!< APSR: GE Mask */
+
+
+/**
+  \brief  Union type to access the Interrupt Program Status Register (IPSR).
+ */
+typedef union
+{
+  struct
+  {
+    uint32_t ISR:9;                      /*!< bit:  0.. 8  Exception number */
+    uint32_t _reserved0:23;              /*!< bit:  9..31  Reserved */
+  } b;                                   /*!< Structure used for bit  access */
+  uint32_t w;                            /*!< Type      used for word access */
+} IPSR_Type;
+
+/* IPSR Register Definitions */
+#define IPSR_ISR_Pos                        0U                                            /*!< IPSR: ISR Position */
+#define IPSR_ISR_Msk                       (0x1FFUL /*<< IPSR_ISR_Pos*/)                  /*!< IPSR: ISR Mask */
+
+
+/**
+  \brief  Union type to access the Special-Purpose Program Status Registers (xPSR).
+ */
+typedef union
+{
+  struct
+  {
+    uint32_t ISR:9;                      /*!< bit:  0.. 8  Exception number */
+    uint32_t _reserved0:1;               /*!< bit:      9  Reserved */
+    uint32_t ICI_IT_1:6;                 /*!< bit: 10..15  ICI/IT part 1 */
+    uint32_t GE:4;                       /*!< bit: 16..19  Greater than or Equal flags */
+    uint32_t _reserved1:4;               /*!< bit: 20..23  Reserved */
+    uint32_t T:1;                        /*!< bit:     24  Thumb bit */
+    uint32_t ICI_IT_2:2;                 /*!< bit: 25..26  ICI/IT part 2 */
+    uint32_t Q:1;                        /*!< bit:     27  Saturation condition flag */
+    uint32_t V:1;                        /*!< bit:     28  Overflow condition code flag */
+    uint32_t C:1;                        /*!< bit:     29  Carry condition code flag */
+    uint32_t Z:1;                        /*!< bit:     30  Zero condition code flag */
+    uint32_t N:1;                        /*!< bit:     31  Negative condition code flag */
+  } b;                                   /*!< Structure used for bit  access */
+  uint32_t w;                            /*!< Type      used for word access */
+} xPSR_Type;
+
+/* xPSR Register Definitions */
+#define xPSR_N_Pos                         31U                                            /*!< xPSR: N Position */
+#define xPSR_N_Msk                         (1UL << xPSR_N_Pos)                            /*!< xPSR: N Mask */
+
+#define xPSR_Z_Pos                         30U                                            /*!< xPSR: Z Position */
+#define xPSR_Z_Msk                         (1UL << xPSR_Z_Pos)                            /*!< xPSR: Z Mask */
+
+#define xPSR_C_Pos                         29U                                            /*!< xPSR: C Position */
+#define xPSR_C_Msk                         (1UL << xPSR_C_Pos)                            /*!< xPSR: C Mask */
+
+#define xPSR_V_Pos                         28U                                            /*!< xPSR: V Position */
+#define xPSR_V_Msk                         (1UL << xPSR_V_Pos)                            /*!< xPSR: V Mask */
+
+#define xPSR_Q_Pos                         27U                                            /*!< xPSR: Q Position */
+#define xPSR_Q_Msk                         (1UL << xPSR_Q_Pos)                            /*!< xPSR: Q Mask */
+
+#define xPSR_ICI_IT_2_Pos                  25U                                            /*!< xPSR: ICI/IT part 2 Position */
+#define xPSR_ICI_IT_2_Msk                  (3UL << xPSR_ICI_IT_2_Pos)                     /*!< xPSR: ICI/IT part 2 Mask */
+
+#define xPSR_T_Pos                         24U                                            /*!< xPSR: T Position */
+#define xPSR_T_Msk                         (1UL << xPSR_T_Pos)                            /*!< xPSR: T Mask */
+
+#define xPSR_GE_Pos                        16U                                            /*!< xPSR: GE Position */
+#define xPSR_GE_Msk                        (0xFUL << xPSR_GE_Pos)                         /*!< xPSR: GE Mask */
+
+#define xPSR_ICI_IT_1_Pos                  10U                                            /*!< xPSR: ICI/IT part 1 Position */
+#define xPSR_ICI_IT_1_Msk                  (0x3FUL << xPSR_ICI_IT_1_Pos)                  /*!< xPSR: ICI/IT part 1 Mask */
+
+#define xPSR_ISR_Pos                        0U                                            /*!< xPSR: ISR Position */
+#define xPSR_ISR_Msk                       (0x1FFUL /*<< xPSR_ISR_Pos*/)                  /*!< xPSR: ISR Mask */
+
+
+/**
+  \brief  Union type to access the Control Registers (CONTROL).
+ */
+typedef union
+{
+  struct
+  {
+    uint32_t nPRIV:1;                    /*!< bit:      0  Execution privilege in Thread mode */
+    uint32_t SPSEL:1;                    /*!< bit:      1  Stack to be used */
+    uint32_t FPCA:1;                     /*!< bit:      2  FP extension active flag */
+    uint32_t _reserved0:29;              /*!< bit:  3..31  Reserved */
+  } b;                                   /*!< Structure used for bit  access */
+  uint32_t w;                            /*!< Type      used for word access */
+} CONTROL_Type;
+
+/* CONTROL Register Definitions */
+#define CONTROL_FPCA_Pos                    2U                                            /*!< CONTROL: FPCA Position */
+#define CONTROL_FPCA_Msk                   (1UL << CONTROL_FPCA_Pos)                      /*!< CONTROL: FPCA Mask */
+
+#define CONTROL_SPSEL_Pos                   1U                                            /*!< CONTROL: SPSEL Position */
+#define CONTROL_SPSEL_Msk                  (1UL << CONTROL_SPSEL_Pos)                     /*!< CONTROL: SPSEL Mask */
+
+#define CONTROL_nPRIV_Pos                   0U                                            /*!< CONTROL: nPRIV Position */
+#define CONTROL_nPRIV_Msk                  (1UL /*<< CONTROL_nPRIV_Pos*/)                 /*!< CONTROL: nPRIV Mask */
+
+/*@} end of group CMSIS_CORE */
+
+
+/**
+  \ingroup    CMSIS_core_register
+  \defgroup   CMSIS_NVIC  Nested Vectored Interrupt Controller (NVIC)
+  \brief      Type definitions for the NVIC Registers
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Nested Vectored Interrupt Controller (NVIC).
+ */
+typedef struct
+{
+  __IOM uint32_t ISER[8U];               /*!< Offset: 0x000 (R/W)  Interrupt Set Enable Register */
+        uint32_t RESERVED0[24U];
+  __IOM uint32_t ICER[8U];               /*!< Offset: 0x080 (R/W)  Interrupt Clear Enable Register */
+        uint32_t RSERVED1[24U];
+  __IOM uint32_t ISPR[8U];               /*!< Offset: 0x100 (R/W)  Interrupt Set Pending Register */
+        uint32_t RESERVED2[24U];
+  __IOM uint32_t ICPR[8U];               /*!< Offset: 0x180 (R/W)  Interrupt Clear Pending Register */
+        uint32_t RESERVED3[24U];
+  __IOM uint32_t IABR[8U];               /*!< Offset: 0x200 (R/W)  Interrupt Active bit Register */
+        uint32_t RESERVED4[56U];
+  __IOM uint8_t  IP[240U];               /*!< Offset: 0x300 (R/W)  Interrupt Priority Register (8Bit wide) */
+        uint32_t RESERVED5[644U];
+  __OM  uint32_t STIR;                   /*!< Offset: 0xE00 ( /W)  Software Trigger Interrupt Register */
+}  NVIC_Type;
+
+/* Software Triggered Interrupt Register Definitions */
+#define NVIC_STIR_INTID_Pos                 0U                                         /*!< STIR: INTLINESNUM Position */
+#define NVIC_STIR_INTID_Msk                (0x1FFUL /*<< NVIC_STIR_INTID_Pos*/)        /*!< STIR: INTLINESNUM Mask */
+
+/*@} end of group CMSIS_NVIC */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_SCB     System Control Block (SCB)
+  \brief    Type definitions for the System Control Block Registers
+  @{
+ */
+
+/**
+  \brief  Structure type to access the System Control Block (SCB).
+ */
+typedef struct
+{
+  __IM  uint32_t CPUID;                  /*!< Offset: 0x000 (R/ )  CPUID Base Register */
+  __IOM uint32_t ICSR;                   /*!< Offset: 0x004 (R/W)  Interrupt Control and State Register */
+  __IOM uint32_t VTOR;                   /*!< Offset: 0x008 (R/W)  Vector Table Offset Register */
+  __IOM uint32_t AIRCR;                  /*!< Offset: 0x00C (R/W)  Application Interrupt and Reset Control Register */
+  __IOM uint32_t SCR;                    /*!< Offset: 0x010 (R/W)  System Control Register */
+  __IOM uint32_t CCR;                    /*!< Offset: 0x014 (R/W)  Configuration Control Register */
+  __IOM uint8_t  SHPR[12U];              /*!< Offset: 0x018 (R/W)  System Handlers Priority Registers (4-7, 8-11, 12-15) */
+  __IOM uint32_t SHCSR;                  /*!< Offset: 0x024 (R/W)  System Handler Control and State Register */
+  __IOM uint32_t CFSR;                   /*!< Offset: 0x028 (R/W)  Configurable Fault Status Register */
+  __IOM uint32_t HFSR;                   /*!< Offset: 0x02C (R/W)  HardFault Status Register */
+  __IOM uint32_t DFSR;                   /*!< Offset: 0x030 (R/W)  Debug Fault Status Register */
+  __IOM uint32_t MMFAR;                  /*!< Offset: 0x034 (R/W)  MemManage Fault Address Register */
+  __IOM uint32_t BFAR;                   /*!< Offset: 0x038 (R/W)  BusFault Address Register */
+  __IOM uint32_t AFSR;                   /*!< Offset: 0x03C (R/W)  Auxiliary Fault Status Register */
+  __IM  uint32_t ID_PFR[2U];             /*!< Offset: 0x040 (R/ )  Processor Feature Register */
+  __IM  uint32_t ID_DFR;                 /*!< Offset: 0x048 (R/ )  Debug Feature Register */
+  __IM  uint32_t ID_AFR;                 /*!< Offset: 0x04C (R/ )  Auxiliary Feature Register */
+  __IM  uint32_t ID_MFR[4U];             /*!< Offset: 0x050 (R/ )  Memory Model Feature Register */
+  __IM  uint32_t ID_ISAR[5U];            /*!< Offset: 0x060 (R/ )  Instruction Set Attributes Register */
+        uint32_t RESERVED0[1U];
+  __IM  uint32_t CLIDR;                  /*!< Offset: 0x078 (R/ )  Cache Level ID register */
+  __IM  uint32_t CTR;                    /*!< Offset: 0x07C (R/ )  Cache Type register */
+  __IM  uint32_t CCSIDR;                 /*!< Offset: 0x080 (R/ )  Cache Size ID Register */
+  __IOM uint32_t CSSELR;                 /*!< Offset: 0x084 (R/W)  Cache Size Selection Register */
+  __IOM uint32_t CPACR;                  /*!< Offset: 0x088 (R/W)  Coprocessor Access Control Register */
+        uint32_t RESERVED3[93U];
+  __OM  uint32_t STIR;                   /*!< Offset: 0x200 ( /W)  Software Triggered Interrupt Register */
+        uint32_t RESERVED4[15U];
+  __IM  uint32_t MVFR0;                  /*!< Offset: 0x240 (R/ )  Media and VFP Feature Register 0 */
+  __IM  uint32_t MVFR1;                  /*!< Offset: 0x244 (R/ )  Media and VFP Feature Register 1 */
+  __IM  uint32_t MVFR2;                  /*!< Offset: 0x248 (R/ )  Media and VFP Feature Register 2 */
+        uint32_t RESERVED5[1U];
+  __OM  uint32_t ICIALLU;                /*!< Offset: 0x250 ( /W)  I-Cache Invalidate All to PoU */
+        uint32_t RESERVED6[1U];
+  __OM  uint32_t ICIMVAU;                /*!< Offset: 0x258 ( /W)  I-Cache Invalidate by MVA to PoU */
+  __OM  uint32_t DCIMVAC;                /*!< Offset: 0x25C ( /W)  D-Cache Invalidate by MVA to PoC */
+  __OM  uint32_t DCISW;                  /*!< Offset: 0x260 ( /W)  D-Cache Invalidate by Set-way */
+  __OM  uint32_t DCCMVAU;                /*!< Offset: 0x264 ( /W)  D-Cache Clean by MVA to PoU */
+  __OM  uint32_t DCCMVAC;                /*!< Offset: 0x268 ( /W)  D-Cache Clean by MVA to PoC */
+  __OM  uint32_t DCCSW;                  /*!< Offset: 0x26C ( /W)  D-Cache Clean by Set-way */
+  __OM  uint32_t DCCIMVAC;               /*!< Offset: 0x270 ( /W)  D-Cache Clean and Invalidate by MVA to PoC */
+  __OM  uint32_t DCCISW;                 /*!< Offset: 0x274 ( /W)  D-Cache Clean and Invalidate by Set-way */
+        uint32_t RESERVED7[6U];
+  __IOM uint32_t ITCMCR;                 /*!< Offset: 0x290 (R/W)  Instruction Tightly-Coupled Memory Control Register */
+  __IOM uint32_t DTCMCR;                 /*!< Offset: 0x294 (R/W)  Data Tightly-Coupled Memory Control Registers */
+  __IOM uint32_t AHBPCR;                 /*!< Offset: 0x298 (R/W)  AHBP Control Register */
+  __IOM uint32_t CACR;                   /*!< Offset: 0x29C (R/W)  L1 Cache Control Register */
+  __IOM uint32_t AHBSCR;                 /*!< Offset: 0x2A0 (R/W)  AHB Slave Control Register */
+        uint32_t RESERVED8[1U];
+  __IOM uint32_t ABFSR;                  /*!< Offset: 0x2A8 (R/W)  Auxiliary Bus Fault Status Register */
+} SCB_Type;
+
+/* SCB CPUID Register Definitions */
+#define SCB_CPUID_IMPLEMENTER_Pos          24U                                            /*!< SCB CPUID: IMPLEMENTER Position */
+#define SCB_CPUID_IMPLEMENTER_Msk          (0xFFUL << SCB_CPUID_IMPLEMENTER_Pos)          /*!< SCB CPUID: IMPLEMENTER Mask */
+
+#define SCB_CPUID_VARIANT_Pos              20U                                            /*!< SCB CPUID: VARIANT Position */
+#define SCB_CPUID_VARIANT_Msk              (0xFUL << SCB_CPUID_VARIANT_Pos)               /*!< SCB CPUID: VARIANT Mask */
+
+#define SCB_CPUID_ARCHITECTURE_Pos         16U                                            /*!< SCB CPUID: ARCHITECTURE Position */
+#define SCB_CPUID_ARCHITECTURE_Msk         (0xFUL << SCB_CPUID_ARCHITECTURE_Pos)          /*!< SCB CPUID: ARCHITECTURE Mask */
+
+#define SCB_CPUID_PARTNO_Pos                4U                                            /*!< SCB CPUID: PARTNO Position */
+#define SCB_CPUID_PARTNO_Msk               (0xFFFUL << SCB_CPUID_PARTNO_Pos)              /*!< SCB CPUID: PARTNO Mask */
+
+#define SCB_CPUID_REVISION_Pos              0U                                            /*!< SCB CPUID: REVISION Position */
+#define SCB_CPUID_REVISION_Msk             (0xFUL /*<< SCB_CPUID_REVISION_Pos*/)          /*!< SCB CPUID: REVISION Mask */
+
+/* SCB Interrupt Control State Register Definitions */
+#define SCB_ICSR_NMIPENDSET_Pos            31U                                            /*!< SCB ICSR: NMIPENDSET Position */
+#define SCB_ICSR_NMIPENDSET_Msk            (1UL << SCB_ICSR_NMIPENDSET_Pos)               /*!< SCB ICSR: NMIPENDSET Mask */
+
+#define SCB_ICSR_PENDSVSET_Pos             28U                                            /*!< SCB ICSR: PENDSVSET Position */
+#define SCB_ICSR_PENDSVSET_Msk             (1UL << SCB_ICSR_PENDSVSET_Pos)                /*!< SCB ICSR: PENDSVSET Mask */
+
+#define SCB_ICSR_PENDSVCLR_Pos             27U                                            /*!< SCB ICSR: PENDSVCLR Position */
+#define SCB_ICSR_PENDSVCLR_Msk             (1UL << SCB_ICSR_PENDSVCLR_Pos)                /*!< SCB ICSR: PENDSVCLR Mask */
+
+#define SCB_ICSR_PENDSTSET_Pos             26U                                            /*!< SCB ICSR: PENDSTSET Position */
+#define SCB_ICSR_PENDSTSET_Msk             (1UL << SCB_ICSR_PENDSTSET_Pos)                /*!< SCB ICSR: PENDSTSET Mask */
+
+#define SCB_ICSR_PENDSTCLR_Pos             25U                                            /*!< SCB ICSR: PENDSTCLR Position */
+#define SCB_ICSR_PENDSTCLR_Msk             (1UL << SCB_ICSR_PENDSTCLR_Pos)                /*!< SCB ICSR: PENDSTCLR Mask */
+
+#define SCB_ICSR_ISRPREEMPT_Pos            23U                                            /*!< SCB ICSR: ISRPREEMPT Position */
+#define SCB_ICSR_ISRPREEMPT_Msk            (1UL << SCB_ICSR_ISRPREEMPT_Pos)               /*!< SCB ICSR: ISRPREEMPT Mask */
+
+#define SCB_ICSR_ISRPENDING_Pos            22U                                            /*!< SCB ICSR: ISRPENDING Position */
+#define SCB_ICSR_ISRPENDING_Msk            (1UL << SCB_ICSR_ISRPENDING_Pos)               /*!< SCB ICSR: ISRPENDING Mask */
+
+#define SCB_ICSR_VECTPENDING_Pos           12U                                            /*!< SCB ICSR: VECTPENDING Position */
+#define SCB_ICSR_VECTPENDING_Msk           (0x1FFUL << SCB_ICSR_VECTPENDING_Pos)          /*!< SCB ICSR: VECTPENDING Mask */
+
+#define SCB_ICSR_RETTOBASE_Pos             11U                                            /*!< SCB ICSR: RETTOBASE Position */
+#define SCB_ICSR_RETTOBASE_Msk             (1UL << SCB_ICSR_RETTOBASE_Pos)                /*!< SCB ICSR: RETTOBASE Mask */
+
+#define SCB_ICSR_VECTACTIVE_Pos             0U                                            /*!< SCB ICSR: VECTACTIVE Position */
+#define SCB_ICSR_VECTACTIVE_Msk            (0x1FFUL /*<< SCB_ICSR_VECTACTIVE_Pos*/)       /*!< SCB ICSR: VECTACTIVE Mask */
+
+/* SCB Vector Table Offset Register Definitions */
+#define SCB_VTOR_TBLOFF_Pos                 7U                                            /*!< SCB VTOR: TBLOFF Position */
+#define SCB_VTOR_TBLOFF_Msk                (0x1FFFFFFUL << SCB_VTOR_TBLOFF_Pos)           /*!< SCB VTOR: TBLOFF Mask */
+
+/* SCB Application Interrupt and Reset Control Register Definitions */
+#define SCB_AIRCR_VECTKEY_Pos              16U                                            /*!< SCB AIRCR: VECTKEY Position */
+#define SCB_AIRCR_VECTKEY_Msk              (0xFFFFUL << SCB_AIRCR_VECTKEY_Pos)            /*!< SCB AIRCR: VECTKEY Mask */
+
+#define SCB_AIRCR_VECTKEYSTAT_Pos          16U                                            /*!< SCB AIRCR: VECTKEYSTAT Position */
+#define SCB_AIRCR_VECTKEYSTAT_Msk          (0xFFFFUL << SCB_AIRCR_VECTKEYSTAT_Pos)        /*!< SCB AIRCR: VECTKEYSTAT Mask */
+
+#define SCB_AIRCR_ENDIANESS_Pos            15U                                            /*!< SCB AIRCR: ENDIANESS Position */
+#define SCB_AIRCR_ENDIANESS_Msk            (1UL << SCB_AIRCR_ENDIANESS_Pos)               /*!< SCB AIRCR: ENDIANESS Mask */
+
+#define SCB_AIRCR_PRIGROUP_Pos              8U                                            /*!< SCB AIRCR: PRIGROUP Position */
+#define SCB_AIRCR_PRIGROUP_Msk             (7UL << SCB_AIRCR_PRIGROUP_Pos)                /*!< SCB AIRCR: PRIGROUP Mask */
+
+#define SCB_AIRCR_SYSRESETREQ_Pos           2U                                            /*!< SCB AIRCR: SYSRESETREQ Position */
+#define SCB_AIRCR_SYSRESETREQ_Msk          (1UL << SCB_AIRCR_SYSRESETREQ_Pos)             /*!< SCB AIRCR: SYSRESETREQ Mask */
+
+#define SCB_AIRCR_VECTCLRACTIVE_Pos         1U                                            /*!< SCB AIRCR: VECTCLRACTIVE Position */
+#define SCB_AIRCR_VECTCLRACTIVE_Msk        (1UL << SCB_AIRCR_VECTCLRACTIVE_Pos)           /*!< SCB AIRCR: VECTCLRACTIVE Mask */
+
+#define SCB_AIRCR_VECTRESET_Pos             0U                                            /*!< SCB AIRCR: VECTRESET Position */
+#define SCB_AIRCR_VECTRESET_Msk            (1UL /*<< SCB_AIRCR_VECTRESET_Pos*/)           /*!< SCB AIRCR: VECTRESET Mask */
+
+/* SCB System Control Register Definitions */
+#define SCB_SCR_SEVONPEND_Pos               4U                                            /*!< SCB SCR: SEVONPEND Position */
+#define SCB_SCR_SEVONPEND_Msk              (1UL << SCB_SCR_SEVONPEND_Pos)                 /*!< SCB SCR: SEVONPEND Mask */
+
+#define SCB_SCR_SLEEPDEEP_Pos               2U                                            /*!< SCB SCR: SLEEPDEEP Position */
+#define SCB_SCR_SLEEPDEEP_Msk              (1UL << SCB_SCR_SLEEPDEEP_Pos)                 /*!< SCB SCR: SLEEPDEEP Mask */
+
+#define SCB_SCR_SLEEPONEXIT_Pos             1U                                            /*!< SCB SCR: SLEEPONEXIT Position */
+#define SCB_SCR_SLEEPONEXIT_Msk            (1UL << SCB_SCR_SLEEPONEXIT_Pos)               /*!< SCB SCR: SLEEPONEXIT Mask */
+
+/* SCB Configuration Control Register Definitions */
+#define SCB_CCR_BP_Pos                      18U                                           /*!< SCB CCR: Branch prediction enable bit Position */
+#define SCB_CCR_BP_Msk                     (1UL << SCB_CCR_BP_Pos)                        /*!< SCB CCR: Branch prediction enable bit Mask */
+
+#define SCB_CCR_IC_Pos                      17U                                           /*!< SCB CCR: Instruction cache enable bit Position */
+#define SCB_CCR_IC_Msk                     (1UL << SCB_CCR_IC_Pos)                        /*!< SCB CCR: Instruction cache enable bit Mask */
+
+#define SCB_CCR_DC_Pos                      16U                                           /*!< SCB CCR: Cache enable bit Position */
+#define SCB_CCR_DC_Msk                     (1UL << SCB_CCR_DC_Pos)                        /*!< SCB CCR: Cache enable bit Mask */
+
+#define SCB_CCR_STKALIGN_Pos                9U                                            /*!< SCB CCR: STKALIGN Position */
+#define SCB_CCR_STKALIGN_Msk               (1UL << SCB_CCR_STKALIGN_Pos)                  /*!< SCB CCR: STKALIGN Mask */
+
+#define SCB_CCR_BFHFNMIGN_Pos               8U                                            /*!< SCB CCR: BFHFNMIGN Position */
+#define SCB_CCR_BFHFNMIGN_Msk              (1UL << SCB_CCR_BFHFNMIGN_Pos)                 /*!< SCB CCR: BFHFNMIGN Mask */
+
+#define SCB_CCR_DIV_0_TRP_Pos               4U                                            /*!< SCB CCR: DIV_0_TRP Position */
+#define SCB_CCR_DIV_0_TRP_Msk              (1UL << SCB_CCR_DIV_0_TRP_Pos)                 /*!< SCB CCR: DIV_0_TRP Mask */
+
+#define SCB_CCR_UNALIGN_TRP_Pos             3U                                            /*!< SCB CCR: UNALIGN_TRP Position */
+#define SCB_CCR_UNALIGN_TRP_Msk            (1UL << SCB_CCR_UNALIGN_TRP_Pos)               /*!< SCB CCR: UNALIGN_TRP Mask */
+
+#define SCB_CCR_USERSETMPEND_Pos            1U                                            /*!< SCB CCR: USERSETMPEND Position */
+#define SCB_CCR_USERSETMPEND_Msk           (1UL << SCB_CCR_USERSETMPEND_Pos)              /*!< SCB CCR: USERSETMPEND Mask */
+
+#define SCB_CCR_NONBASETHRDENA_Pos          0U                                            /*!< SCB CCR: NONBASETHRDENA Position */
+#define SCB_CCR_NONBASETHRDENA_Msk         (1UL /*<< SCB_CCR_NONBASETHRDENA_Pos*/)        /*!< SCB CCR: NONBASETHRDENA Mask */
+
+/* SCB System Handler Control and State Register Definitions */
+#define SCB_SHCSR_USGFAULTENA_Pos          18U                                            /*!< SCB SHCSR: USGFAULTENA Position */
+#define SCB_SHCSR_USGFAULTENA_Msk          (1UL << SCB_SHCSR_USGFAULTENA_Pos)             /*!< SCB SHCSR: USGFAULTENA Mask */
+
+#define SCB_SHCSR_BUSFAULTENA_Pos          17U                                            /*!< SCB SHCSR: BUSFAULTENA Position */
+#define SCB_SHCSR_BUSFAULTENA_Msk          (1UL << SCB_SHCSR_BUSFAULTENA_Pos)             /*!< SCB SHCSR: BUSFAULTENA Mask */
+
+#define SCB_SHCSR_MEMFAULTENA_Pos          16U                                            /*!< SCB SHCSR: MEMFAULTENA Position */
+#define SCB_SHCSR_MEMFAULTENA_Msk          (1UL << SCB_SHCSR_MEMFAULTENA_Pos)             /*!< SCB SHCSR: MEMFAULTENA Mask */
+
+#define SCB_SHCSR_SVCALLPENDED_Pos         15U                                            /*!< SCB SHCSR: SVCALLPENDED Position */
+#define SCB_SHCSR_SVCALLPENDED_Msk         (1UL << SCB_SHCSR_SVCALLPENDED_Pos)            /*!< SCB SHCSR: SVCALLPENDED Mask */
+
+#define SCB_SHCSR_BUSFAULTPENDED_Pos       14U                                            /*!< SCB SHCSR: BUSFAULTPENDED Position */
+#define SCB_SHCSR_BUSFAULTPENDED_Msk       (1UL << SCB_SHCSR_BUSFAULTPENDED_Pos)          /*!< SCB SHCSR: BUSFAULTPENDED Mask */
+
+#define SCB_SHCSR_MEMFAULTPENDED_Pos       13U                                            /*!< SCB SHCSR: MEMFAULTPENDED Position */
+#define SCB_SHCSR_MEMFAULTPENDED_Msk       (1UL << SCB_SHCSR_MEMFAULTPENDED_Pos)          /*!< SCB SHCSR: MEMFAULTPENDED Mask */
+
+#define SCB_SHCSR_USGFAULTPENDED_Pos       12U                                            /*!< SCB SHCSR: USGFAULTPENDED Position */
+#define SCB_SHCSR_USGFAULTPENDED_Msk       (1UL << SCB_SHCSR_USGFAULTPENDED_Pos)          /*!< SCB SHCSR: USGFAULTPENDED Mask */
+
+#define SCB_SHCSR_SYSTICKACT_Pos           11U                                            /*!< SCB SHCSR: SYSTICKACT Position */
+#define SCB_SHCSR_SYSTICKACT_Msk           (1UL << SCB_SHCSR_SYSTICKACT_Pos)              /*!< SCB SHCSR: SYSTICKACT Mask */
+
+#define SCB_SHCSR_PENDSVACT_Pos            10U                                            /*!< SCB SHCSR: PENDSVACT Position */
+#define SCB_SHCSR_PENDSVACT_Msk            (1UL << SCB_SHCSR_PENDSVACT_Pos)               /*!< SCB SHCSR: PENDSVACT Mask */
+
+#define SCB_SHCSR_MONITORACT_Pos            8U                                            /*!< SCB SHCSR: MONITORACT Position */
+#define SCB_SHCSR_MONITORACT_Msk           (1UL << SCB_SHCSR_MONITORACT_Pos)              /*!< SCB SHCSR: MONITORACT Mask */
+
+#define SCB_SHCSR_SVCALLACT_Pos             7U                                            /*!< SCB SHCSR: SVCALLACT Position */
+#define SCB_SHCSR_SVCALLACT_Msk            (1UL << SCB_SHCSR_SVCALLACT_Pos)               /*!< SCB SHCSR: SVCALLACT Mask */
+
+#define SCB_SHCSR_USGFAULTACT_Pos           3U                                            /*!< SCB SHCSR: USGFAULTACT Position */
+#define SCB_SHCSR_USGFAULTACT_Msk          (1UL << SCB_SHCSR_USGFAULTACT_Pos)             /*!< SCB SHCSR: USGFAULTACT Mask */
+
+#define SCB_SHCSR_BUSFAULTACT_Pos           1U                                            /*!< SCB SHCSR: BUSFAULTACT Position */
+#define SCB_SHCSR_BUSFAULTACT_Msk          (1UL << SCB_SHCSR_BUSFAULTACT_Pos)             /*!< SCB SHCSR: BUSFAULTACT Mask */
+
+#define SCB_SHCSR_MEMFAULTACT_Pos           0U                                            /*!< SCB SHCSR: MEMFAULTACT Position */
+#define SCB_SHCSR_MEMFAULTACT_Msk          (1UL /*<< SCB_SHCSR_MEMFAULTACT_Pos*/)         /*!< SCB SHCSR: MEMFAULTACT Mask */
+
+/* SCB Configurable Fault Status Register Definitions */
+#define SCB_CFSR_USGFAULTSR_Pos            16U                                            /*!< SCB CFSR: Usage Fault Status Register Position */
+#define SCB_CFSR_USGFAULTSR_Msk            (0xFFFFUL << SCB_CFSR_USGFAULTSR_Pos)          /*!< SCB CFSR: Usage Fault Status Register Mask */
+
+#define SCB_CFSR_BUSFAULTSR_Pos             8U                                            /*!< SCB CFSR: Bus Fault Status Register Position */
+#define SCB_CFSR_BUSFAULTSR_Msk            (0xFFUL << SCB_CFSR_BUSFAULTSR_Pos)            /*!< SCB CFSR: Bus Fault Status Register Mask */
+
+#define SCB_CFSR_MEMFAULTSR_Pos             0U                                            /*!< SCB CFSR: Memory Manage Fault Status Register Position */
+#define SCB_CFSR_MEMFAULTSR_Msk            (0xFFUL /*<< SCB_CFSR_MEMFAULTSR_Pos*/)        /*!< SCB CFSR: Memory Manage Fault Status Register Mask */
+
+/* MemManage Fault Status Register (part of SCB Configurable Fault Status Register) */
+#define SCB_CFSR_MMARVALID_Pos             (SCB_SHCSR_MEMFAULTACT_Pos + 7U)               /*!< SCB CFSR (MMFSR): MMARVALID Position */
+#define SCB_CFSR_MMARVALID_Msk             (1UL << SCB_CFSR_MMARVALID_Pos)                /*!< SCB CFSR (MMFSR): MMARVALID Mask */
+
+#define SCB_CFSR_MLSPERR_Pos               (SCB_SHCSR_MEMFAULTACT_Pos + 5U)               /*!< SCB CFSR (MMFSR): MLSPERR Position */
+#define SCB_CFSR_MLSPERR_Msk               (1UL << SCB_CFSR_MLSPERR_Pos)                  /*!< SCB CFSR (MMFSR): MLSPERR Mask */
+
+#define SCB_CFSR_MSTKERR_Pos               (SCB_SHCSR_MEMFAULTACT_Pos + 4U)               /*!< SCB CFSR (MMFSR): MSTKERR Position */
+#define SCB_CFSR_MSTKERR_Msk               (1UL << SCB_CFSR_MSTKERR_Pos)                  /*!< SCB CFSR (MMFSR): MSTKERR Mask */
+
+#define SCB_CFSR_MUNSTKERR_Pos             (SCB_SHCSR_MEMFAULTACT_Pos + 3U)               /*!< SCB CFSR (MMFSR): MUNSTKERR Position */
+#define SCB_CFSR_MUNSTKERR_Msk             (1UL << SCB_CFSR_MUNSTKERR_Pos)                /*!< SCB CFSR (MMFSR): MUNSTKERR Mask */
+
+#define SCB_CFSR_DACCVIOL_Pos              (SCB_SHCSR_MEMFAULTACT_Pos + 1U)               /*!< SCB CFSR (MMFSR): DACCVIOL Position */
+#define SCB_CFSR_DACCVIOL_Msk              (1UL << SCB_CFSR_DACCVIOL_Pos)                 /*!< SCB CFSR (MMFSR): DACCVIOL Mask */
+
+#define SCB_CFSR_IACCVIOL_Pos              (SCB_SHCSR_MEMFAULTACT_Pos + 0U)               /*!< SCB CFSR (MMFSR): IACCVIOL Position */
+#define SCB_CFSR_IACCVIOL_Msk              (1UL /*<< SCB_CFSR_IACCVIOL_Pos*/)             /*!< SCB CFSR (MMFSR): IACCVIOL Mask */
+
+/* BusFault Status Register (part of SCB Configurable Fault Status Register) */
+#define SCB_CFSR_BFARVALID_Pos            (SCB_CFSR_BUSFAULTSR_Pos + 7U)                  /*!< SCB CFSR (BFSR): BFARVALID Position */
+#define SCB_CFSR_BFARVALID_Msk            (1UL << SCB_CFSR_BFARVALID_Pos)                 /*!< SCB CFSR (BFSR): BFARVALID Mask */
+
+#define SCB_CFSR_LSPERR_Pos               (SCB_CFSR_BUSFAULTSR_Pos + 5U)                  /*!< SCB CFSR (BFSR): LSPERR Position */
+#define SCB_CFSR_LSPERR_Msk               (1UL << SCB_CFSR_LSPERR_Pos)                    /*!< SCB CFSR (BFSR): LSPERR Mask */
+
+#define SCB_CFSR_STKERR_Pos               (SCB_CFSR_BUSFAULTSR_Pos + 4U)                  /*!< SCB CFSR (BFSR): STKERR Position */
+#define SCB_CFSR_STKERR_Msk               (1UL << SCB_CFSR_STKERR_Pos)                    /*!< SCB CFSR (BFSR): STKERR Mask */
+
+#define SCB_CFSR_UNSTKERR_Pos             (SCB_CFSR_BUSFAULTSR_Pos + 3U)                  /*!< SCB CFSR (BFSR): UNSTKERR Position */
+#define SCB_CFSR_UNSTKERR_Msk             (1UL << SCB_CFSR_UNSTKERR_Pos)                  /*!< SCB CFSR (BFSR): UNSTKERR Mask */
+
+#define SCB_CFSR_IMPRECISERR_Pos          (SCB_CFSR_BUSFAULTSR_Pos + 2U)                  /*!< SCB CFSR (BFSR): IMPRECISERR Position */
+#define SCB_CFSR_IMPRECISERR_Msk          (1UL << SCB_CFSR_IMPRECISERR_Pos)               /*!< SCB CFSR (BFSR): IMPRECISERR Mask */
+
+#define SCB_CFSR_PRECISERR_Pos            (SCB_CFSR_BUSFAULTSR_Pos + 1U)                  /*!< SCB CFSR (BFSR): PRECISERR Position */
+#define SCB_CFSR_PRECISERR_Msk            (1UL << SCB_CFSR_PRECISERR_Pos)                 /*!< SCB CFSR (BFSR): PRECISERR Mask */
+
+#define SCB_CFSR_IBUSERR_Pos              (SCB_CFSR_BUSFAULTSR_Pos + 0U)                  /*!< SCB CFSR (BFSR): IBUSERR Position */
+#define SCB_CFSR_IBUSERR_Msk              (1UL << SCB_CFSR_IBUSERR_Pos)                   /*!< SCB CFSR (BFSR): IBUSERR Mask */
+
+/* UsageFault Status Register (part of SCB Configurable Fault Status Register) */
+#define SCB_CFSR_DIVBYZERO_Pos            (SCB_CFSR_USGFAULTSR_Pos + 9U)                  /*!< SCB CFSR (UFSR): DIVBYZERO Position */
+#define SCB_CFSR_DIVBYZERO_Msk            (1UL << SCB_CFSR_DIVBYZERO_Pos)                 /*!< SCB CFSR (UFSR): DIVBYZERO Mask */
+
+#define SCB_CFSR_UNALIGNED_Pos            (SCB_CFSR_USGFAULTSR_Pos + 8U)                  /*!< SCB CFSR (UFSR): UNALIGNED Position */
+#define SCB_CFSR_UNALIGNED_Msk            (1UL << SCB_CFSR_UNALIGNED_Pos)                 /*!< SCB CFSR (UFSR): UNALIGNED Mask */
+
+#define SCB_CFSR_NOCP_Pos                 (SCB_CFSR_USGFAULTSR_Pos + 3U)                  /*!< SCB CFSR (UFSR): NOCP Position */
+#define SCB_CFSR_NOCP_Msk                 (1UL << SCB_CFSR_NOCP_Pos)                      /*!< SCB CFSR (UFSR): NOCP Mask */
+
+#define SCB_CFSR_INVPC_Pos                (SCB_CFSR_USGFAULTSR_Pos + 2U)                  /*!< SCB CFSR (UFSR): INVPC Position */
+#define SCB_CFSR_INVPC_Msk                (1UL << SCB_CFSR_INVPC_Pos)                     /*!< SCB CFSR (UFSR): INVPC Mask */
+
+#define SCB_CFSR_INVSTATE_Pos             (SCB_CFSR_USGFAULTSR_Pos + 1U)                  /*!< SCB CFSR (UFSR): INVSTATE Position */
+#define SCB_CFSR_INVSTATE_Msk             (1UL << SCB_CFSR_INVSTATE_Pos)                  /*!< SCB CFSR (UFSR): INVSTATE Mask */
+
+#define SCB_CFSR_UNDEFINSTR_Pos           (SCB_CFSR_USGFAULTSR_Pos + 0U)                  /*!< SCB CFSR (UFSR): UNDEFINSTR Position */
+#define SCB_CFSR_UNDEFINSTR_Msk           (1UL << SCB_CFSR_UNDEFINSTR_Pos)                /*!< SCB CFSR (UFSR): UNDEFINSTR Mask */
+
+/* SCB Hard Fault Status Register Definitions */
+#define SCB_HFSR_DEBUGEVT_Pos              31U                                            /*!< SCB HFSR: DEBUGEVT Position */
+#define SCB_HFSR_DEBUGEVT_Msk              (1UL << SCB_HFSR_DEBUGEVT_Pos)                 /*!< SCB HFSR: DEBUGEVT Mask */
+
+#define SCB_HFSR_FORCED_Pos                30U                                            /*!< SCB HFSR: FORCED Position */
+#define SCB_HFSR_FORCED_Msk                (1UL << SCB_HFSR_FORCED_Pos)                   /*!< SCB HFSR: FORCED Mask */
+
+#define SCB_HFSR_VECTTBL_Pos                1U                                            /*!< SCB HFSR: VECTTBL Position */
+#define SCB_HFSR_VECTTBL_Msk               (1UL << SCB_HFSR_VECTTBL_Pos)                  /*!< SCB HFSR: VECTTBL Mask */
+
+/* SCB Debug Fault Status Register Definitions */
+#define SCB_DFSR_EXTERNAL_Pos               4U                                            /*!< SCB DFSR: EXTERNAL Position */
+#define SCB_DFSR_EXTERNAL_Msk              (1UL << SCB_DFSR_EXTERNAL_Pos)                 /*!< SCB DFSR: EXTERNAL Mask */
+
+#define SCB_DFSR_VCATCH_Pos                 3U                                            /*!< SCB DFSR: VCATCH Position */
+#define SCB_DFSR_VCATCH_Msk                (1UL << SCB_DFSR_VCATCH_Pos)                   /*!< SCB DFSR: VCATCH Mask */
+
+#define SCB_DFSR_DWTTRAP_Pos                2U                                            /*!< SCB DFSR: DWTTRAP Position */
+#define SCB_DFSR_DWTTRAP_Msk               (1UL << SCB_DFSR_DWTTRAP_Pos)                  /*!< SCB DFSR: DWTTRAP Mask */
+
+#define SCB_DFSR_BKPT_Pos                   1U                                            /*!< SCB DFSR: BKPT Position */
+#define SCB_DFSR_BKPT_Msk                  (1UL << SCB_DFSR_BKPT_Pos)                     /*!< SCB DFSR: BKPT Mask */
+
+#define SCB_DFSR_HALTED_Pos                 0U                                            /*!< SCB DFSR: HALTED Position */
+#define SCB_DFSR_HALTED_Msk                (1UL /*<< SCB_DFSR_HALTED_Pos*/)               /*!< SCB DFSR: HALTED Mask */
+
+/* SCB Cache Level ID Register Definitions */
+#define SCB_CLIDR_LOUU_Pos                 27U                                            /*!< SCB CLIDR: LoUU Position */
+#define SCB_CLIDR_LOUU_Msk                 (7UL << SCB_CLIDR_LOUU_Pos)                    /*!< SCB CLIDR: LoUU Mask */
+
+#define SCB_CLIDR_LOC_Pos                  24U                                            /*!< SCB CLIDR: LoC Position */
+#define SCB_CLIDR_LOC_Msk                  (7UL << SCB_CLIDR_LOC_Pos)                     /*!< SCB CLIDR: LoC Mask */
+
+/* SCB Cache Type Register Definitions */
+#define SCB_CTR_FORMAT_Pos                 29U                                            /*!< SCB CTR: Format Position */
+#define SCB_CTR_FORMAT_Msk                 (7UL << SCB_CTR_FORMAT_Pos)                    /*!< SCB CTR: Format Mask */
+
+#define SCB_CTR_CWG_Pos                    24U                                            /*!< SCB CTR: CWG Position */
+#define SCB_CTR_CWG_Msk                    (0xFUL << SCB_CTR_CWG_Pos)                     /*!< SCB CTR: CWG Mask */
+
+#define SCB_CTR_ERG_Pos                    20U                                            /*!< SCB CTR: ERG Position */
+#define SCB_CTR_ERG_Msk                    (0xFUL << SCB_CTR_ERG_Pos)                     /*!< SCB CTR: ERG Mask */
+
+#define SCB_CTR_DMINLINE_Pos               16U                                            /*!< SCB CTR: DminLine Position */
+#define SCB_CTR_DMINLINE_Msk               (0xFUL << SCB_CTR_DMINLINE_Pos)                /*!< SCB CTR: DminLine Mask */
+
+#define SCB_CTR_IMINLINE_Pos                0U                                            /*!< SCB CTR: ImInLine Position */
+#define SCB_CTR_IMINLINE_Msk               (0xFUL /*<< SCB_CTR_IMINLINE_Pos*/)            /*!< SCB CTR: ImInLine Mask */
+
+/* SCB Cache Size ID Register Definitions */
+#define SCB_CCSIDR_WT_Pos                  31U                                            /*!< SCB CCSIDR: WT Position */
+#define SCB_CCSIDR_WT_Msk                  (1UL << SCB_CCSIDR_WT_Pos)                     /*!< SCB CCSIDR: WT Mask */
+
+#define SCB_CCSIDR_WB_Pos                  30U                                            /*!< SCB CCSIDR: WB Position */
+#define SCB_CCSIDR_WB_Msk                  (1UL << SCB_CCSIDR_WB_Pos)                     /*!< SCB CCSIDR: WB Mask */
+
+#define SCB_CCSIDR_RA_Pos                  29U                                            /*!< SCB CCSIDR: RA Position */
+#define SCB_CCSIDR_RA_Msk                  (1UL << SCB_CCSIDR_RA_Pos)                     /*!< SCB CCSIDR: RA Mask */
+
+#define SCB_CCSIDR_WA_Pos                  28U                                            /*!< SCB CCSIDR: WA Position */
+#define SCB_CCSIDR_WA_Msk                  (1UL << SCB_CCSIDR_WA_Pos)                     /*!< SCB CCSIDR: WA Mask */
+
+#define SCB_CCSIDR_NUMSETS_Pos             13U                                            /*!< SCB CCSIDR: NumSets Position */
+#define SCB_CCSIDR_NUMSETS_Msk             (0x7FFFUL << SCB_CCSIDR_NUMSETS_Pos)           /*!< SCB CCSIDR: NumSets Mask */
+
+#define SCB_CCSIDR_ASSOCIATIVITY_Pos        3U                                            /*!< SCB CCSIDR: Associativity Position */
+#define SCB_CCSIDR_ASSOCIATIVITY_Msk       (0x3FFUL << SCB_CCSIDR_ASSOCIATIVITY_Pos)      /*!< SCB CCSIDR: Associativity Mask */
+
+#define SCB_CCSIDR_LINESIZE_Pos             0U                                            /*!< SCB CCSIDR: LineSize Position */
+#define SCB_CCSIDR_LINESIZE_Msk            (7UL /*<< SCB_CCSIDR_LINESIZE_Pos*/)           /*!< SCB CCSIDR: LineSize Mask */
+
+/* SCB Cache Size Selection Register Definitions */
+#define SCB_CSSELR_LEVEL_Pos                1U                                            /*!< SCB CSSELR: Level Position */
+#define SCB_CSSELR_LEVEL_Msk               (7UL << SCB_CSSELR_LEVEL_Pos)                  /*!< SCB CSSELR: Level Mask */
+
+#define SCB_CSSELR_IND_Pos                  0U                                            /*!< SCB CSSELR: InD Position */
+#define SCB_CSSELR_IND_Msk                 (1UL /*<< SCB_CSSELR_IND_Pos*/)                /*!< SCB CSSELR: InD Mask */
+
+/* SCB Software Triggered Interrupt Register Definitions */
+#define SCB_STIR_INTID_Pos                  0U                                            /*!< SCB STIR: INTID Position */
+#define SCB_STIR_INTID_Msk                 (0x1FFUL /*<< SCB_STIR_INTID_Pos*/)            /*!< SCB STIR: INTID Mask */
+
+/* SCB D-Cache Invalidate by Set-way Register Definitions */
+#define SCB_DCISW_WAY_Pos                  30U                                            /*!< SCB DCISW: Way Position */
+#define SCB_DCISW_WAY_Msk                  (3UL << SCB_DCISW_WAY_Pos)                     /*!< SCB DCISW: Way Mask */
+
+#define SCB_DCISW_SET_Pos                   5U                                            /*!< SCB DCISW: Set Position */
+#define SCB_DCISW_SET_Msk                  (0x1FFUL << SCB_DCISW_SET_Pos)                 /*!< SCB DCISW: Set Mask */
+
+/* SCB D-Cache Clean by Set-way Register Definitions */
+#define SCB_DCCSW_WAY_Pos                  30U                                            /*!< SCB DCCSW: Way Position */
+#define SCB_DCCSW_WAY_Msk                  (3UL << SCB_DCCSW_WAY_Pos)                     /*!< SCB DCCSW: Way Mask */
+
+#define SCB_DCCSW_SET_Pos                   5U                                            /*!< SCB DCCSW: Set Position */
+#define SCB_DCCSW_SET_Msk                  (0x1FFUL << SCB_DCCSW_SET_Pos)                 /*!< SCB DCCSW: Set Mask */
+
+/* SCB D-Cache Clean and Invalidate by Set-way Register Definitions */
+#define SCB_DCCISW_WAY_Pos                 30U                                            /*!< SCB DCCISW: Way Position */
+#define SCB_DCCISW_WAY_Msk                 (3UL << SCB_DCCISW_WAY_Pos)                    /*!< SCB DCCISW: Way Mask */
+
+#define SCB_DCCISW_SET_Pos                  5U                                            /*!< SCB DCCISW: Set Position */
+#define SCB_DCCISW_SET_Msk                 (0x1FFUL << SCB_DCCISW_SET_Pos)                /*!< SCB DCCISW: Set Mask */
+
+/* Instruction Tightly-Coupled Memory Control Register Definitions */
+#define SCB_ITCMCR_SZ_Pos                   3U                                            /*!< SCB ITCMCR: SZ Position */
+#define SCB_ITCMCR_SZ_Msk                  (0xFUL << SCB_ITCMCR_SZ_Pos)                   /*!< SCB ITCMCR: SZ Mask */
+
+#define SCB_ITCMCR_RETEN_Pos                2U                                            /*!< SCB ITCMCR: RETEN Position */
+#define SCB_ITCMCR_RETEN_Msk               (1UL << SCB_ITCMCR_RETEN_Pos)                  /*!< SCB ITCMCR: RETEN Mask */
+
+#define SCB_ITCMCR_RMW_Pos                  1U                                            /*!< SCB ITCMCR: RMW Position */
+#define SCB_ITCMCR_RMW_Msk                 (1UL << SCB_ITCMCR_RMW_Pos)                    /*!< SCB ITCMCR: RMW Mask */
+
+#define SCB_ITCMCR_EN_Pos                   0U                                            /*!< SCB ITCMCR: EN Position */
+#define SCB_ITCMCR_EN_Msk                  (1UL /*<< SCB_ITCMCR_EN_Pos*/)                 /*!< SCB ITCMCR: EN Mask */
+
+/* Data Tightly-Coupled Memory Control Register Definitions */
+#define SCB_DTCMCR_SZ_Pos                   3U                                            /*!< SCB DTCMCR: SZ Position */
+#define SCB_DTCMCR_SZ_Msk                  (0xFUL << SCB_DTCMCR_SZ_Pos)                   /*!< SCB DTCMCR: SZ Mask */
+
+#define SCB_DTCMCR_RETEN_Pos                2U                                            /*!< SCB DTCMCR: RETEN Position */
+#define SCB_DTCMCR_RETEN_Msk               (1UL << SCB_DTCMCR_RETEN_Pos)                   /*!< SCB DTCMCR: RETEN Mask */
+
+#define SCB_DTCMCR_RMW_Pos                  1U                                            /*!< SCB DTCMCR: RMW Position */
+#define SCB_DTCMCR_RMW_Msk                 (1UL << SCB_DTCMCR_RMW_Pos)                    /*!< SCB DTCMCR: RMW Mask */
+
+#define SCB_DTCMCR_EN_Pos                   0U                                            /*!< SCB DTCMCR: EN Position */
+#define SCB_DTCMCR_EN_Msk                  (1UL /*<< SCB_DTCMCR_EN_Pos*/)                 /*!< SCB DTCMCR: EN Mask */
+
+/* AHBP Control Register Definitions */
+#define SCB_AHBPCR_SZ_Pos                   1U                                            /*!< SCB AHBPCR: SZ Position */
+#define SCB_AHBPCR_SZ_Msk                  (7UL << SCB_AHBPCR_SZ_Pos)                     /*!< SCB AHBPCR: SZ Mask */
+
+#define SCB_AHBPCR_EN_Pos                   0U                                            /*!< SCB AHBPCR: EN Position */
+#define SCB_AHBPCR_EN_Msk                  (1UL /*<< SCB_AHBPCR_EN_Pos*/)                 /*!< SCB AHBPCR: EN Mask */
+
+/* L1 Cache Control Register Definitions */
+#define SCB_CACR_FORCEWT_Pos                2U                                            /*!< SCB CACR: FORCEWT Position */
+#define SCB_CACR_FORCEWT_Msk               (1UL << SCB_CACR_FORCEWT_Pos)                  /*!< SCB CACR: FORCEWT Mask */
+
+#define SCB_CACR_ECCEN_Pos                  1U                                            /*!< SCB CACR: ECCEN Position */
+#define SCB_CACR_ECCEN_Msk                 (1UL << SCB_CACR_ECCEN_Pos)                    /*!< SCB CACR: ECCEN Mask */
+
+#define SCB_CACR_SIWT_Pos                   0U                                            /*!< SCB CACR: SIWT Position */
+#define SCB_CACR_SIWT_Msk                  (1UL /*<< SCB_CACR_SIWT_Pos*/)                 /*!< SCB CACR: SIWT Mask */
+
+/* AHBS Control Register Definitions */
+#define SCB_AHBSCR_INITCOUNT_Pos           11U                                            /*!< SCB AHBSCR: INITCOUNT Position */
+#define SCB_AHBSCR_INITCOUNT_Msk           (0x1FUL << SCB_AHBPCR_INITCOUNT_Pos)           /*!< SCB AHBSCR: INITCOUNT Mask */
+
+#define SCB_AHBSCR_TPRI_Pos                 2U                                            /*!< SCB AHBSCR: TPRI Position */
+#define SCB_AHBSCR_TPRI_Msk                (0x1FFUL << SCB_AHBPCR_TPRI_Pos)               /*!< SCB AHBSCR: TPRI Mask */
+
+#define SCB_AHBSCR_CTL_Pos                  0U                                            /*!< SCB AHBSCR: CTL Position*/
+#define SCB_AHBSCR_CTL_Msk                 (3UL /*<< SCB_AHBPCR_CTL_Pos*/)                /*!< SCB AHBSCR: CTL Mask */
+
+/* Auxiliary Bus Fault Status Register Definitions */
+#define SCB_ABFSR_AXIMTYPE_Pos              8U                                            /*!< SCB ABFSR: AXIMTYPE Position*/
+#define SCB_ABFSR_AXIMTYPE_Msk             (3UL << SCB_ABFSR_AXIMTYPE_Pos)                /*!< SCB ABFSR: AXIMTYPE Mask */
+
+#define SCB_ABFSR_EPPB_Pos                  4U                                            /*!< SCB ABFSR: EPPB Position*/
+#define SCB_ABFSR_EPPB_Msk                 (1UL << SCB_ABFSR_EPPB_Pos)                    /*!< SCB ABFSR: EPPB Mask */
+
+#define SCB_ABFSR_AXIM_Pos                  3U                                            /*!< SCB ABFSR: AXIM Position*/
+#define SCB_ABFSR_AXIM_Msk                 (1UL << SCB_ABFSR_AXIM_Pos)                    /*!< SCB ABFSR: AXIM Mask */
+
+#define SCB_ABFSR_AHBP_Pos                  2U                                            /*!< SCB ABFSR: AHBP Position*/
+#define SCB_ABFSR_AHBP_Msk                 (1UL << SCB_ABFSR_AHBP_Pos)                    /*!< SCB ABFSR: AHBP Mask */
+
+#define SCB_ABFSR_DTCM_Pos                  1U                                            /*!< SCB ABFSR: DTCM Position*/
+#define SCB_ABFSR_DTCM_Msk                 (1UL << SCB_ABFSR_DTCM_Pos)                    /*!< SCB ABFSR: DTCM Mask */
+
+#define SCB_ABFSR_ITCM_Pos                  0U                                            /*!< SCB ABFSR: ITCM Position*/
+#define SCB_ABFSR_ITCM_Msk                 (1UL /*<< SCB_ABFSR_ITCM_Pos*/)                /*!< SCB ABFSR: ITCM Mask */
+
+/*@} end of group CMSIS_SCB */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_SCnSCB System Controls not in SCB (SCnSCB)
+  \brief    Type definitions for the System Control and ID Register not in the SCB
+  @{
+ */
+
+/**
+  \brief  Structure type to access the System Control and ID Register not in the SCB.
+ */
+typedef struct
+{
+        uint32_t RESERVED0[1U];
+  __IM  uint32_t ICTR;                   /*!< Offset: 0x004 (R/ )  Interrupt Controller Type Register */
+  __IOM uint32_t ACTLR;                  /*!< Offset: 0x008 (R/W)  Auxiliary Control Register */
+} SCnSCB_Type;
+
+/* Interrupt Controller Type Register Definitions */
+#define SCnSCB_ICTR_INTLINESNUM_Pos         0U                                         /*!< ICTR: INTLINESNUM Position */
+#define SCnSCB_ICTR_INTLINESNUM_Msk        (0xFUL /*<< SCnSCB_ICTR_INTLINESNUM_Pos*/)  /*!< ICTR: INTLINESNUM Mask */
+
+/* Auxiliary Control Register Definitions */
+#define SCnSCB_ACTLR_DISITMATBFLUSH_Pos    12U                                         /*!< ACTLR: DISITMATBFLUSH Position */
+#define SCnSCB_ACTLR_DISITMATBFLUSH_Msk    (1UL << SCnSCB_ACTLR_DISITMATBFLUSH_Pos)    /*!< ACTLR: DISITMATBFLUSH Mask */
+
+#define SCnSCB_ACTLR_DISRAMODE_Pos         11U                                         /*!< ACTLR: DISRAMODE Position */
+#define SCnSCB_ACTLR_DISRAMODE_Msk         (1UL << SCnSCB_ACTLR_DISRAMODE_Pos)         /*!< ACTLR: DISRAMODE Mask */
+
+#define SCnSCB_ACTLR_FPEXCODIS_Pos         10U                                         /*!< ACTLR: FPEXCODIS Position */
+#define SCnSCB_ACTLR_FPEXCODIS_Msk         (1UL << SCnSCB_ACTLR_FPEXCODIS_Pos)         /*!< ACTLR: FPEXCODIS Mask */
+
+#define SCnSCB_ACTLR_DISFOLD_Pos            2U                                         /*!< ACTLR: DISFOLD Position */
+#define SCnSCB_ACTLR_DISFOLD_Msk           (1UL << SCnSCB_ACTLR_DISFOLD_Pos)           /*!< ACTLR: DISFOLD Mask */
+
+#define SCnSCB_ACTLR_DISMCYCINT_Pos         0U                                         /*!< ACTLR: DISMCYCINT Position */
+#define SCnSCB_ACTLR_DISMCYCINT_Msk        (1UL /*<< SCnSCB_ACTLR_DISMCYCINT_Pos*/)    /*!< ACTLR: DISMCYCINT Mask */
+
+/*@} end of group CMSIS_SCnotSCB */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_SysTick     System Tick Timer (SysTick)
+  \brief    Type definitions for the System Timer Registers.
+  @{
+ */
+
+/**
+  \brief  Structure type to access the System Timer (SysTick).
+ */
+typedef struct
+{
+  __IOM uint32_t CTRL;                   /*!< Offset: 0x000 (R/W)  SysTick Control and Status Register */
+  __IOM uint32_t LOAD;                   /*!< Offset: 0x004 (R/W)  SysTick Reload Value Register */
+  __IOM uint32_t VAL;                    /*!< Offset: 0x008 (R/W)  SysTick Current Value Register */
+  __IM  uint32_t CALIB;                  /*!< Offset: 0x00C (R/ )  SysTick Calibration Register */
+} SysTick_Type;
+
+/* SysTick Control / Status Register Definitions */
+#define SysTick_CTRL_COUNTFLAG_Pos         16U                                            /*!< SysTick CTRL: COUNTFLAG Position */
+#define SysTick_CTRL_COUNTFLAG_Msk         (1UL << SysTick_CTRL_COUNTFLAG_Pos)            /*!< SysTick CTRL: COUNTFLAG Mask */
+
+#define SysTick_CTRL_CLKSOURCE_Pos          2U                                            /*!< SysTick CTRL: CLKSOURCE Position */
+#define SysTick_CTRL_CLKSOURCE_Msk         (1UL << SysTick_CTRL_CLKSOURCE_Pos)            /*!< SysTick CTRL: CLKSOURCE Mask */
+
+#define SysTick_CTRL_TICKINT_Pos            1U                                            /*!< SysTick CTRL: TICKINT Position */
+#define SysTick_CTRL_TICKINT_Msk           (1UL << SysTick_CTRL_TICKINT_Pos)              /*!< SysTick CTRL: TICKINT Mask */
+
+#define SysTick_CTRL_ENABLE_Pos             0U                                            /*!< SysTick CTRL: ENABLE Position */
+#define SysTick_CTRL_ENABLE_Msk            (1UL /*<< SysTick_CTRL_ENABLE_Pos*/)           /*!< SysTick CTRL: ENABLE Mask */
+
+/* SysTick Reload Register Definitions */
+#define SysTick_LOAD_RELOAD_Pos             0U                                            /*!< SysTick LOAD: RELOAD Position */
+#define SysTick_LOAD_RELOAD_Msk            (0xFFFFFFUL /*<< SysTick_LOAD_RELOAD_Pos*/)    /*!< SysTick LOAD: RELOAD Mask */
+
+/* SysTick Current Register Definitions */
+#define SysTick_VAL_CURRENT_Pos             0U                                            /*!< SysTick VAL: CURRENT Position */
+#define SysTick_VAL_CURRENT_Msk            (0xFFFFFFUL /*<< SysTick_VAL_CURRENT_Pos*/)    /*!< SysTick VAL: CURRENT Mask */
+
+/* SysTick Calibration Register Definitions */
+#define SysTick_CALIB_NOREF_Pos            31U                                            /*!< SysTick CALIB: NOREF Position */
+#define SysTick_CALIB_NOREF_Msk            (1UL << SysTick_CALIB_NOREF_Pos)               /*!< SysTick CALIB: NOREF Mask */
+
+#define SysTick_CALIB_SKEW_Pos             30U                                            /*!< SysTick CALIB: SKEW Position */
+#define SysTick_CALIB_SKEW_Msk             (1UL << SysTick_CALIB_SKEW_Pos)                /*!< SysTick CALIB: SKEW Mask */
+
+#define SysTick_CALIB_TENMS_Pos             0U                                            /*!< SysTick CALIB: TENMS Position */
+#define SysTick_CALIB_TENMS_Msk            (0xFFFFFFUL /*<< SysTick_CALIB_TENMS_Pos*/)    /*!< SysTick CALIB: TENMS Mask */
+
+/*@} end of group CMSIS_SysTick */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_ITM     Instrumentation Trace Macrocell (ITM)
+  \brief    Type definitions for the Instrumentation Trace Macrocell (ITM)
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Instrumentation Trace Macrocell Register (ITM).
+ */
+typedef struct
+{
+  __OM  union
+  {
+    __OM  uint8_t    u8;                 /*!< Offset: 0x000 ( /W)  ITM Stimulus Port 8-bit */
+    __OM  uint16_t   u16;                /*!< Offset: 0x000 ( /W)  ITM Stimulus Port 16-bit */
+    __OM  uint32_t   u32;                /*!< Offset: 0x000 ( /W)  ITM Stimulus Port 32-bit */
+  }  PORT [32U];                         /*!< Offset: 0x000 ( /W)  ITM Stimulus Port Registers */
+        uint32_t RESERVED0[864U];
+  __IOM uint32_t TER;                    /*!< Offset: 0xE00 (R/W)  ITM Trace Enable Register */
+        uint32_t RESERVED1[15U];
+  __IOM uint32_t TPR;                    /*!< Offset: 0xE40 (R/W)  ITM Trace Privilege Register */
+        uint32_t RESERVED2[15U];
+  __IOM uint32_t TCR;                    /*!< Offset: 0xE80 (R/W)  ITM Trace Control Register */
+        uint32_t RESERVED3[32U];
+        uint32_t RESERVED4[43U];
+  __OM  uint32_t LAR;                    /*!< Offset: 0xFB0 ( /W)  ITM Lock Access Register */
+  __IM  uint32_t LSR;                    /*!< Offset: 0xFB4 (R/ )  ITM Lock Status Register */
+        uint32_t RESERVED5[6U];
+  __IM  uint32_t PID4;                   /*!< Offset: 0xFD0 (R/ )  ITM Peripheral Identification Register #4 */
+  __IM  uint32_t PID5;                   /*!< Offset: 0xFD4 (R/ )  ITM Peripheral Identification Register #5 */
+  __IM  uint32_t PID6;                   /*!< Offset: 0xFD8 (R/ )  ITM Peripheral Identification Register #6 */
+  __IM  uint32_t PID7;                   /*!< Offset: 0xFDC (R/ )  ITM Peripheral Identification Register #7 */
+  __IM  uint32_t PID0;                   /*!< Offset: 0xFE0 (R/ )  ITM Peripheral Identification Register #0 */
+  __IM  uint32_t PID1;                   /*!< Offset: 0xFE4 (R/ )  ITM Peripheral Identification Register #1 */
+  __IM  uint32_t PID2;                   /*!< Offset: 0xFE8 (R/ )  ITM Peripheral Identification Register #2 */
+  __IM  uint32_t PID3;                   /*!< Offset: 0xFEC (R/ )  ITM Peripheral Identification Register #3 */
+  __IM  uint32_t CID0;                   /*!< Offset: 0xFF0 (R/ )  ITM Component  Identification Register #0 */
+  __IM  uint32_t CID1;                   /*!< Offset: 0xFF4 (R/ )  ITM Component  Identification Register #1 */
+  __IM  uint32_t CID2;                   /*!< Offset: 0xFF8 (R/ )  ITM Component  Identification Register #2 */
+  __IM  uint32_t CID3;                   /*!< Offset: 0xFFC (R/ )  ITM Component  Identification Register #3 */
+} ITM_Type;
+
+/* ITM Trace Privilege Register Definitions */
+#define ITM_TPR_PRIVMASK_Pos                0U                                            /*!< ITM TPR: PRIVMASK Position */
+#define ITM_TPR_PRIVMASK_Msk               (0xFFFFFFFFUL /*<< ITM_TPR_PRIVMASK_Pos*/)     /*!< ITM TPR: PRIVMASK Mask */
+
+/* ITM Trace Control Register Definitions */
+#define ITM_TCR_BUSY_Pos                   23U                                            /*!< ITM TCR: BUSY Position */
+#define ITM_TCR_BUSY_Msk                   (1UL << ITM_TCR_BUSY_Pos)                      /*!< ITM TCR: BUSY Mask */
+
+#define ITM_TCR_TraceBusID_Pos             16U                                            /*!< ITM TCR: ATBID Position */
+#define ITM_TCR_TraceBusID_Msk             (0x7FUL << ITM_TCR_TraceBusID_Pos)             /*!< ITM TCR: ATBID Mask */
+
+#define ITM_TCR_GTSFREQ_Pos                10U                                            /*!< ITM TCR: Global timestamp frequency Position */
+#define ITM_TCR_GTSFREQ_Msk                (3UL << ITM_TCR_GTSFREQ_Pos)                   /*!< ITM TCR: Global timestamp frequency Mask */
+
+#define ITM_TCR_TSPrescale_Pos              8U                                            /*!< ITM TCR: TSPrescale Position */
+#define ITM_TCR_TSPrescale_Msk             (3UL << ITM_TCR_TSPrescale_Pos)                /*!< ITM TCR: TSPrescale Mask */
+
+#define ITM_TCR_SWOENA_Pos                  4U                                            /*!< ITM TCR: SWOENA Position */
+#define ITM_TCR_SWOENA_Msk                 (1UL << ITM_TCR_SWOENA_Pos)                    /*!< ITM TCR: SWOENA Mask */
+
+#define ITM_TCR_DWTENA_Pos                  3U                                            /*!< ITM TCR: DWTENA Position */
+#define ITM_TCR_DWTENA_Msk                 (1UL << ITM_TCR_DWTENA_Pos)                    /*!< ITM TCR: DWTENA Mask */
+
+#define ITM_TCR_SYNCENA_Pos                 2U                                            /*!< ITM TCR: SYNCENA Position */
+#define ITM_TCR_SYNCENA_Msk                (1UL << ITM_TCR_SYNCENA_Pos)                   /*!< ITM TCR: SYNCENA Mask */
+
+#define ITM_TCR_TSENA_Pos                   1U                                            /*!< ITM TCR: TSENA Position */
+#define ITM_TCR_TSENA_Msk                  (1UL << ITM_TCR_TSENA_Pos)                     /*!< ITM TCR: TSENA Mask */
+
+#define ITM_TCR_ITMENA_Pos                  0U                                            /*!< ITM TCR: ITM Enable bit Position */
+#define ITM_TCR_ITMENA_Msk                 (1UL /*<< ITM_TCR_ITMENA_Pos*/)                /*!< ITM TCR: ITM Enable bit Mask */
+
+/* ITM Lock Status Register Definitions */
+#define ITM_LSR_ByteAcc_Pos                 2U                                            /*!< ITM LSR: ByteAcc Position */
+#define ITM_LSR_ByteAcc_Msk                (1UL << ITM_LSR_ByteAcc_Pos)                   /*!< ITM LSR: ByteAcc Mask */
+
+#define ITM_LSR_Access_Pos                  1U                                            /*!< ITM LSR: Access Position */
+#define ITM_LSR_Access_Msk                 (1UL << ITM_LSR_Access_Pos)                    /*!< ITM LSR: Access Mask */
+
+#define ITM_LSR_Present_Pos                 0U                                            /*!< ITM LSR: Present Position */
+#define ITM_LSR_Present_Msk                (1UL /*<< ITM_LSR_Present_Pos*/)               /*!< ITM LSR: Present Mask */
+
+/*@}*/ /* end of group CMSIS_ITM */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_DWT     Data Watchpoint and Trace (DWT)
+  \brief    Type definitions for the Data Watchpoint and Trace (DWT)
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Data Watchpoint and Trace Register (DWT).
+ */
+typedef struct
+{
+  __IOM uint32_t CTRL;                   /*!< Offset: 0x000 (R/W)  Control Register */
+  __IOM uint32_t CYCCNT;                 /*!< Offset: 0x004 (R/W)  Cycle Count Register */
+  __IOM uint32_t CPICNT;                 /*!< Offset: 0x008 (R/W)  CPI Count Register */
+  __IOM uint32_t EXCCNT;                 /*!< Offset: 0x00C (R/W)  Exception Overhead Count Register */
+  __IOM uint32_t SLEEPCNT;               /*!< Offset: 0x010 (R/W)  Sleep Count Register */
+  __IOM uint32_t LSUCNT;                 /*!< Offset: 0x014 (R/W)  LSU Count Register */
+  __IOM uint32_t FOLDCNT;                /*!< Offset: 0x018 (R/W)  Folded-instruction Count Register */
+  __IM  uint32_t PCSR;                   /*!< Offset: 0x01C (R/ )  Program Counter Sample Register */
+  __IOM uint32_t COMP0;                  /*!< Offset: 0x020 (R/W)  Comparator Register 0 */
+  __IOM uint32_t MASK0;                  /*!< Offset: 0x024 (R/W)  Mask Register 0 */
+  __IOM uint32_t FUNCTION0;              /*!< Offset: 0x028 (R/W)  Function Register 0 */
+        uint32_t RESERVED0[1U];
+  __IOM uint32_t COMP1;                  /*!< Offset: 0x030 (R/W)  Comparator Register 1 */
+  __IOM uint32_t MASK1;                  /*!< Offset: 0x034 (R/W)  Mask Register 1 */
+  __IOM uint32_t FUNCTION1;              /*!< Offset: 0x038 (R/W)  Function Register 1 */
+        uint32_t RESERVED1[1U];
+  __IOM uint32_t COMP2;                  /*!< Offset: 0x040 (R/W)  Comparator Register 2 */
+  __IOM uint32_t MASK2;                  /*!< Offset: 0x044 (R/W)  Mask Register 2 */
+  __IOM uint32_t FUNCTION2;              /*!< Offset: 0x048 (R/W)  Function Register 2 */
+        uint32_t RESERVED2[1U];
+  __IOM uint32_t COMP3;                  /*!< Offset: 0x050 (R/W)  Comparator Register 3 */
+  __IOM uint32_t MASK3;                  /*!< Offset: 0x054 (R/W)  Mask Register 3 */
+  __IOM uint32_t FUNCTION3;              /*!< Offset: 0x058 (R/W)  Function Register 3 */
+        uint32_t RESERVED3[981U];
+  __OM  uint32_t LAR;                    /*!< Offset: 0xFB0 (  W)  Lock Access Register */
+  __IM  uint32_t LSR;                    /*!< Offset: 0xFB4 (R  )  Lock Status Register */
+} DWT_Type;
+
+/* DWT Control Register Definitions */
+#define DWT_CTRL_NUMCOMP_Pos               28U                                         /*!< DWT CTRL: NUMCOMP Position */
+#define DWT_CTRL_NUMCOMP_Msk               (0xFUL << DWT_CTRL_NUMCOMP_Pos)             /*!< DWT CTRL: NUMCOMP Mask */
+
+#define DWT_CTRL_NOTRCPKT_Pos              27U                                         /*!< DWT CTRL: NOTRCPKT Position */
+#define DWT_CTRL_NOTRCPKT_Msk              (0x1UL << DWT_CTRL_NOTRCPKT_Pos)            /*!< DWT CTRL: NOTRCPKT Mask */
+
+#define DWT_CTRL_NOEXTTRIG_Pos             26U                                         /*!< DWT CTRL: NOEXTTRIG Position */
+#define DWT_CTRL_NOEXTTRIG_Msk             (0x1UL << DWT_CTRL_NOEXTTRIG_Pos)           /*!< DWT CTRL: NOEXTTRIG Mask */
+
+#define DWT_CTRL_NOCYCCNT_Pos              25U                                         /*!< DWT CTRL: NOCYCCNT Position */
+#define DWT_CTRL_NOCYCCNT_Msk              (0x1UL << DWT_CTRL_NOCYCCNT_Pos)            /*!< DWT CTRL: NOCYCCNT Mask */
+
+#define DWT_CTRL_NOPRFCNT_Pos              24U                                         /*!< DWT CTRL: NOPRFCNT Position */
+#define DWT_CTRL_NOPRFCNT_Msk              (0x1UL << DWT_CTRL_NOPRFCNT_Pos)            /*!< DWT CTRL: NOPRFCNT Mask */
+
+#define DWT_CTRL_CYCEVTENA_Pos             22U                                         /*!< DWT CTRL: CYCEVTENA Position */
+#define DWT_CTRL_CYCEVTENA_Msk             (0x1UL << DWT_CTRL_CYCEVTENA_Pos)           /*!< DWT CTRL: CYCEVTENA Mask */
+
+#define DWT_CTRL_FOLDEVTENA_Pos            21U                                         /*!< DWT CTRL: FOLDEVTENA Position */
+#define DWT_CTRL_FOLDEVTENA_Msk            (0x1UL << DWT_CTRL_FOLDEVTENA_Pos)          /*!< DWT CTRL: FOLDEVTENA Mask */
+
+#define DWT_CTRL_LSUEVTENA_Pos             20U                                         /*!< DWT CTRL: LSUEVTENA Position */
+#define DWT_CTRL_LSUEVTENA_Msk             (0x1UL << DWT_CTRL_LSUEVTENA_Pos)           /*!< DWT CTRL: LSUEVTENA Mask */
+
+#define DWT_CTRL_SLEEPEVTENA_Pos           19U                                         /*!< DWT CTRL: SLEEPEVTENA Position */
+#define DWT_CTRL_SLEEPEVTENA_Msk           (0x1UL << DWT_CTRL_SLEEPEVTENA_Pos)         /*!< DWT CTRL: SLEEPEVTENA Mask */
+
+#define DWT_CTRL_EXCEVTENA_Pos             18U                                         /*!< DWT CTRL: EXCEVTENA Position */
+#define DWT_CTRL_EXCEVTENA_Msk             (0x1UL << DWT_CTRL_EXCEVTENA_Pos)           /*!< DWT CTRL: EXCEVTENA Mask */
+
+#define DWT_CTRL_CPIEVTENA_Pos             17U                                         /*!< DWT CTRL: CPIEVTENA Position */
+#define DWT_CTRL_CPIEVTENA_Msk             (0x1UL << DWT_CTRL_CPIEVTENA_Pos)           /*!< DWT CTRL: CPIEVTENA Mask */
+
+#define DWT_CTRL_EXCTRCENA_Pos             16U                                         /*!< DWT CTRL: EXCTRCENA Position */
+#define DWT_CTRL_EXCTRCENA_Msk             (0x1UL << DWT_CTRL_EXCTRCENA_Pos)           /*!< DWT CTRL: EXCTRCENA Mask */
+
+#define DWT_CTRL_PCSAMPLENA_Pos            12U                                         /*!< DWT CTRL: PCSAMPLENA Position */
+#define DWT_CTRL_PCSAMPLENA_Msk            (0x1UL << DWT_CTRL_PCSAMPLENA_Pos)          /*!< DWT CTRL: PCSAMPLENA Mask */
+
+#define DWT_CTRL_SYNCTAP_Pos               10U                                         /*!< DWT CTRL: SYNCTAP Position */
+#define DWT_CTRL_SYNCTAP_Msk               (0x3UL << DWT_CTRL_SYNCTAP_Pos)             /*!< DWT CTRL: SYNCTAP Mask */
+
+#define DWT_CTRL_CYCTAP_Pos                 9U                                         /*!< DWT CTRL: CYCTAP Position */
+#define DWT_CTRL_CYCTAP_Msk                (0x1UL << DWT_CTRL_CYCTAP_Pos)              /*!< DWT CTRL: CYCTAP Mask */
+
+#define DWT_CTRL_POSTINIT_Pos               5U                                         /*!< DWT CTRL: POSTINIT Position */
+#define DWT_CTRL_POSTINIT_Msk              (0xFUL << DWT_CTRL_POSTINIT_Pos)            /*!< DWT CTRL: POSTINIT Mask */
+
+#define DWT_CTRL_POSTPRESET_Pos             1U                                         /*!< DWT CTRL: POSTPRESET Position */
+#define DWT_CTRL_POSTPRESET_Msk            (0xFUL << DWT_CTRL_POSTPRESET_Pos)          /*!< DWT CTRL: POSTPRESET Mask */
+
+#define DWT_CTRL_CYCCNTENA_Pos              0U                                         /*!< DWT CTRL: CYCCNTENA Position */
+#define DWT_CTRL_CYCCNTENA_Msk             (0x1UL /*<< DWT_CTRL_CYCCNTENA_Pos*/)       /*!< DWT CTRL: CYCCNTENA Mask */
+
+/* DWT CPI Count Register Definitions */
+#define DWT_CPICNT_CPICNT_Pos               0U                                         /*!< DWT CPICNT: CPICNT Position */
+#define DWT_CPICNT_CPICNT_Msk              (0xFFUL /*<< DWT_CPICNT_CPICNT_Pos*/)       /*!< DWT CPICNT: CPICNT Mask */
+
+/* DWT Exception Overhead Count Register Definitions */
+#define DWT_EXCCNT_EXCCNT_Pos               0U                                         /*!< DWT EXCCNT: EXCCNT Position */
+#define DWT_EXCCNT_EXCCNT_Msk              (0xFFUL /*<< DWT_EXCCNT_EXCCNT_Pos*/)       /*!< DWT EXCCNT: EXCCNT Mask */
+
+/* DWT Sleep Count Register Definitions */
+#define DWT_SLEEPCNT_SLEEPCNT_Pos           0U                                         /*!< DWT SLEEPCNT: SLEEPCNT Position */
+#define DWT_SLEEPCNT_SLEEPCNT_Msk          (0xFFUL /*<< DWT_SLEEPCNT_SLEEPCNT_Pos*/)   /*!< DWT SLEEPCNT: SLEEPCNT Mask */
+
+/* DWT LSU Count Register Definitions */
+#define DWT_LSUCNT_LSUCNT_Pos               0U                                         /*!< DWT LSUCNT: LSUCNT Position */
+#define DWT_LSUCNT_LSUCNT_Msk              (0xFFUL /*<< DWT_LSUCNT_LSUCNT_Pos*/)       /*!< DWT LSUCNT: LSUCNT Mask */
+
+/* DWT Folded-instruction Count Register Definitions */
+#define DWT_FOLDCNT_FOLDCNT_Pos             0U                                         /*!< DWT FOLDCNT: FOLDCNT Position */
+#define DWT_FOLDCNT_FOLDCNT_Msk            (0xFFUL /*<< DWT_FOLDCNT_FOLDCNT_Pos*/)     /*!< DWT FOLDCNT: FOLDCNT Mask */
+
+/* DWT Comparator Mask Register Definitions */
+#define DWT_MASK_MASK_Pos                   0U                                         /*!< DWT MASK: MASK Position */
+#define DWT_MASK_MASK_Msk                  (0x1FUL /*<< DWT_MASK_MASK_Pos*/)           /*!< DWT MASK: MASK Mask */
+
+/* DWT Comparator Function Register Definitions */
+#define DWT_FUNCTION_MATCHED_Pos           24U                                         /*!< DWT FUNCTION: MATCHED Position */
+#define DWT_FUNCTION_MATCHED_Msk           (0x1UL << DWT_FUNCTION_MATCHED_Pos)         /*!< DWT FUNCTION: MATCHED Mask */
+
+#define DWT_FUNCTION_DATAVADDR1_Pos        16U                                         /*!< DWT FUNCTION: DATAVADDR1 Position */
+#define DWT_FUNCTION_DATAVADDR1_Msk        (0xFUL << DWT_FUNCTION_DATAVADDR1_Pos)      /*!< DWT FUNCTION: DATAVADDR1 Mask */
+
+#define DWT_FUNCTION_DATAVADDR0_Pos        12U                                         /*!< DWT FUNCTION: DATAVADDR0 Position */
+#define DWT_FUNCTION_DATAVADDR0_Msk        (0xFUL << DWT_FUNCTION_DATAVADDR0_Pos)      /*!< DWT FUNCTION: DATAVADDR0 Mask */
+
+#define DWT_FUNCTION_DATAVSIZE_Pos         10U                                         /*!< DWT FUNCTION: DATAVSIZE Position */
+#define DWT_FUNCTION_DATAVSIZE_Msk         (0x3UL << DWT_FUNCTION_DATAVSIZE_Pos)       /*!< DWT FUNCTION: DATAVSIZE Mask */
+
+#define DWT_FUNCTION_LNK1ENA_Pos            9U                                         /*!< DWT FUNCTION: LNK1ENA Position */
+#define DWT_FUNCTION_LNK1ENA_Msk           (0x1UL << DWT_FUNCTION_LNK1ENA_Pos)         /*!< DWT FUNCTION: LNK1ENA Mask */
+
+#define DWT_FUNCTION_DATAVMATCH_Pos         8U                                         /*!< DWT FUNCTION: DATAVMATCH Position */
+#define DWT_FUNCTION_DATAVMATCH_Msk        (0x1UL << DWT_FUNCTION_DATAVMATCH_Pos)      /*!< DWT FUNCTION: DATAVMATCH Mask */
+
+#define DWT_FUNCTION_CYCMATCH_Pos           7U                                         /*!< DWT FUNCTION: CYCMATCH Position */
+#define DWT_FUNCTION_CYCMATCH_Msk          (0x1UL << DWT_FUNCTION_CYCMATCH_Pos)        /*!< DWT FUNCTION: CYCMATCH Mask */
+
+#define DWT_FUNCTION_EMITRANGE_Pos          5U                                         /*!< DWT FUNCTION: EMITRANGE Position */
+#define DWT_FUNCTION_EMITRANGE_Msk         (0x1UL << DWT_FUNCTION_EMITRANGE_Pos)       /*!< DWT FUNCTION: EMITRANGE Mask */
+
+#define DWT_FUNCTION_FUNCTION_Pos           0U                                         /*!< DWT FUNCTION: FUNCTION Position */
+#define DWT_FUNCTION_FUNCTION_Msk          (0xFUL /*<< DWT_FUNCTION_FUNCTION_Pos*/)    /*!< DWT FUNCTION: FUNCTION Mask */
+
+/*@}*/ /* end of group CMSIS_DWT */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_TPI     Trace Port Interface (TPI)
+  \brief    Type definitions for the Trace Port Interface (TPI)
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Trace Port Interface Register (TPI).
+ */
+typedef struct
+{
+  __IM  uint32_t SSPSR;                  /*!< Offset: 0x000 (R/ )  Supported Parallel Port Size Register */
+  __IOM uint32_t CSPSR;                  /*!< Offset: 0x004 (R/W)  Current Parallel Port Size Register */
+        uint32_t RESERVED0[2U];
+  __IOM uint32_t ACPR;                   /*!< Offset: 0x010 (R/W)  Asynchronous Clock Prescaler Register */
+        uint32_t RESERVED1[55U];
+  __IOM uint32_t SPPR;                   /*!< Offset: 0x0F0 (R/W)  Selected Pin Protocol Register */
+        uint32_t RESERVED2[131U];
+  __IM  uint32_t FFSR;                   /*!< Offset: 0x300 (R/ )  Formatter and Flush Status Register */
+  __IOM uint32_t FFCR;                   /*!< Offset: 0x304 (R/W)  Formatter and Flush Control Register */
+  __IM  uint32_t FSCR;                   /*!< Offset: 0x308 (R/ )  Formatter Synchronization Counter Register */
+        uint32_t RESERVED3[759U];
+  __IM  uint32_t TRIGGER;                /*!< Offset: 0xEE8 (R/ )  TRIGGER Register */
+  __IM  uint32_t FIFO0;                  /*!< Offset: 0xEEC (R/ )  Integration ETM Data */
+  __IM  uint32_t ITATBCTR2;              /*!< Offset: 0xEF0 (R/ )  ITATBCTR2 */
+        uint32_t RESERVED4[1U];
+  __IM  uint32_t ITATBCTR0;              /*!< Offset: 0xEF8 (R/ )  ITATBCTR0 */
+  __IM  uint32_t FIFO1;                  /*!< Offset: 0xEFC (R/ )  Integration ITM Data */
+  __IOM uint32_t ITCTRL;                 /*!< Offset: 0xF00 (R/W)  Integration Mode Control */
+        uint32_t RESERVED5[39U];
+  __IOM uint32_t CLAIMSET;               /*!< Offset: 0xFA0 (R/W)  Claim tag set */
+  __IOM uint32_t CLAIMCLR;               /*!< Offset: 0xFA4 (R/W)  Claim tag clear */
+        uint32_t RESERVED7[8U];
+  __IM  uint32_t DEVID;                  /*!< Offset: 0xFC8 (R/ )  TPIU_DEVID */
+  __IM  uint32_t DEVTYPE;                /*!< Offset: 0xFCC (R/ )  TPIU_DEVTYPE */
+} TPI_Type;
+
+/* TPI Asynchronous Clock Prescaler Register Definitions */
+#define TPI_ACPR_PRESCALER_Pos              0U                                         /*!< TPI ACPR: PRESCALER Position */
+#define TPI_ACPR_PRESCALER_Msk             (0x1FFFUL /*<< TPI_ACPR_PRESCALER_Pos*/)    /*!< TPI ACPR: PRESCALER Mask */
+
+/* TPI Selected Pin Protocol Register Definitions */
+#define TPI_SPPR_TXMODE_Pos                 0U                                         /*!< TPI SPPR: TXMODE Position */
+#define TPI_SPPR_TXMODE_Msk                (0x3UL /*<< TPI_SPPR_TXMODE_Pos*/)          /*!< TPI SPPR: TXMODE Mask */
+
+/* TPI Formatter and Flush Status Register Definitions */
+#define TPI_FFSR_FtNonStop_Pos              3U                                         /*!< TPI FFSR: FtNonStop Position */
+#define TPI_FFSR_FtNonStop_Msk             (0x1UL << TPI_FFSR_FtNonStop_Pos)           /*!< TPI FFSR: FtNonStop Mask */
+
+#define TPI_FFSR_TCPresent_Pos              2U                                         /*!< TPI FFSR: TCPresent Position */
+#define TPI_FFSR_TCPresent_Msk             (0x1UL << TPI_FFSR_TCPresent_Pos)           /*!< TPI FFSR: TCPresent Mask */
+
+#define TPI_FFSR_FtStopped_Pos              1U                                         /*!< TPI FFSR: FtStopped Position */
+#define TPI_FFSR_FtStopped_Msk             (0x1UL << TPI_FFSR_FtStopped_Pos)           /*!< TPI FFSR: FtStopped Mask */
+
+#define TPI_FFSR_FlInProg_Pos               0U                                         /*!< TPI FFSR: FlInProg Position */
+#define TPI_FFSR_FlInProg_Msk              (0x1UL /*<< TPI_FFSR_FlInProg_Pos*/)        /*!< TPI FFSR: FlInProg Mask */
+
+/* TPI Formatter and Flush Control Register Definitions */
+#define TPI_FFCR_TrigIn_Pos                 8U                                         /*!< TPI FFCR: TrigIn Position */
+#define TPI_FFCR_TrigIn_Msk                (0x1UL << TPI_FFCR_TrigIn_Pos)              /*!< TPI FFCR: TrigIn Mask */
+
+#define TPI_FFCR_EnFCont_Pos                1U                                         /*!< TPI FFCR: EnFCont Position */
+#define TPI_FFCR_EnFCont_Msk               (0x1UL << TPI_FFCR_EnFCont_Pos)             /*!< TPI FFCR: EnFCont Mask */
+
+/* TPI TRIGGER Register Definitions */
+#define TPI_TRIGGER_TRIGGER_Pos             0U                                         /*!< TPI TRIGGER: TRIGGER Position */
+#define TPI_TRIGGER_TRIGGER_Msk            (0x1UL /*<< TPI_TRIGGER_TRIGGER_Pos*/)      /*!< TPI TRIGGER: TRIGGER Mask */
+
+/* TPI Integration ETM Data Register Definitions (FIFO0) */
+#define TPI_FIFO0_ITM_ATVALID_Pos          29U                                         /*!< TPI FIFO0: ITM_ATVALID Position */
+#define TPI_FIFO0_ITM_ATVALID_Msk          (0x3UL << TPI_FIFO0_ITM_ATVALID_Pos)        /*!< TPI FIFO0: ITM_ATVALID Mask */
+
+#define TPI_FIFO0_ITM_bytecount_Pos        27U                                         /*!< TPI FIFO0: ITM_bytecount Position */
+#define TPI_FIFO0_ITM_bytecount_Msk        (0x3UL << TPI_FIFO0_ITM_bytecount_Pos)      /*!< TPI FIFO0: ITM_bytecount Mask */
+
+#define TPI_FIFO0_ETM_ATVALID_Pos          26U                                         /*!< TPI FIFO0: ETM_ATVALID Position */
+#define TPI_FIFO0_ETM_ATVALID_Msk          (0x3UL << TPI_FIFO0_ETM_ATVALID_Pos)        /*!< TPI FIFO0: ETM_ATVALID Mask */
+
+#define TPI_FIFO0_ETM_bytecount_Pos        24U                                         /*!< TPI FIFO0: ETM_bytecount Position */
+#define TPI_FIFO0_ETM_bytecount_Msk        (0x3UL << TPI_FIFO0_ETM_bytecount_Pos)      /*!< TPI FIFO0: ETM_bytecount Mask */
+
+#define TPI_FIFO0_ETM2_Pos                 16U                                         /*!< TPI FIFO0: ETM2 Position */
+#define TPI_FIFO0_ETM2_Msk                 (0xFFUL << TPI_FIFO0_ETM2_Pos)              /*!< TPI FIFO0: ETM2 Mask */
+
+#define TPI_FIFO0_ETM1_Pos                  8U                                         /*!< TPI FIFO0: ETM1 Position */
+#define TPI_FIFO0_ETM1_Msk                 (0xFFUL << TPI_FIFO0_ETM1_Pos)              /*!< TPI FIFO0: ETM1 Mask */
+
+#define TPI_FIFO0_ETM0_Pos                  0U                                         /*!< TPI FIFO0: ETM0 Position */
+#define TPI_FIFO0_ETM0_Msk                 (0xFFUL /*<< TPI_FIFO0_ETM0_Pos*/)          /*!< TPI FIFO0: ETM0 Mask */
+
+/* TPI ITATBCTR2 Register Definitions */
+#define TPI_ITATBCTR2_ATREADY2_Pos          0U                                         /*!< TPI ITATBCTR2: ATREADY2 Position */
+#define TPI_ITATBCTR2_ATREADY2_Msk         (0x1UL /*<< TPI_ITATBCTR2_ATREADY2_Pos*/)   /*!< TPI ITATBCTR2: ATREADY2 Mask */
+
+#define TPI_ITATBCTR2_ATREADY1_Pos          0U                                         /*!< TPI ITATBCTR2: ATREADY1 Position */
+#define TPI_ITATBCTR2_ATREADY1_Msk         (0x1UL /*<< TPI_ITATBCTR2_ATREADY1_Pos*/)   /*!< TPI ITATBCTR2: ATREADY1 Mask */
+
+/* TPI Integration ITM Data Register Definitions (FIFO1) */
+#define TPI_FIFO1_ITM_ATVALID_Pos          29U                                         /*!< TPI FIFO1: ITM_ATVALID Position */
+#define TPI_FIFO1_ITM_ATVALID_Msk          (0x3UL << TPI_FIFO1_ITM_ATVALID_Pos)        /*!< TPI FIFO1: ITM_ATVALID Mask */
+
+#define TPI_FIFO1_ITM_bytecount_Pos        27U                                         /*!< TPI FIFO1: ITM_bytecount Position */
+#define TPI_FIFO1_ITM_bytecount_Msk        (0x3UL << TPI_FIFO1_ITM_bytecount_Pos)      /*!< TPI FIFO1: ITM_bytecount Mask */
+
+#define TPI_FIFO1_ETM_ATVALID_Pos          26U                                         /*!< TPI FIFO1: ETM_ATVALID Position */
+#define TPI_FIFO1_ETM_ATVALID_Msk          (0x3UL << TPI_FIFO1_ETM_ATVALID_Pos)        /*!< TPI FIFO1: ETM_ATVALID Mask */
+
+#define TPI_FIFO1_ETM_bytecount_Pos        24U                                         /*!< TPI FIFO1: ETM_bytecount Position */
+#define TPI_FIFO1_ETM_bytecount_Msk        (0x3UL << TPI_FIFO1_ETM_bytecount_Pos)      /*!< TPI FIFO1: ETM_bytecount Mask */
+
+#define TPI_FIFO1_ITM2_Pos                 16U                                         /*!< TPI FIFO1: ITM2 Position */
+#define TPI_FIFO1_ITM2_Msk                 (0xFFUL << TPI_FIFO1_ITM2_Pos)              /*!< TPI FIFO1: ITM2 Mask */
+
+#define TPI_FIFO1_ITM1_Pos                  8U                                         /*!< TPI FIFO1: ITM1 Position */
+#define TPI_FIFO1_ITM1_Msk                 (0xFFUL << TPI_FIFO1_ITM1_Pos)              /*!< TPI FIFO1: ITM1 Mask */
+
+#define TPI_FIFO1_ITM0_Pos                  0U                                         /*!< TPI FIFO1: ITM0 Position */
+#define TPI_FIFO1_ITM0_Msk                 (0xFFUL /*<< TPI_FIFO1_ITM0_Pos*/)          /*!< TPI FIFO1: ITM0 Mask */
+
+/* TPI ITATBCTR0 Register Definitions */
+#define TPI_ITATBCTR0_ATREADY2_Pos          0U                                         /*!< TPI ITATBCTR0: ATREADY2 Position */
+#define TPI_ITATBCTR0_ATREADY2_Msk         (0x1UL /*<< TPI_ITATBCTR0_ATREADY2_Pos*/)   /*!< TPI ITATBCTR0: ATREADY2 Mask */
+
+#define TPI_ITATBCTR0_ATREADY1_Pos          0U                                         /*!< TPI ITATBCTR0: ATREADY1 Position */
+#define TPI_ITATBCTR0_ATREADY1_Msk         (0x1UL /*<< TPI_ITATBCTR0_ATREADY1_Pos*/)   /*!< TPI ITATBCTR0: ATREADY1 Mask */
+
+/* TPI Integration Mode Control Register Definitions */
+#define TPI_ITCTRL_Mode_Pos                 0U                                         /*!< TPI ITCTRL: Mode Position */
+#define TPI_ITCTRL_Mode_Msk                (0x3UL /*<< TPI_ITCTRL_Mode_Pos*/)          /*!< TPI ITCTRL: Mode Mask */
+
+/* TPI DEVID Register Definitions */
+#define TPI_DEVID_NRZVALID_Pos             11U                                         /*!< TPI DEVID: NRZVALID Position */
+#define TPI_DEVID_NRZVALID_Msk             (0x1UL << TPI_DEVID_NRZVALID_Pos)           /*!< TPI DEVID: NRZVALID Mask */
+
+#define TPI_DEVID_MANCVALID_Pos            10U                                         /*!< TPI DEVID: MANCVALID Position */
+#define TPI_DEVID_MANCVALID_Msk            (0x1UL << TPI_DEVID_MANCVALID_Pos)          /*!< TPI DEVID: MANCVALID Mask */
+
+#define TPI_DEVID_PTINVALID_Pos             9U                                         /*!< TPI DEVID: PTINVALID Position */
+#define TPI_DEVID_PTINVALID_Msk            (0x1UL << TPI_DEVID_PTINVALID_Pos)          /*!< TPI DEVID: PTINVALID Mask */
+
+#define TPI_DEVID_MinBufSz_Pos              6U                                         /*!< TPI DEVID: MinBufSz Position */
+#define TPI_DEVID_MinBufSz_Msk             (0x7UL << TPI_DEVID_MinBufSz_Pos)           /*!< TPI DEVID: MinBufSz Mask */
+
+#define TPI_DEVID_AsynClkIn_Pos             5U                                         /*!< TPI DEVID: AsynClkIn Position */
+#define TPI_DEVID_AsynClkIn_Msk            (0x1UL << TPI_DEVID_AsynClkIn_Pos)          /*!< TPI DEVID: AsynClkIn Mask */
+
+#define TPI_DEVID_NrTraceInput_Pos          0U                                         /*!< TPI DEVID: NrTraceInput Position */
+#define TPI_DEVID_NrTraceInput_Msk         (0x1FUL /*<< TPI_DEVID_NrTraceInput_Pos*/)  /*!< TPI DEVID: NrTraceInput Mask */
+
+/* TPI DEVTYPE Register Definitions */
+#define TPI_DEVTYPE_SubType_Pos             4U                                         /*!< TPI DEVTYPE: SubType Position */
+#define TPI_DEVTYPE_SubType_Msk            (0xFUL /*<< TPI_DEVTYPE_SubType_Pos*/)      /*!< TPI DEVTYPE: SubType Mask */
+
+#define TPI_DEVTYPE_MajorType_Pos           0U                                         /*!< TPI DEVTYPE: MajorType Position */
+#define TPI_DEVTYPE_MajorType_Msk          (0xFUL << TPI_DEVTYPE_MajorType_Pos)        /*!< TPI DEVTYPE: MajorType Mask */
+
+/*@}*/ /* end of group CMSIS_TPI */
+
+
+#if defined (__MPU_PRESENT) && (__MPU_PRESENT == 1U)
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_MPU     Memory Protection Unit (MPU)
+  \brief    Type definitions for the Memory Protection Unit (MPU)
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Memory Protection Unit (MPU).
+ */
+typedef struct
+{
+  __IM  uint32_t TYPE;                   /*!< Offset: 0x000 (R/ )  MPU Type Register */
+  __IOM uint32_t CTRL;                   /*!< Offset: 0x004 (R/W)  MPU Control Register */
+  __IOM uint32_t RNR;                    /*!< Offset: 0x008 (R/W)  MPU Region RNRber Register */
+  __IOM uint32_t RBAR;                   /*!< Offset: 0x00C (R/W)  MPU Region Base Address Register */
+  __IOM uint32_t RASR;                   /*!< Offset: 0x010 (R/W)  MPU Region Attribute and Size Register */
+  __IOM uint32_t RBAR_A1;                /*!< Offset: 0x014 (R/W)  MPU Alias 1 Region Base Address Register */
+  __IOM uint32_t RASR_A1;                /*!< Offset: 0x018 (R/W)  MPU Alias 1 Region Attribute and Size Register */
+  __IOM uint32_t RBAR_A2;                /*!< Offset: 0x01C (R/W)  MPU Alias 2 Region Base Address Register */
+  __IOM uint32_t RASR_A2;                /*!< Offset: 0x020 (R/W)  MPU Alias 2 Region Attribute and Size Register */
+  __IOM uint32_t RBAR_A3;                /*!< Offset: 0x024 (R/W)  MPU Alias 3 Region Base Address Register */
+  __IOM uint32_t RASR_A3;                /*!< Offset: 0x028 (R/W)  MPU Alias 3 Region Attribute and Size Register */
+} MPU_Type;
+
+#define MPU_TYPE_RALIASES                  4U
+
+/* MPU Type Register Definitions */
+#define MPU_TYPE_IREGION_Pos               16U                                            /*!< MPU TYPE: IREGION Position */
+#define MPU_TYPE_IREGION_Msk               (0xFFUL << MPU_TYPE_IREGION_Pos)               /*!< MPU TYPE: IREGION Mask */
+
+#define MPU_TYPE_DREGION_Pos                8U                                            /*!< MPU TYPE: DREGION Position */
+#define MPU_TYPE_DREGION_Msk               (0xFFUL << MPU_TYPE_DREGION_Pos)               /*!< MPU TYPE: DREGION Mask */
+
+#define MPU_TYPE_SEPARATE_Pos               0U                                            /*!< MPU TYPE: SEPARATE Position */
+#define MPU_TYPE_SEPARATE_Msk              (1UL /*<< MPU_TYPE_SEPARATE_Pos*/)             /*!< MPU TYPE: SEPARATE Mask */
+
+/* MPU Control Register Definitions */
+#define MPU_CTRL_PRIVDEFENA_Pos             2U                                            /*!< MPU CTRL: PRIVDEFENA Position */
+#define MPU_CTRL_PRIVDEFENA_Msk            (1UL << MPU_CTRL_PRIVDEFENA_Pos)               /*!< MPU CTRL: PRIVDEFENA Mask */
+
+#define MPU_CTRL_HFNMIENA_Pos               1U                                            /*!< MPU CTRL: HFNMIENA Position */
+#define MPU_CTRL_HFNMIENA_Msk              (1UL << MPU_CTRL_HFNMIENA_Pos)                 /*!< MPU CTRL: HFNMIENA Mask */
+
+#define MPU_CTRL_ENABLE_Pos                 0U                                            /*!< MPU CTRL: ENABLE Position */
+#define MPU_CTRL_ENABLE_Msk                (1UL /*<< MPU_CTRL_ENABLE_Pos*/)               /*!< MPU CTRL: ENABLE Mask */
+
+/* MPU Region Number Register Definitions */
+#define MPU_RNR_REGION_Pos                  0U                                            /*!< MPU RNR: REGION Position */
+#define MPU_RNR_REGION_Msk                 (0xFFUL /*<< MPU_RNR_REGION_Pos*/)             /*!< MPU RNR: REGION Mask */
+
+/* MPU Region Base Address Register Definitions */
+#define MPU_RBAR_ADDR_Pos                   0U                                            /*!< MPU RBAR: ADDR Position */
+#define MPU_RBAR_ADDR_Msk                  (0xFFFFFFFUL << MPU_RBAR_ADDR_Pos)             /*!< MPU RBAR: ADDR Mask */
+
+#define MPU_RBAR_VALID_Pos                  4U                                            /*!< MPU RBAR: VALID Position */
+#define MPU_RBAR_VALID_Msk                 (1UL << MPU_RBAR_VALID_Pos)                    /*!< MPU RBAR: VALID Mask */
+
+#define MPU_RBAR_REGION_Pos                 0U                                            /*!< MPU RBAR: REGION Position */
+#define MPU_RBAR_REGION_Msk                (0xFUL /*<< MPU_RBAR_REGION_Pos*/)             /*!< MPU RBAR: REGION Mask */
+
+/* MPU Region Attribute and Size Register Definitions */
+#define MPU_RASR_ATTRS_Pos                 0U                                            /*!< MPU RASR: MPU Region Attribute field Position */
+#define MPU_RASR_ATTRS_Msk                 (0xFFFFUL << MPU_RASR_ATTRS_Pos)               /*!< MPU RASR: MPU Region Attribute field Mask */
+
+#define MPU_RASR_XN_Pos                    12U                                            /*!< MPU RASR: ATTRS.XN Position */
+#define MPU_RASR_XN_Msk                    (1UL << MPU_RASR_XN_Pos)                       /*!< MPU RASR: ATTRS.XN Mask */
+
+#define MPU_RASR_AP_Pos                    8U                                            /*!< MPU RASR: ATTRS.AP Position */
+#define MPU_RASR_AP_Msk                    (0x7UL << MPU_RASR_AP_Pos)                     /*!< MPU RASR: ATTRS.AP Mask */
+
+#define MPU_RASR_TEX_Pos                   3U                                            /*!< MPU RASR: ATTRS.TEX Position */
+#define MPU_RASR_TEX_Msk                   (0x3UL << MPU_RASR_TEX_Pos)                    /*!< MPU RASR: ATTRS.TEX Mask */
+
+#define MPU_RASR_S_Pos                     2U                                            /*!< MPU RASR: ATTRS.S Position */
+#define MPU_RASR_S_Msk                     (1UL << MPU_RASR_S_Pos)                        /*!< MPU RASR: ATTRS.S Mask */
+
+#define MPU_RASR_C_Pos                     1U                                            /*!< MPU RASR: ATTRS.C Position */
+#define MPU_RASR_C_Msk                     (1UL << MPU_RASR_C_Pos)                        /*!< MPU RASR: ATTRS.C Mask */
+
+#define MPU_RASR_B_Pos                     0U                                            /*!< MPU RASR: ATTRS.B Position */
+#define MPU_RASR_B_Msk                     (1UL << MPU_RASR_B_Pos)                        /*!< MPU RASR: ATTRS.B Mask */
+
+#define MPU_RASR_SRD_Pos                    8U                                            /*!< MPU RASR: Sub-Region Disable Position */
+#define MPU_RASR_SRD_Msk                   (0xFFUL << MPU_RASR_SRD_Pos)                   /*!< MPU RASR: Sub-Region Disable Mask */
+
+#define MPU_RASR_SIZE_Pos                   1U                                            /*!< MPU RASR: Region Size Field Position */
+#define MPU_RASR_SIZE_Msk                  (0x1FUL << MPU_RASR_SIZE_Pos)                  /*!< MPU RASR: Region Size Field Mask */
+
+#define MPU_RASR_ENABLE_Pos                 0U                                            /*!< MPU RASR: Region enable bit Position */
+#define MPU_RASR_ENABLE_Msk                (0x1UL << MPU_RASR_ENABLE_Pos)                 /*!< MPU RASR: Region enable bit Disable Mask */
+
+/*@} end of group CMSIS_MPU */
+#endif /* defined (__MPU_PRESENT) && (__MPU_PRESENT == 1U) */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_FPU     Floating Point Unit (FPU)
+  \brief    Type definitions for the Floating Point Unit (FPU)
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Floating Point Unit (FPU).
+ */
+typedef struct
+{
+        uint32_t RESERVED0[1U];
+  __IOM uint32_t FPCCR;                  /*!< Offset: 0x004 (R/W)  Floating-Point Context Control Register */
+  __IOM uint32_t FPCAR;                  /*!< Offset: 0x008 (R/W)  Floating-Point Context Address Register */
+  __IOM uint32_t FPDSCR;                 /*!< Offset: 0x00C (R/W)  Floating-Point Default Status Control Register */
+  __IM  uint32_t MVFR0;                  /*!< Offset: 0x010 (R/ )  Media and FP Feature Register 0 */
+  __IM  uint32_t MVFR1;                  /*!< Offset: 0x014 (R/ )  Media and FP Feature Register 1 */
+  __IM  uint32_t MVFR2;                  /*!< Offset: 0x018 (R/ )  Media and FP Feature Register 2 */
+} FPU_Type;
+
+/* Floating-Point Context Control Register Definitions */
+#define FPU_FPCCR_ASPEN_Pos                31U                                            /*!< FPCCR: ASPEN bit Position */
+#define FPU_FPCCR_ASPEN_Msk                (1UL << FPU_FPCCR_ASPEN_Pos)                   /*!< FPCCR: ASPEN bit Mask */
+
+#define FPU_FPCCR_LSPEN_Pos                30U                                            /*!< FPCCR: LSPEN Position */
+#define FPU_FPCCR_LSPEN_Msk                (1UL << FPU_FPCCR_LSPEN_Pos)                   /*!< FPCCR: LSPEN bit Mask */
+
+#define FPU_FPCCR_MONRDY_Pos                8U                                            /*!< FPCCR: MONRDY Position */
+#define FPU_FPCCR_MONRDY_Msk               (1UL << FPU_FPCCR_MONRDY_Pos)                  /*!< FPCCR: MONRDY bit Mask */
+
+#define FPU_FPCCR_BFRDY_Pos                 6U                                            /*!< FPCCR: BFRDY Position */
+#define FPU_FPCCR_BFRDY_Msk                (1UL << FPU_FPCCR_BFRDY_Pos)                   /*!< FPCCR: BFRDY bit Mask */
+
+#define FPU_FPCCR_MMRDY_Pos                 5U                                            /*!< FPCCR: MMRDY Position */
+#define FPU_FPCCR_MMRDY_Msk                (1UL << FPU_FPCCR_MMRDY_Pos)                   /*!< FPCCR: MMRDY bit Mask */
+
+#define FPU_FPCCR_HFRDY_Pos                 4U                                            /*!< FPCCR: HFRDY Position */
+#define FPU_FPCCR_HFRDY_Msk                (1UL << FPU_FPCCR_HFRDY_Pos)                   /*!< FPCCR: HFRDY bit Mask */
+
+#define FPU_FPCCR_THREAD_Pos                3U                                            /*!< FPCCR: processor mode bit Position */
+#define FPU_FPCCR_THREAD_Msk               (1UL << FPU_FPCCR_THREAD_Pos)                  /*!< FPCCR: processor mode active bit Mask */
+
+#define FPU_FPCCR_USER_Pos                  1U                                            /*!< FPCCR: privilege level bit Position */
+#define FPU_FPCCR_USER_Msk                 (1UL << FPU_FPCCR_USER_Pos)                    /*!< FPCCR: privilege level bit Mask */
+
+#define FPU_FPCCR_LSPACT_Pos                0U                                            /*!< FPCCR: Lazy state preservation active bit Position */
+#define FPU_FPCCR_LSPACT_Msk               (1UL /*<< FPU_FPCCR_LSPACT_Pos*/)              /*!< FPCCR: Lazy state preservation active bit Mask */
+
+/* Floating-Point Context Address Register Definitions */
+#define FPU_FPCAR_ADDRESS_Pos               3U                                            /*!< FPCAR: ADDRESS bit Position */
+#define FPU_FPCAR_ADDRESS_Msk              (0x1FFFFFFFUL << FPU_FPCAR_ADDRESS_Pos)        /*!< FPCAR: ADDRESS bit Mask */
+
+/* Floating-Point Default Status Control Register Definitions */
+#define FPU_FPDSCR_AHP_Pos                 26U                                            /*!< FPDSCR: AHP bit Position */
+#define FPU_FPDSCR_AHP_Msk                 (1UL << FPU_FPDSCR_AHP_Pos)                    /*!< FPDSCR: AHP bit Mask */
+
+#define FPU_FPDSCR_DN_Pos                  25U                                            /*!< FPDSCR: DN bit Position */
+#define FPU_FPDSCR_DN_Msk                  (1UL << FPU_FPDSCR_DN_Pos)                     /*!< FPDSCR: DN bit Mask */
+
+#define FPU_FPDSCR_FZ_Pos                  24U                                            /*!< FPDSCR: FZ bit Position */
+#define FPU_FPDSCR_FZ_Msk                  (1UL << FPU_FPDSCR_FZ_Pos)                     /*!< FPDSCR: FZ bit Mask */
+
+#define FPU_FPDSCR_RMode_Pos               22U                                            /*!< FPDSCR: RMode bit Position */
+#define FPU_FPDSCR_RMode_Msk               (3UL << FPU_FPDSCR_RMode_Pos)                  /*!< FPDSCR: RMode bit Mask */
+
+/* Media and FP Feature Register 0 Definitions */
+#define FPU_MVFR0_FP_rounding_modes_Pos    28U                                            /*!< MVFR0: FP rounding modes bits Position */
+#define FPU_MVFR0_FP_rounding_modes_Msk    (0xFUL << FPU_MVFR0_FP_rounding_modes_Pos)     /*!< MVFR0: FP rounding modes bits Mask */
+
+#define FPU_MVFR0_Short_vectors_Pos        24U                                            /*!< MVFR0: Short vectors bits Position */
+#define FPU_MVFR0_Short_vectors_Msk        (0xFUL << FPU_MVFR0_Short_vectors_Pos)         /*!< MVFR0: Short vectors bits Mask */
+
+#define FPU_MVFR0_Square_root_Pos          20U                                            /*!< MVFR0: Square root bits Position */
+#define FPU_MVFR0_Square_root_Msk          (0xFUL << FPU_MVFR0_Square_root_Pos)           /*!< MVFR0: Square root bits Mask */
+
+#define FPU_MVFR0_Divide_Pos               16U                                            /*!< MVFR0: Divide bits Position */
+#define FPU_MVFR0_Divide_Msk               (0xFUL << FPU_MVFR0_Divide_Pos)                /*!< MVFR0: Divide bits Mask */
+
+#define FPU_MVFR0_FP_excep_trapping_Pos    12U                                            /*!< MVFR0: FP exception trapping bits Position */
+#define FPU_MVFR0_FP_excep_trapping_Msk    (0xFUL << FPU_MVFR0_FP_excep_trapping_Pos)     /*!< MVFR0: FP exception trapping bits Mask */
+
+#define FPU_MVFR0_Double_precision_Pos      8U                                            /*!< MVFR0: Double-precision bits Position */
+#define FPU_MVFR0_Double_precision_Msk     (0xFUL << FPU_MVFR0_Double_precision_Pos)      /*!< MVFR0: Double-precision bits Mask */
+
+#define FPU_MVFR0_Single_precision_Pos      4U                                            /*!< MVFR0: Single-precision bits Position */
+#define FPU_MVFR0_Single_precision_Msk     (0xFUL << FPU_MVFR0_Single_precision_Pos)      /*!< MVFR0: Single-precision bits Mask */
+
+#define FPU_MVFR0_A_SIMD_registers_Pos      0U                                            /*!< MVFR0: A_SIMD registers bits Position */
+#define FPU_MVFR0_A_SIMD_registers_Msk     (0xFUL /*<< FPU_MVFR0_A_SIMD_registers_Pos*/)  /*!< MVFR0: A_SIMD registers bits Mask */
+
+/* Media and FP Feature Register 1 Definitions */
+#define FPU_MVFR1_FP_fused_MAC_Pos         28U                                            /*!< MVFR1: FP fused MAC bits Position */
+#define FPU_MVFR1_FP_fused_MAC_Msk         (0xFUL << FPU_MVFR1_FP_fused_MAC_Pos)          /*!< MVFR1: FP fused MAC bits Mask */
+
+#define FPU_MVFR1_FP_HPFP_Pos              24U                                            /*!< MVFR1: FP HPFP bits Position */
+#define FPU_MVFR1_FP_HPFP_Msk              (0xFUL << FPU_MVFR1_FP_HPFP_Pos)               /*!< MVFR1: FP HPFP bits Mask */
+
+#define FPU_MVFR1_D_NaN_mode_Pos            4U                                            /*!< MVFR1: D_NaN mode bits Position */
+#define FPU_MVFR1_D_NaN_mode_Msk           (0xFUL << FPU_MVFR1_D_NaN_mode_Pos)            /*!< MVFR1: D_NaN mode bits Mask */
+
+#define FPU_MVFR1_FtZ_mode_Pos              0U                                            /*!< MVFR1: FtZ mode bits Position */
+#define FPU_MVFR1_FtZ_mode_Msk             (0xFUL /*<< FPU_MVFR1_FtZ_mode_Pos*/)          /*!< MVFR1: FtZ mode bits Mask */
+
+/* Media and FP Feature Register 2 Definitions */
+
+/*@} end of group CMSIS_FPU */
+
+
+/**
+  \ingroup  CMSIS_core_register
+  \defgroup CMSIS_CoreDebug       Core Debug Registers (CoreDebug)
+  \brief    Type definitions for the Core Debug Registers
+  @{
+ */
+
+/**
+  \brief  Structure type to access the Core Debug Register (CoreDebug).
+ */
+typedef struct
+{
+  __IOM uint32_t DHCSR;                  /*!< Offset: 0x000 (R/W)  Debug Halting Control and Status Register */
+  __OM  uint32_t DCRSR;                  /*!< Offset: 0x004 ( /W)  Debug Core Register Selector Register */
+  __IOM uint32_t DCRDR;                  /*!< Offset: 0x008 (R/W)  Debug Core Register Data Register */
+  __IOM uint32_t DEMCR;                  /*!< Offset: 0x00C (R/W)  Debug Exception and Monitor Control Register */
+} CoreDebug_Type;
+
+/* Debug Halting Control and Status Register Definitions */
+#define CoreDebug_DHCSR_DBGKEY_Pos         16U                                            /*!< CoreDebug DHCSR: DBGKEY Position */
+#define CoreDebug_DHCSR_DBGKEY_Msk         (0xFFFFUL << CoreDebug_DHCSR_DBGKEY_Pos)       /*!< CoreDebug DHCSR: DBGKEY Mask */
+
+#define CoreDebug_DHCSR_S_RESET_ST_Pos     25U                                            /*!< CoreDebug DHCSR: S_RESET_ST Position */
+#define CoreDebug_DHCSR_S_RESET_ST_Msk     (1UL << CoreDebug_DHCSR_S_RESET_ST_Pos)        /*!< CoreDebug DHCSR: S_RESET_ST Mask */
+
+#define CoreDebug_DHCSR_S_RETIRE_ST_Pos    24U                                            /*!< CoreDebug DHCSR: S_RETIRE_ST Position */
+#define CoreDebug_DHCSR_S_RETIRE_ST_Msk    (1UL << CoreDebug_DHCSR_S_RETIRE_ST_Pos)       /*!< CoreDebug DHCSR: S_RETIRE_ST Mask */
+
+#define CoreDebug_DHCSR_S_LOCKUP_Pos       19U                                            /*!< CoreDebug DHCSR: S_LOCKUP Position */
+#define CoreDebug_DHCSR_S_LOCKUP_Msk       (1UL << CoreDebug_DHCSR_S_LOCKUP_Pos)          /*!< CoreDebug DHCSR: S_LOCKUP Mask */
+
+#define CoreDebug_DHCSR_S_SLEEP_Pos        18U                                            /*!< CoreDebug DHCSR: S_SLEEP Position */
+#define CoreDebug_DHCSR_S_SLEEP_Msk        (1UL << CoreDebug_DHCSR_S_SLEEP_Pos)           /*!< CoreDebug DHCSR: S_SLEEP Mask */
+
+#define CoreDebug_DHCSR_S_HALT_Pos         17U                                            /*!< CoreDebug DHCSR: S_HALT Position */
+#define CoreDebug_DHCSR_S_HALT_Msk         (1UL << CoreDebug_DHCSR_S_HALT_Pos)            /*!< CoreDebug DHCSR: S_HALT Mask */
+
+#define CoreDebug_DHCSR_S_REGRDY_Pos       16U                                            /*!< CoreDebug DHCSR: S_REGRDY Position */
+#define CoreDebug_DHCSR_S_REGRDY_Msk       (1UL << CoreDebug_DHCSR_S_REGRDY_Pos)          /*!< CoreDebug DHCSR: S_REGRDY Mask */
+
+#define CoreDebug_DHCSR_C_SNAPSTALL_Pos     5U                                            /*!< CoreDebug DHCSR: C_SNAPSTALL Position */
+#define CoreDebug_DHCSR_C_SNAPSTALL_Msk    (1UL << CoreDebug_DHCSR_C_SNAPSTALL_Pos)       /*!< CoreDebug DHCSR: C_SNAPSTALL Mask */
+
+#define CoreDebug_DHCSR_C_MASKINTS_Pos      3U                                            /*!< CoreDebug DHCSR: C_MASKINTS Position */
+#define CoreDebug_DHCSR_C_MASKINTS_Msk     (1UL << CoreDebug_DHCSR_C_MASKINTS_Pos)        /*!< CoreDebug DHCSR: C_MASKINTS Mask */
+
+#define CoreDebug_DHCSR_C_STEP_Pos          2U                                            /*!< CoreDebug DHCSR: C_STEP Position */
+#define CoreDebug_DHCSR_C_STEP_Msk         (1UL << CoreDebug_DHCSR_C_STEP_Pos)            /*!< CoreDebug DHCSR: C_STEP Mask */
+
+#define CoreDebug_DHCSR_C_HALT_Pos          1U                                            /*!< CoreDebug DHCSR: C_HALT Position */
+#define CoreDebug_DHCSR_C_HALT_Msk         (1UL << CoreDebug_DHCSR_C_HALT_Pos)            /*!< CoreDebug DHCSR: C_HALT Mask */
+
+#define CoreDebug_DHCSR_C_DEBUGEN_Pos       0U                                            /*!< CoreDebug DHCSR: C_DEBUGEN Position */
+#define CoreDebug_DHCSR_C_DEBUGEN_Msk      (1UL /*<< CoreDebug_DHCSR_C_DEBUGEN_Pos*/)     /*!< CoreDebug DHCSR: C_DEBUGEN Mask */
+
+/* Debug Core Register Selector Register Definitions */
+#define CoreDebug_DCRSR_REGWnR_Pos         16U                                            /*!< CoreDebug DCRSR: REGWnR Position */
+#define CoreDebug_DCRSR_REGWnR_Msk         (1UL << CoreDebug_DCRSR_REGWnR_Pos)            /*!< CoreDebug DCRSR: REGWnR Mask */
+
+#define CoreDebug_DCRSR_REGSEL_Pos          0U                                            /*!< CoreDebug DCRSR: REGSEL Position */
+#define CoreDebug_DCRSR_REGSEL_Msk         (0x1FUL /*<< CoreDebug_DCRSR_REGSEL_Pos*/)     /*!< CoreDebug DCRSR: REGSEL Mask */
+
+/* Debug Exception and Monitor Control Register Definitions */
+#define CoreDebug_DEMCR_TRCENA_Pos         24U                                            /*!< CoreDebug DEMCR: TRCENA Position */
+#define CoreDebug_DEMCR_TRCENA_Msk         (1UL << CoreDebug_DEMCR_TRCENA_Pos)            /*!< CoreDebug DEMCR: TRCENA Mask */
+
+#define CoreDebug_DEMCR_MON_REQ_Pos        19U                                            /*!< CoreDebug DEMCR: MON_REQ Position */
+#define CoreDebug_DEMCR_MON_REQ_Msk        (1UL << CoreDebug_DEMCR_MON_REQ_Pos)           /*!< CoreDebug DEMCR: MON_REQ Mask */
+
+#define CoreDebug_DEMCR_MON_STEP_Pos       18U                                            /*!< CoreDebug DEMCR: MON_STEP Position */
+#define CoreDebug_DEMCR_MON_STEP_Msk       (1UL << CoreDebug_DEMCR_MON_STEP_Pos)          /*!< CoreDebug DEMCR: MON_STEP Mask */
+
+#define CoreDebug_DEMCR_MON_PEND_Pos       17U                                            /*!< CoreDebug DEMCR: MON_PEND Position */
+#define CoreDebug_DEMCR_MON_PEND_Msk       (1UL << CoreDebug_DEMCR_MON_PEND_Pos)          /*!< CoreDebug DEMCR: MON_PEND Mask */
+
+#define CoreDebug_DEMCR_MON_EN_Pos         16U                                            /*!< CoreDebug DEMCR: MON_EN Position */
+#define CoreDebug_DEMCR_MON_EN_Msk         (1UL << CoreDebug_DEMCR_MON_EN_Pos)            /*!< CoreDebug DEMCR: MON_EN Mask */
+
+#define CoreDebug_DEMCR_VC_HARDERR_Pos     10U                                            /*!< CoreDebug DEMCR: VC_HARDERR Position */
+#define CoreDebug_DEMCR_VC_HARDERR_Msk     (1UL << CoreDebug_DEMCR_VC_HARDERR_Pos)        /*!< CoreDebug DEMCR: VC_HARDERR Mask */
+
+#define CoreDebug_DEMCR_VC_INTERR_Pos       9U                                            /*!< CoreDebug DEMCR: VC_INTERR Position */
+#define CoreDebug_DEMCR_VC_INTERR_Msk      (1UL << CoreDebug_DEMCR_VC_INTERR_Pos)         /*!< CoreDebug DEMCR: VC_INTERR Mask */
+
+#define CoreDebug_DEMCR_VC_BUSERR_Pos       8U                                            /*!< CoreDebug DEMCR: VC_BUSERR Position */
+#define CoreDebug_DEMCR_VC_BUSERR_Msk      (1UL << CoreDebug_DEMCR_VC_BUSERR_Pos)         /*!< CoreDebug DEMCR: VC_BUSERR Mask */
+
+#define CoreDebug_DEMCR_VC_STATERR_Pos      7U                                            /*!< CoreDebug DEMCR: VC_STATERR Position */
+#define CoreDebug_DEMCR_VC_STATERR_Msk     (1UL << CoreDebug_DEMCR_VC_STATERR_Pos)        /*!< CoreDebug DEMCR: VC_STATERR Mask */
+
+#define CoreDebug_DEMCR_VC_CHKERR_Pos       6U                                            /*!< CoreDebug DEMCR: VC_CHKERR Position */
+#define CoreDebug_DEMCR_VC_CHKERR_Msk      (1UL << CoreDebug_DEMCR_VC_CHKERR_Pos)         /*!< CoreDebug DEMCR: VC_CHKERR Mask */
+
+#define CoreDebug_DEMCR_VC_NOCPERR_Pos      5U                                            /*!< CoreDebug DEMCR: VC_NOCPERR Position */
+#define CoreDebug_DEMCR_VC_NOCPERR_Msk     (1UL << CoreDebug_DEMCR_VC_NOCPERR_Pos)        /*!< CoreDebug DEMCR: VC_NOCPERR Mask */
+
+#define CoreDebug_DEMCR_VC_MMERR_Pos        4U                                            /*!< CoreDebug DEMCR: VC_MMERR Position */
+#define CoreDebug_DEMCR_VC_MMERR_Msk       (1UL << CoreDebug_DEMCR_VC_MMERR_Pos)          /*!< CoreDebug DEMCR: VC_MMERR Mask */
+
+#define CoreDebug_DEMCR_VC_CORERESET_Pos    0U                                            /*!< CoreDebug DEMCR: VC_CORERESET Position */
+#define CoreDebug_DEMCR_VC_CORERESET_Msk   (1UL /*<< CoreDebug_DEMCR_VC_CORERESET_Pos*/)  /*!< CoreDebug DEMCR: VC_CORERESET Mask */
+
+/*@} end of group CMSIS_CoreDebug */
+
+
+/**
+  \ingroup    CMSIS_core_register
+  \defgroup   CMSIS_core_bitfield     Core register bit field macros
+  \brief      Macros for use with bit field definitions (xxx_Pos, xxx_Msk).
+  @{
+ */
+
+/**
+  \brief   Mask and shift a bit field value for use in a register bit range.
+  \param[in] field  Name of the register bit field.
+  \param[in] value  Value of the bit field. This parameter is interpreted as an uint32_t type.
+  \return           Masked and shifted value.
+*/
+#define _VAL2FLD(field, value)    (((uint32_t)(value) << field ## _Pos) & field ## _Msk)
+
+/**
+  \brief     Mask and shift a register value to extract a bit filed value.
+  \param[in] field  Name of the register bit field.
+  \param[in] value  Value of register. This parameter is interpreted as an uint32_t type.
+  \return           Masked and shifted bit field value.
+*/
+#define _FLD2VAL(field, value)    (((uint32_t)(value) & field ## _Msk) >> field ## _Pos)
+
+/*@} end of group CMSIS_core_bitfield */
+
+
+/**
+  \ingroup    CMSIS_core_register
+  \defgroup   CMSIS_core_base     Core Definitions
+  \brief      Definitions for base addresses, unions, and structures.
+  @{
+ */
+
+/* Memory mapping of Core Hardware */
+#define SCS_BASE            (0xE000E000UL)                            /*!< System Control Space Base Address */
+#define ITM_BASE            (0xE0000000UL)                            /*!< ITM Base Address */
+#define DWT_BASE            (0xE0001000UL)                            /*!< DWT Base Address */
+#define TPI_BASE            (0xE0040000UL)                            /*!< TPI Base Address */
+#define CoreDebug_BASE      (0xE000EDF0UL)                            /*!< Core Debug Base Address */
+#define SysTick_BASE        (SCS_BASE +  0x0010UL)                    /*!< SysTick Base Address */
+#define NVIC_BASE           (SCS_BASE +  0x0100UL)                    /*!< NVIC Base Address */
+#define SCB_BASE            (SCS_BASE +  0x0D00UL)                    /*!< System Control Block Base Address */
+
+#define SCnSCB              ((SCnSCB_Type    *)     SCS_BASE      )   /*!< System control Register not in SCB */
+#define SCB                 ((SCB_Type       *)     SCB_BASE      )   /*!< SCB configuration struct */
+#define SysTick             ((SysTick_Type   *)     SysTick_BASE  )   /*!< SysTick configuration struct */
+#define NVIC                ((NVIC_Type      *)     NVIC_BASE     )   /*!< NVIC configuration struct */
+#define ITM                 ((ITM_Type       *)     ITM_BASE      )   /*!< ITM configuration struct */
+#define DWT                 ((DWT_Type       *)     DWT_BASE      )   /*!< DWT configuration struct */
+#define TPI                 ((TPI_Type       *)     TPI_BASE      )   /*!< TPI configuration struct */
+#define CoreDebug           ((CoreDebug_Type *)     CoreDebug_BASE)   /*!< Core Debug configuration struct */
+
+#if defined (__MPU_PRESENT) && (__MPU_PRESENT == 1U)
+  #define MPU_BASE          (SCS_BASE +  0x0D90UL)                    /*!< Memory Protection Unit */
+  #define MPU               ((MPU_Type       *)     MPU_BASE      )   /*!< Memory Protection Unit */
+#endif
+
+#define FPU_BASE            (SCS_BASE +  0x0F30UL)                    /*!< Floating Point Unit */
+#define FPU                 ((FPU_Type       *)     FPU_BASE      )   /*!< Floating Point Unit */
+
+/*@} */
+
+
+
+/*******************************************************************************
+ *                Hardware Abstraction Layer
+  Core Function Interface contains:
+  - Core NVIC Functions
+  - Core SysTick Functions
+  - Core Debug Functions
+  - Core Register Access Functions
+ ******************************************************************************/
+/**
+  \defgroup CMSIS_Core_FunctionInterface Functions and Instructions Reference
+*/
+
+
+/* Cortex-R has GIC, not NVIC */
+#ifdef HAS_NVIC
+/* ##########################   NVIC functions  #################################### */
+/**
+  \ingroup  CMSIS_Core_FunctionInterface
+  \defgroup CMSIS_Core_NVICFunctions NVIC Functions
+  \brief    Functions that manage interrupts and exceptions via the NVIC.
+  @{
+ */
+
+#ifdef CMSIS_NVIC_VIRTUAL
+  #ifndef CMSIS_NVIC_VIRTUAL_HEADER_FILE
+    #define CMSIS_NVIC_VIRTUAL_HEADER_FILE "cmsis_nvic_virtual.h"
+  #endif
+  #include CMSIS_NVIC_VIRTUAL_HEADER_FILE
+#else
+  #define NVIC_SetPriorityGrouping    __NVIC_SetPriorityGrouping
+  #define NVIC_GetPriorityGrouping    __NVIC_GetPriorityGrouping
+  #define NVIC_EnableIRQ              __NVIC_EnableIRQ
+  #define NVIC_GetEnableIRQ           __NVIC_GetEnableIRQ
+  #define NVIC_DisableIRQ             __NVIC_DisableIRQ
+  #define NVIC_GetPendingIRQ          __NVIC_GetPendingIRQ
+  #define NVIC_SetPendingIRQ          __NVIC_SetPendingIRQ
+  #define NVIC_ClearPendingIRQ        __NVIC_ClearPendingIRQ
+  #define NVIC_GetActive              __NVIC_GetActive
+  #define NVIC_SetPriority            __NVIC_SetPriority
+  #define NVIC_GetPriority            __NVIC_GetPriority
+  #define NVIC_SystemReset            __NVIC_SystemReset
+#endif /* CMSIS_NVIC_VIRTUAL */
+
+#ifdef CMSIS_VECTAB_VIRTUAL
+  #ifndef CMSIS_VECTAB_VIRTUAL_HEADER_FILE
+    #define CMSIS_VECTAB_VIRTUAL_HEADER_FILE "cmsis_vectab_virtual.h"
+  #endif
+  #include CMSIS_VECTAB_VIRTUAL_HEADER_FILE
+#else
+  #define NVIC_SetVector              __NVIC_SetVector
+  #define NVIC_GetVector              __NVIC_GetVector
+#endif  /* (CMSIS_VECTAB_VIRTUAL) */
+
+#define NVIC_USER_IRQ_OFFSET          16
+
+
+/* The following EXC_RETURN values are saved the LR on exception entry */
+#define EXC_RETURN_HANDLER         (0xFFFFFFF1UL)     /* return to Handler mode, uses MSP after return                               */
+#define EXC_RETURN_THREAD_MSP      (0xFFFFFFF9UL)     /* return to Thread mode, uses MSP after return                                */
+#define EXC_RETURN_THREAD_PSP      (0xFFFFFFFDUL)     /* return to Thread mode, uses PSP after return                                */
+#define EXC_RETURN_HANDLER_FPU     (0xFFFFFFE1UL)     /* return to Handler mode, uses MSP after return, restore floating-point state */
+#define EXC_RETURN_THREAD_MSP_FPU  (0xFFFFFFE9UL)     /* return to Thread mode, uses MSP after return, restore floating-point state  */
+#define EXC_RETURN_THREAD_PSP_FPU  (0xFFFFFFEDUL)     /* return to Thread mode, uses PSP after return, restore floating-point state  */
+
+
+/**
+  \brief   Set Priority Grouping
+  \details Sets the priority grouping field using the required unlock sequence.
+           The parameter PriorityGroup is assigned to the field SCB->AIRCR [10:8] PRIGROUP field.
+           Only values from 0..7 are used.
+           In case of a conflict between priority grouping and available
+           priority bits (__NVIC_PRIO_BITS), the smallest possible priority group is set.
+  \param [in]      PriorityGroup  Priority grouping field.
+ */
+__STATIC_INLINE void __NVIC_SetPriorityGrouping(uint32_t PriorityGroup)
+{
+  uint32_t reg_value;
+  uint32_t PriorityGroupTmp = (PriorityGroup & (uint32_t)0x07UL);             /* only values 0..7 are used          */
+
+  reg_value  =  SCB->AIRCR;                                                   /* read old register configuration    */
+  reg_value &= ~((uint32_t)(SCB_AIRCR_VECTKEY_Msk | SCB_AIRCR_PRIGROUP_Msk)); /* clear bits to change               */
+  reg_value  =  (reg_value                                   |
+                ((uint32_t)0x5FAUL << SCB_AIRCR_VECTKEY_Pos) |
+                (PriorityGroupTmp << SCB_AIRCR_PRIGROUP_Pos)  );              /* Insert write key and priority group */
+  SCB->AIRCR =  reg_value;
+}
+
+
+/**
+  \brief   Get Priority Grouping
+  \details Reads the priority grouping field from the NVIC Interrupt Controller.
+  \return                Priority grouping field (SCB->AIRCR [10:8] PRIGROUP field).
+ */
+__STATIC_INLINE uint32_t __NVIC_GetPriorityGrouping(void)
+{
+  return ((uint32_t)((SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) >> SCB_AIRCR_PRIGROUP_Pos));
+}
+
+
+/**
+  \brief   Enable Interrupt
+  \details Enables a device specific interrupt in the NVIC interrupt controller.
+  \param [in]      IRQn  Device specific interrupt number.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE void __NVIC_EnableIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
+  }
+}
+
+
+/**
+  \brief   Get Interrupt Enable status
+  \details Returns a device specific interrupt enable status from the NVIC interrupt controller.
+  \param [in]      IRQn  Device specific interrupt number.
+  \return             0  Interrupt is not enabled.
+  \return             1  Interrupt is enabled.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE uint32_t __NVIC_GetEnableIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    return((uint32_t)(((NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] & (1UL << (((uint32_t)IRQn) & 0x1FUL))) != 0UL) ? 1UL : 0UL));
+  }
+  else
+  {
+    return(0U);
+  }
+}
+
+
+/**
+  \brief   Disable Interrupt
+  \details Disables a device specific interrupt in the NVIC interrupt controller.
+  \param [in]      IRQn  Device specific interrupt number.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE void __NVIC_DisableIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    NVIC->ICER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
+    __DSB();
+    __ISB();
+  }
+}
+
+
+/**
+  \brief   Get Pending Interrupt
+  \details Reads the NVIC pending register and returns the pending bit for the specified device specific interrupt.
+  \param [in]      IRQn  Device specific interrupt number.
+  \return             0  Interrupt status is not pending.
+  \return             1  Interrupt status is pending.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE uint32_t __NVIC_GetPendingIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    return((uint32_t)(((NVIC->ISPR[(((uint32_t)IRQn) >> 5UL)] & (1UL << (((uint32_t)IRQn) & 0x1FUL))) != 0UL) ? 1UL : 0UL));
+  }
+  else
+  {
+    return(0U);
+  }
+}
+
+
+/**
+  \brief   Set Pending Interrupt
+  \details Sets the pending bit of a device specific interrupt in the NVIC pending register.
+  \param [in]      IRQn  Device specific interrupt number.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE void __NVIC_SetPendingIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    NVIC->ISPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
+  }
+}
+
+
+/**
+  \brief   Clear Pending Interrupt
+  \details Clears the pending bit of a device specific interrupt in the NVIC pending register.
+  \param [in]      IRQn  Device specific interrupt number.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
+  }
+}
+
+
+/**
+  \brief   Get Active Interrupt
+  \details Reads the active register in the NVIC and returns the active bit for the device specific interrupt.
+  \param [in]      IRQn  Device specific interrupt number.
+  \return             0  Interrupt status is not active.
+  \return             1  Interrupt status is active.
+  \note    IRQn must not be negative.
+ */
+__STATIC_INLINE uint32_t __NVIC_GetActive(IRQn_Type IRQn)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    return((uint32_t)(((NVIC->IABR[(((uint32_t)IRQn) >> 5UL)] & (1UL << (((uint32_t)IRQn) & 0x1FUL))) != 0UL) ? 1UL : 0UL));
+  }
+  else
+  {
+    return(0U);
+  }
+}
+
+
+/**
+  \brief   Set Interrupt Priority
+  \details Sets the priority of a device specific interrupt or a processor exception.
+           The interrupt number can be positive to specify a device specific interrupt,
+           or negative to specify a processor exception.
+  \param [in]      IRQn  Interrupt number.
+  \param [in]  priority  Priority to set.
+  \note    The priority cannot be set for every processor exception.
+ */
+__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
+{
+  if ((int32_t)(IRQn) >= 0)
+  {
+    NVIC->IP[((uint32_t)IRQn)]                = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
+  }
+  else
+  {
+    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
+  }
+}
+
+
+/**
+  \brief   Get Interrupt Priority
+  \details Reads the priority of a device specific interrupt or a processor exception.
+           The interrupt number can be positive to specify a device specific interrupt,
+           or negative to specify a processor exception.
+  \param [in]   IRQn  Interrupt number.
+  \return             Interrupt Priority.
+                      Value is aligned automatically to the implemented priority bits of the microcontroller.
+ */
+__STATIC_INLINE uint32_t __NVIC_GetPriority(IRQn_Type IRQn)
+{
+
+  if ((int32_t)(IRQn) >= 0)
+  {
+    return(((uint32_t)NVIC->IP[((uint32_t)IRQn)]                >> (8U - __NVIC_PRIO_BITS)));
+  }
+  else
+  {
+    return(((uint32_t)SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] >> (8U - __NVIC_PRIO_BITS)));
+  }
+}
+
+
+/**
+  \brief   Encode Priority
+  \details Encodes the priority for an interrupt with the given priority group,
+           preemptive priority value, and subpriority value.
+           In case of a conflict between priority grouping and available
+           priority bits (__NVIC_PRIO_BITS), the smallest possible priority group is set.
+  \param [in]     PriorityGroup  Used priority group.
+  \param [in]   PreemptPriority  Preemptive priority value (starting from 0).
+  \param [in]       SubPriority  Subpriority value (starting from 0).
+  \return                        Encoded priority. Value can be used in the function \ref NVIC_SetPriority().
+ */
+__STATIC_INLINE uint32_t NVIC_EncodePriority (uint32_t PriorityGroup, uint32_t PreemptPriority, uint32_t SubPriority)
+{
+  uint32_t PriorityGroupTmp = (PriorityGroup & (uint32_t)0x07UL);   /* only values 0..7 are used          */
+  uint32_t PreemptPriorityBits;
+  uint32_t SubPriorityBits;
+
+  PreemptPriorityBits = ((7UL - PriorityGroupTmp) > (uint32_t)(__NVIC_PRIO_BITS)) ? (uint32_t)(__NVIC_PRIO_BITS) : (uint32_t)(7UL - PriorityGroupTmp);
+  SubPriorityBits     = ((PriorityGroupTmp + (uint32_t)(__NVIC_PRIO_BITS)) < (uint32_t)7UL) ? (uint32_t)0UL : (uint32_t)((PriorityGroupTmp - 7UL) + (uint32_t)(__NVIC_PRIO_BITS));
+
+  return (
+           ((PreemptPriority & (uint32_t)((1UL << (PreemptPriorityBits)) - 1UL)) << SubPriorityBits) |
+           ((SubPriority     & (uint32_t)((1UL << (SubPriorityBits    )) - 1UL)))
+         );
+}
+
+
+/**
+  \brief   Decode Priority
+  \details Decodes an interrupt priority value with a given priority group to
+           preemptive priority value and subpriority value.
+           In case of a conflict between priority grouping and available
+           priority bits (__NVIC_PRIO_BITS) the smallest possible priority group is set.
+  \param [in]         Priority   Priority value, which can be retrieved with the function \ref NVIC_GetPriority().
+  \param [in]     PriorityGroup  Used priority group.
+  \param [out] pPreemptPriority  Preemptive priority value (starting from 0).
+  \param [out]     pSubPriority  Subpriority value (starting from 0).
+ */
+__STATIC_INLINE void NVIC_DecodePriority (uint32_t Priority, uint32_t PriorityGroup, uint32_t* const pPreemptPriority, uint32_t* const pSubPriority)
+{
+  uint32_t PriorityGroupTmp = (PriorityGroup & (uint32_t)0x07UL);   /* only values 0..7 are used          */
+  uint32_t PreemptPriorityBits;
+  uint32_t SubPriorityBits;
+
+  PreemptPriorityBits = ((7UL - PriorityGroupTmp) > (uint32_t)(__NVIC_PRIO_BITS)) ? (uint32_t)(__NVIC_PRIO_BITS) : (uint32_t)(7UL - PriorityGroupTmp);
+  SubPriorityBits     = ((PriorityGroupTmp + (uint32_t)(__NVIC_PRIO_BITS)) < (uint32_t)7UL) ? (uint32_t)0UL : (uint32_t)((PriorityGroupTmp - 7UL) + (uint32_t)(__NVIC_PRIO_BITS));
+
+  *pPreemptPriority = (Priority >> SubPriorityBits) & (uint32_t)((1UL << (PreemptPriorityBits)) - 1UL);
+  *pSubPriority     = (Priority                   ) & (uint32_t)((1UL << (SubPriorityBits    )) - 1UL);
+}
+
+
+/**
+  \brief   Set Interrupt Vector
+  \details Sets an interrupt vector in SRAM based interrupt vector table.
+           The interrupt number can be positive to specify a device specific interrupt,
+           or negative to specify a processor exception.
+           VTOR must been relocated to SRAM before.
+  \param [in]   IRQn      Interrupt number
+  \param [in]   vector    Address of interrupt handler function
+ */
+__STATIC_INLINE void __NVIC_SetVector(IRQn_Type IRQn, uint32_t vector)
+{
+  uint32_t *vectors = (uint32_t *)SCB->VTOR;
+  vectors[(int32_t)IRQn + NVIC_USER_IRQ_OFFSET] = vector;
+}
+
+
+/**
+  \brief   Get Interrupt Vector
+  \details Reads an interrupt vector from interrupt vector table.
+           The interrupt number can be positive to specify a device specific interrupt,
+           or negative to specify a processor exception.
+  \param [in]   IRQn      Interrupt number.
+  \return                 Address of interrupt handler function
+ */
+__STATIC_INLINE uint32_t __NVIC_GetVector(IRQn_Type IRQn)
+{
+  uint32_t *vectors = (uint32_t *)SCB->VTOR;
+  return vectors[(int32_t)IRQn + NVIC_USER_IRQ_OFFSET];
+}
+
+
+/**
+  \brief   System Reset
+  \details Initiates a system reset request to reset the MCU.
+ */
+__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
+{
+  __DSB();                                                          /* Ensure all outstanding memory accesses included
+                                                                       buffered write are completed before reset */
+  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
+                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
+                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
+  __DSB();                                                          /* Ensure completion of memory access */
+
+  for(;;)                                                           /* wait until reset */
+  {
+    __NOP();
+  }
+}
+
+/*@} end of CMSIS_Core_NVICFunctions */
+#endif /* HAS_NVIC */
+
+/* ##########################  MPU functions  #################################### */
+
+#if defined (__MPU_PRESENT) && (__MPU_PRESENT == 1U)
+
+#include "mpu_cr7.h"
+
+#endif
+
+
+/* ##########################  FPU functions  #################################### */
+/**
+  \ingroup  CMSIS_Core_FunctionInterface
+  \defgroup CMSIS_Core_FpuFunctions FPU Functions
+  \brief    Function that provides FPU type.
+  @{
+ */
+
+/**
+  \brief   get FPU type
+  \details returns the FPU type
+  \returns
+   - \b  0: No FPU
+   - \b  1: Single precision FPU
+   - \b  2: Double + Single precision FPU
+ */
+__STATIC_INLINE uint32_t SCB_GetFPUType(void)
+{
+  uint32_t mvfr0;
+
+  mvfr0 = SCB->MVFR0;
+  if      ((mvfr0 & (FPU_MVFR0_Single_precision_Msk | FPU_MVFR0_Double_precision_Msk)) == 0x220U)
+  {
+    return 2U;           /* Double + Single precision FPU */
+  }
+  else if ((mvfr0 & (FPU_MVFR0_Single_precision_Msk | FPU_MVFR0_Double_precision_Msk)) == 0x020U)
+  {
+    return 1U;           /* Single precision FPU */
+  }
+  else
+  {
+    return 0U;           /* No FPU */
+  }
+}
+
+/*@} end of CMSIS_Core_FpuFunctions */
+
+
+
+/* ##########################  Cache functions  #################################### */
+/**
+  \ingroup  CMSIS_Core_FunctionInterface
+  \defgroup CMSIS_Core_CacheFunctions Cache Functions
+  \brief    Functions that configure Instruction and Data cache.
+  @{
+ */
+
+/* Cache Size ID Register Macros */
+#define CCSIDR_WAYS(x)         (((x) & SCB_CCSIDR_ASSOCIATIVITY_Msk) >> SCB_CCSIDR_ASSOCIATIVITY_Pos)
+#define CCSIDR_SETS(x)         (((x) & SCB_CCSIDR_NUMSETS_Msk      ) >> SCB_CCSIDR_NUMSETS_Pos      )
+
+#define __SCB_DCACHE_LINE_SIZE  32U /*!< Cortex-M7 cache line size is fixed to 32 bytes (8 words). See also register SCB_CCSIDR */
+
+/**
+  \brief   Enable I-Cache
+  \details Turns on I-Cache
+  */
+__STATIC_FORCEINLINE void SCB_EnableICache (void)
+{
+  #if defined (__ICACHE_PRESENT) && (__ICACHE_PRESENT == 1U)
+    if (SCB->CCR & SCB_CCR_IC_Msk) return;  /* return if ICache is already enabled */
+
+    __DSB();
+    __ISB();
+    SCB->ICIALLU = 0UL;                     /* invalidate I-Cache */
+    __DSB();
+    __ISB();
+    SCB->CCR |=  (uint32_t)SCB_CCR_IC_Msk;  /* enable I-Cache */
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Disable I-Cache
+  \details Turns off I-Cache
+  */
+__STATIC_FORCEINLINE void SCB_DisableICache (void)
+{
+  #if defined (__ICACHE_PRESENT) && (__ICACHE_PRESENT == 1U)
+    __DSB();
+    __ISB();
+    SCB->CCR &= ~(uint32_t)SCB_CCR_IC_Msk;  /* disable I-Cache */
+    SCB->ICIALLU = 0UL;                     /* invalidate I-Cache */
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Invalidate I-Cache
+  \details Invalidates I-Cache
+  */
+__STATIC_FORCEINLINE void SCB_InvalidateICache (void)
+{
+  #if defined (__ICACHE_PRESENT) && (__ICACHE_PRESENT == 1U)
+    __DSB();
+    __ISB();
+    SCB->ICIALLU = 0UL;
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Enable D-Cache
+  \details Turns on D-Cache
+  */
+__STATIC_FORCEINLINE void SCB_EnableDCache (void)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    uint32_t ccsidr;
+    uint32_t sets;
+    uint32_t ways;
+
+    if (SCB->CCR & SCB_CCR_DC_Msk) return;  /* return if DCache is already enabled */
+
+    SCB->CSSELR = 0U;                       /* select Level 1 data cache */
+    __DSB();
+
+    ccsidr = SCB->CCSIDR;
+
+                                            /* invalidate D-Cache */
+    sets = (uint32_t)(CCSIDR_SETS(ccsidr));
+    do {
+      ways = (uint32_t)(CCSIDR_WAYS(ccsidr));
+      do {
+        SCB->DCISW = (((sets << SCB_DCISW_SET_Pos) & SCB_DCISW_SET_Msk) |
+                      ((ways << SCB_DCISW_WAY_Pos) & SCB_DCISW_WAY_Msk)  );
+        #if defined ( __CC_ARM )
+          __schedule_barrier();
+        #endif
+      } while (ways-- != 0U);
+    } while(sets-- != 0U);
+    __DSB();
+
+    SCB->CCR |=  (uint32_t)SCB_CCR_DC_Msk;  /* enable D-Cache */
+
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Disable D-Cache
+  \details Turns off D-Cache
+  */
+__STATIC_FORCEINLINE void SCB_DisableDCache (void)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    uint32_t ccsidr;
+    uint32_t sets;
+    uint32_t ways;
+
+    SCB->CSSELR = 0U;                       /* select Level 1 data cache */
+    __DSB();
+
+    SCB->CCR &= ~(uint32_t)SCB_CCR_DC_Msk;  /* disable D-Cache */
+    __DSB();
+
+    ccsidr = SCB->CCSIDR;
+
+                                            /* clean & invalidate D-Cache */
+    sets = (uint32_t)(CCSIDR_SETS(ccsidr));
+    do {
+      ways = (uint32_t)(CCSIDR_WAYS(ccsidr));
+      do {
+        SCB->DCCISW = (((sets << SCB_DCCISW_SET_Pos) & SCB_DCCISW_SET_Msk) |
+                       ((ways << SCB_DCCISW_WAY_Pos) & SCB_DCCISW_WAY_Msk)  );
+        #if defined ( __CC_ARM )
+          __schedule_barrier();
+        #endif
+      } while (ways-- != 0U);
+    } while(sets-- != 0U);
+
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Invalidate D-Cache
+  \details Invalidates D-Cache
+  */
+__STATIC_FORCEINLINE void SCB_InvalidateDCache (void)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    uint32_t ccsidr;
+    uint32_t sets;
+    uint32_t ways;
+
+    SCB->CSSELR = 0U;                       /* select Level 1 data cache */
+    __DSB();
+
+    ccsidr = SCB->CCSIDR;
+
+                                            /* invalidate D-Cache */
+    sets = (uint32_t)(CCSIDR_SETS(ccsidr));
+    do {
+      ways = (uint32_t)(CCSIDR_WAYS(ccsidr));
+      do {
+        SCB->DCISW = (((sets << SCB_DCISW_SET_Pos) & SCB_DCISW_SET_Msk) |
+                      ((ways << SCB_DCISW_WAY_Pos) & SCB_DCISW_WAY_Msk)  );
+        #if defined ( __CC_ARM )
+          __schedule_barrier();
+        #endif
+      } while (ways-- != 0U);
+    } while(sets-- != 0U);
+
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Clean D-Cache
+  \details Cleans D-Cache
+  */
+__STATIC_FORCEINLINE void SCB_CleanDCache (void)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    uint32_t ccsidr;
+    uint32_t sets;
+    uint32_t ways;
+
+    SCB->CSSELR = 0U;                       /* select Level 1 data cache */
+    __DSB();
+
+    ccsidr = SCB->CCSIDR;
+
+                                            /* clean D-Cache */
+    sets = (uint32_t)(CCSIDR_SETS(ccsidr));
+    do {
+      ways = (uint32_t)(CCSIDR_WAYS(ccsidr));
+      do {
+        SCB->DCCSW = (((sets << SCB_DCCSW_SET_Pos) & SCB_DCCSW_SET_Msk) |
+                      ((ways << SCB_DCCSW_WAY_Pos) & SCB_DCCSW_WAY_Msk)  );
+        #if defined ( __CC_ARM )
+          __schedule_barrier();
+        #endif
+      } while (ways-- != 0U);
+    } while(sets-- != 0U);
+
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   Clean & Invalidate D-Cache
+  \details Cleans and Invalidates D-Cache
+  */
+__STATIC_FORCEINLINE void SCB_CleanInvalidateDCache (void)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    uint32_t ccsidr;
+    uint32_t sets;
+    uint32_t ways;
+
+    SCB->CSSELR = 0U;                       /* select Level 1 data cache */
+    __DSB();
+
+    ccsidr = SCB->CCSIDR;
+
+                                            /* clean & invalidate D-Cache */
+    sets = (uint32_t)(CCSIDR_SETS(ccsidr));
+    do {
+      ways = (uint32_t)(CCSIDR_WAYS(ccsidr));
+      do {
+        SCB->DCCISW = (((sets << SCB_DCCISW_SET_Pos) & SCB_DCCISW_SET_Msk) |
+                       ((ways << SCB_DCCISW_WAY_Pos) & SCB_DCCISW_WAY_Msk)  );
+        #if defined ( __CC_ARM )
+          __schedule_barrier();
+        #endif
+      } while (ways-- != 0U);
+    } while(sets-- != 0U);
+
+    __DSB();
+    __ISB();
+  #endif
+}
+
+
+/**
+  \brief   D-Cache Invalidate by address
+  \details Invalidates D-Cache for the given address.
+           D-Cache is invalidated starting from a 32 byte aligned address in 32 byte granularity.
+           D-Cache memory blocks which are part of given address + given size are invalidated.
+  \param[in]   addr    address
+  \param[in]   dsize   size of memory block (in number of bytes)
+*/
+__STATIC_FORCEINLINE void SCB_InvalidateDCache_by_Addr (void *addr, int32_t dsize)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    if ( dsize > 0 ) { 
+       int32_t op_size = dsize + (((uint32_t)addr) & (__SCB_DCACHE_LINE_SIZE - 1U));
+      uint32_t op_addr = (uint32_t)addr /* & ~(__SCB_DCACHE_LINE_SIZE - 1U) */;
+    
+      __DSB();
+
+      do {
+        SCB->DCIMVAC = op_addr;             /* register accepts only 32byte aligned values, only bits 31..5 are valid */
+        op_addr += __SCB_DCACHE_LINE_SIZE;
+        op_size -= __SCB_DCACHE_LINE_SIZE;
+      } while ( op_size > 0 );
+
+      __DSB();
+      __ISB();
+    }
+  #endif
+}
+
+
+/**
+  \brief   D-Cache Clean by address
+  \details Cleans D-Cache for the given address
+           D-Cache is cleaned starting from a 32 byte aligned address in 32 byte granularity.
+           D-Cache memory blocks which are part of given address + given size are cleaned.
+  \param[in]   addr    address
+  \param[in]   dsize   size of memory block (in number of bytes)
+*/
+__STATIC_FORCEINLINE void SCB_CleanDCache_by_Addr (uint32_t *addr, int32_t dsize)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    if ( dsize > 0 ) { 
+       int32_t op_size = dsize + (((uint32_t)addr) & (__SCB_DCACHE_LINE_SIZE - 1U));
+      uint32_t op_addr = (uint32_t)addr /* & ~(__SCB_DCACHE_LINE_SIZE - 1U) */;
+    
+      __DSB();
+
+      do {
+        SCB->DCCMVAC = op_addr;             /* register accepts only 32byte aligned values, only bits 31..5 are valid */
+        op_addr += __SCB_DCACHE_LINE_SIZE;
+        op_size -= __SCB_DCACHE_LINE_SIZE;
+      } while ( op_size > 0 );
+
+      __DSB();
+      __ISB();
+    }
+  #endif
+}
+
+
+/**
+  \brief   D-Cache Clean and Invalidate by address
+  \details Cleans and invalidates D_Cache for the given address
+           D-Cache is cleaned and invalidated starting from a 32 byte aligned address in 32 byte granularity.
+           D-Cache memory blocks which are part of given address + given size are cleaned and invalidated.
+  \param[in]   addr    address (aligned to 32-byte boundary)
+  \param[in]   dsize   size of memory block (in number of bytes)
+*/
+__STATIC_FORCEINLINE void SCB_CleanInvalidateDCache_by_Addr (uint32_t *addr, int32_t dsize)
+{
+  #if defined (__DCACHE_PRESENT) && (__DCACHE_PRESENT == 1U)
+    if ( dsize > 0 ) { 
+       int32_t op_size = dsize + (((uint32_t)addr) & (__SCB_DCACHE_LINE_SIZE - 1U));
+      uint32_t op_addr = (uint32_t)addr /* & ~(__SCB_DCACHE_LINE_SIZE - 1U) */;
+    
+      __DSB();
+
+      do {
+        SCB->DCCIMVAC = op_addr;            /* register accepts only 32byte aligned values, only bits 31..5 are valid */
+        op_addr +=          __SCB_DCACHE_LINE_SIZE;
+        op_size -=          __SCB_DCACHE_LINE_SIZE;
+      } while ( op_size > 0 );
+
+      __DSB();
+      __ISB();
+    }
+  #endif
+}
+
+/*@} end of CMSIS_Core_CacheFunctions */
+
+
+
+/* ##################################    SysTick function  ############################################ */
+/**
+  \ingroup  CMSIS_Core_FunctionInterface
+  \defgroup CMSIS_Core_SysTickFunctions SysTick Functions
+  \brief    Functions that configure the System.
+  @{
+ */
+
+#if defined (__Vendor_SysTickConfig) && (__Vendor_SysTickConfig == 0U)
+
+/**
+  \brief   System Tick Configuration
+  \details Initializes the System Timer and its interrupt, and starts the System Tick Timer.
+           Counter is in free running mode to generate periodic interrupts.
+  \param [in]  ticks  Number of ticks between two interrupts.
+  \return          0  Function succeeded.
+  \return          1  Function failed.
+  \note    When the variable <b>__Vendor_SysTickConfig</b> is set to 1, then the
+           function <b>SysTick_Config</b> is not included. In this case, the file <b><i>device</i>.h</b>
+           must contain a vendor-specific implementation of this function.
+ */
+__STATIC_INLINE uint32_t SysTick_Config(uint32_t ticks)
+{
+  if ((ticks - 1UL) > SysTick_LOAD_RELOAD_Msk)
+  {
+    return (1UL);                                                   /* Reload value impossible */
+  }
+
+  SysTick->LOAD  = (uint32_t)(ticks - 1UL);                         /* set reload register */
+  NVIC_SetPriority (SysTick_IRQn, (1UL << __NVIC_PRIO_BITS) - 1UL); /* set Priority for Systick Interrupt */
+  SysTick->VAL   = 0UL;                                             /* Load the SysTick Counter Value */
+  SysTick->CTRL  = SysTick_CTRL_CLKSOURCE_Msk |
+                   SysTick_CTRL_TICKINT_Msk   |
+                   SysTick_CTRL_ENABLE_Msk;                         /* Enable SysTick IRQ and SysTick Timer */
+  return (0UL);                                                     /* Function successful */
+}
+
+#endif
+
+/*@} end of CMSIS_Core_SysTickFunctions */
+
+
+
+/* ##################################### Debug In/Output function ########################################### */
+/**
+  \ingroup  CMSIS_Core_FunctionInterface
+  \defgroup CMSIS_core_DebugFunctions ITM Functions
+  \brief    Functions that access the ITM debug interface.
+  @{
+ */
+
+extern volatile int32_t ITM_RxBuffer;                              /*!< External variable to receive characters. */
+#define                 ITM_RXBUFFER_EMPTY  ((int32_t)0x5AA55AA5U) /*!< Value identifying \ref ITM_RxBuffer is ready for next character. */
+
+
+/**
+  \brief   ITM Send Character
+  \details Transmits a character via the ITM channel 0, and
+           \li Just returns when no debugger is connected that has booked the output.
+           \li Is blocking when a debugger is connected, but the previous character sent has not been transmitted.
+  \param [in]     ch  Character to transmit.
+  \returns            Character to transmit.
+ */
+__STATIC_INLINE uint32_t ITM_SendChar (uint32_t ch)
+{
+  if (((ITM->TCR & ITM_TCR_ITMENA_Msk) != 0UL) &&      /* ITM enabled */
+      ((ITM->TER & 1UL               ) != 0UL)   )     /* ITM Port #0 enabled */
+  {
+    while (ITM->PORT[0U].u32 == 0UL)
+    {
+      __NOP();
+    }
+    ITM->PORT[0U].u8 = (uint8_t)ch;
+  }
+  return (ch);
+}
+
+
+/**
+  \brief   ITM Receive Character
+  \details Inputs a character via the external variable \ref ITM_RxBuffer.
+  \return             Received character.
+  \return         -1  No character pending.
+ */
+__STATIC_INLINE int32_t ITM_ReceiveChar (void)
+{
+  int32_t ch = -1;                           /* no character available */
+
+  if (ITM_RxBuffer != ITM_RXBUFFER_EMPTY)
+  {
+    ch = ITM_RxBuffer;
+    ITM_RxBuffer = ITM_RXBUFFER_EMPTY;       /* ready for next character */
+  }
+
+  return (ch);
+}
+
+
+/**
+  \brief   ITM Check Character
+  \details Checks whether a character is pending for reading in the variable \ref ITM_RxBuffer.
+  \return          0  No character available.
+  \return          1  Character available.
+ */
+__STATIC_INLINE int32_t ITM_CheckChar (void)
+{
+
+  if (ITM_RxBuffer == ITM_RXBUFFER_EMPTY)
+  {
+    return (0);                              /* no character available */
+  }
+  else
+  {
+    return (1);                              /*    character available */
+  }
+}
+
+/*@} end of CMSIS_core_DebugFunctions */
+
+
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __CORE_CM7_H_DEPENDANT */
+
+#endif /* __CMSIS_GENERIC */
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl.h b/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl.h
new file mode 100644
index 00000000..fbb7617c
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl.h
@@ -0,0 +1,102 @@
+/**************************************************************************//**
+ * @file     irq_ctrl.h
+ * @brief    Interrupt Controller API header file
+ * @version  V1.0.0
+ * @date     23. June 2017
+ ******************************************************************************/
+/*
+ * Copyright (c) 2017 ARM Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header   /* treat file as system include file */
+#endif
+
+#ifndef IRQ_CTRL_H_
+#define IRQ_CTRL_H_
+
+#include <stdint.h>
+
+#ifndef IRQHANDLER_T
+#define IRQHANDLER_T
+/// Interrupt handler data type
+typedef void (*IRQHandler_t) (void);
+#endif
+
+#ifndef IRQN_ID_T
+#define IRQN_ID_T
+/// Interrupt ID number data type
+typedef int32_t IRQn_ID_t;
+#endif
+
+/* Interrupt mode bit-masks */
+#define IRQ_MODE_TRIG_Pos           (0U)
+#define IRQ_MODE_TRIG_Msk           (0x07UL /*<< IRQ_MODE_TRIG_Pos*/)
+#define IRQ_MODE_TRIG_LEVEL         (0x00UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: level triggered interrupt
+#define IRQ_MODE_TRIG_LEVEL_LOW     (0x01UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: low level triggered interrupt
+#define IRQ_MODE_TRIG_LEVEL_HIGH    (0x02UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: high level triggered interrupt
+#define IRQ_MODE_TRIG_EDGE          (0x04UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: edge triggered interrupt
+#define IRQ_MODE_TRIG_EDGE_RISING   (0x05UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: rising edge triggered interrupt
+#define IRQ_MODE_TRIG_EDGE_FALLING  (0x06UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: falling edge triggered interrupt
+#define IRQ_MODE_TRIG_EDGE_BOTH     (0x07UL /*<< IRQ_MODE_TRIG_Pos*/) ///< Trigger: rising and falling edge triggered interrupt
+
+#define IRQ_MODE_TYPE_Pos           (3U)
+#define IRQ_MODE_TYPE_Msk           (0x01UL << IRQ_MODE_TYPE_Pos)
+#define IRQ_MODE_TYPE_IRQ           (0x00UL << IRQ_MODE_TYPE_Pos)     ///< Type: interrupt source triggers CPU IRQ line
+#define IRQ_MODE_TYPE_FIQ           (0x01UL << IRQ_MODE_TYPE_Pos)     ///< Type: interrupt source triggers CPU FIQ line
+
+#define IRQ_MODE_DOMAIN_Pos         (4U)
+#define IRQ_MODE_DOMAIN_Msk         (0x01UL << IRQ_MODE_DOMAIN_Pos)
+#define IRQ_MODE_DOMAIN_NONSECURE   (0x00UL << IRQ_MODE_DOMAIN_Pos)   ///< Domain: interrupt is targeting non-secure domain
+#define IRQ_MODE_DOMAIN_SECURE      (0x01UL << IRQ_MODE_DOMAIN_Pos)   ///< Domain: interrupt is targeting secure domain
+
+#define IRQ_MODE_CPU_Pos            (5U)
+#define IRQ_MODE_CPU_Msk            (0xFFUL << IRQ_MODE_CPU_Pos)
+#define IRQ_MODE_CPU_ALL            (0x00UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets all CPUs
+#define IRQ_MODE_CPU_0              (0x01UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 0
+#define IRQ_MODE_CPU_1              (0x02UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 1
+#define IRQ_MODE_CPU_2              (0x04UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 2
+#define IRQ_MODE_CPU_3              (0x08UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 3
+#define IRQ_MODE_CPU_4              (0x10UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 4
+#define IRQ_MODE_CPU_5              (0x20UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 5
+#define IRQ_MODE_CPU_6              (0x40UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 6
+#define IRQ_MODE_CPU_7              (0x80UL << IRQ_MODE_CPU_Pos)      ///< CPU: interrupt targets CPU 7
+
+#define IRQ_MODE_ERROR              (0x80000000UL)                    ///< Bit indicating mode value error
+
+/* Interrupt priority bit-masks */
+#define IRQ_PRIORITY_Msk            (0x0000FFFFUL)                    ///< Interrupt priority value bit-mask
+#define IRQ_PRIORITY_ERROR          (0x80000000UL)                    ///< Bit indicating priority value error
+
+/// Configure interrupt request mode.
+/// \param[in]     irqn          interrupt ID number
+/// \param[in]     mode          mode configuration
+/// \return 0 on success, -1 on error.
+int32_t IRQ_SetMode (GICDistributor_Type *GICDistributor, IRQn_ID_t irqn, uint32_t mode);
+
+/// Get interrupt mode configuration.
+/// \param[in]     irqn          interrupt ID number
+/// \return current interrupt mode configuration with optional IRQ_MODE_ERROR bit set.
+uint32_t IRQ_GetMode (IRQn_ID_t irqn);
+
+/// Get ID number of current interrupt request (IRQ).
+/// \return interrupt ID number.
+IRQn_ID_t IRQ_GetActiveIRQ (GICDistributor_Type *GICDistributor, GICInterface_Type *GICInterface);
+
+#endif  // IRQ_CTRL_H_
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl_gic.c b/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl_gic.c
new file mode 100644
index 00000000..a35334df
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/irq_ctrl_gic.c
@@ -0,0 +1,149 @@
+/**************************************************************************//**
+ * @file     irq_ctrl_gic.c
+ * @brief    Interrupt controller handling implementation for GIC
+ * @version  V1.0.1
+ * @date     9. April 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2017 ARM Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <stddef.h>
+
+//#include "RTE_Components.h"
+//#include CMSIS_device_header
+#include "cmsis_rcar_gen3.h"
+
+#include "irq_ctrl.h"
+
+#if defined(__GIC_PRESENT) && (__GIC_PRESENT == 1U)
+
+/// Number of implemented interrupt lines
+#ifndef IRQ_GIC_LINE_COUNT
+#define IRQ_GIC_LINE_COUNT      (1020U)
+#endif
+
+static uint32_t     IRQ_ID0;
+
+/// Configure interrupt request mode.
+__WEAK int32_t IRQ_SetMode (GICDistributor_Type *GICDistributor, IRQn_ID_t irqn, uint32_t mode) {
+  uint32_t val;
+  uint8_t cfg;
+  uint8_t secure;
+  uint8_t cpu;
+  int32_t status = 0;
+
+  if ((irqn >= 0) && (irqn < (IRQn_ID_t)IRQ_GIC_LINE_COUNT)) {
+    // Check triggering mode
+    val = (mode & IRQ_MODE_TRIG_Msk);
+
+    if (val == IRQ_MODE_TRIG_LEVEL) {
+      cfg = 0x00U;
+    } else if (val == IRQ_MODE_TRIG_EDGE) {
+      cfg = 0x02U;
+    } else {
+      cfg = 0x00U;
+      status = -1;
+    }
+
+    // Check interrupt type
+    val = mode & IRQ_MODE_TYPE_Msk;
+
+    if (val != IRQ_MODE_TYPE_IRQ) {
+      status = -1;
+    }
+
+    // Check interrupt domain
+    val = mode & IRQ_MODE_DOMAIN_Msk;
+
+    if (val == IRQ_MODE_DOMAIN_NONSECURE) {
+      secure = 0U;
+    } else {
+      // Check security extensions support
+      val = GIC_DistributorInfo(GICDistributor) & (1UL << 10U);
+
+      if (val != 0U) {
+        // Security extensions are supported
+        secure = 1U;
+      } else {
+        secure = 0U;
+        status = -1;
+      }
+    }
+
+    // Check interrupt CPU targets
+    val = mode & IRQ_MODE_CPU_Msk;
+
+    if (val == IRQ_MODE_CPU_ALL) {
+      cpu = 0xFFU;
+    } else {
+      cpu = val >> IRQ_MODE_CPU_Pos;
+    }
+
+    // Apply configuration if no mode error
+    if (status == 0) {
+      GIC_SetConfiguration(GICDistributor, (IRQn_Type)irqn, cfg);
+      GIC_SetTarget       (GICDistributor, (IRQn_Type)irqn, cpu);
+
+      if (secure != 0U) {
+        GIC_SetGroup (GICDistributor, (IRQn_Type)irqn, secure);
+      }
+    }
+  }
+
+  return (status);
+}
+
+
+/// Get ID number of current interrupt request (IRQ).
+__WEAK IRQn_ID_t IRQ_GetActiveIRQ (GICDistributor_Type *GICDistributor, GICInterface_Type *GICInterface) {
+  IRQn_ID_t irqn;
+  uint32_t prio;
+
+  /* Dummy read to avoid GIC 390 errata 801120 */
+  GIC_GetHighPendingIRQ(GICInterface);
+
+  irqn = GIC_AcknowledgePending(GICInterface);
+
+  __DSB();
+
+  /* Workaround GIC 390 errata 733075 (GIC-390_Errata_Notice_v6.pdf, 09-Jul-2014)  */
+  /* The following workaround code is for a single-core system.  It would be       */
+  /* different in a multi-core system.                                             */
+  /* If the ID is 0 or 0x3FE or 0x3FF, then the GIC CPU interface may be locked-up */
+  /* so unlock it, otherwise service the interrupt as normal.                      */
+  /* Special IDs 1020=0x3FC and 1021=0x3FD are reserved values in GICv1 and GICv2  */
+  /* so will not occur here.                                                       */
+
+  if ((irqn == 0) || (irqn >= 0x3FE)) {
+    /* Unlock the CPU interface with a dummy write to Interrupt Priority Register */
+    prio = GIC_GetPriority(GICDistributor, (IRQn_Type)0);
+    GIC_SetPriority (GICDistributor, (IRQn_Type)0, prio);
+
+    __DSB();
+
+    if ((irqn == 0U) && ((GIC_GetIRQStatus (GICDistributor, (IRQn_Type)irqn) & 1U) != 0U) && (IRQ_ID0 == 0U)) {
+      /* If the ID is 0, is active and has not been seen before */
+      IRQ_ID0 = 1U;
+    }
+    /* End of Workaround GIC 390 errata 733075 */
+  }
+
+  return (irqn);
+}
+
+#endif
diff --git a/machines/cortex-r/armv7/RCar/CMSIS/mpu_cr7.h b/machines/cortex-r/armv7/RCar/CMSIS/mpu_cr7.h
new file mode 100644
index 00000000..19e6fb05
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/CMSIS/mpu_cr7.h
@@ -0,0 +1,271 @@
+/******************************************************************************
+ * MPU API for Armv7-R MPU
+ *
+ * Based on
+ * @file     mpu_armv7.h
+ * @brief    CMSIS MPU API for Armv7-M MPU
+ * @version  V5.0.5
+ * @date     06. September 2018
+ ******************************************************************************/
+/*
+ * Copyright (c) 2017-2018 Arm Limited. All rights reserved.
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Licensed under the Apache License, Version 2.0 (the License); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ 
+#if   defined ( __ICCARM__ )
+  #pragma system_include         /* treat file as system include file for MISRA check */
+#elif defined (__clang__)
+  #pragma clang system_header    /* treat file as system include file */
+#endif
+ 
+#ifndef ARM_MPU_ARMV7_H
+#define ARM_MPU_ARMV7_H
+
+/** @defgroup group2 MPU
+ *  The MPU (Memory Protection Unit) functions are based on the ARM CMSIS MPU
+ *  functions for Cortex-M devices. The MPU not only restricts execution and
+ *  data access to address regions, but also specifies the attributes of the
+ *  regions such as caching.
+ *  @{
+ */
+
+#define ARM_MPU_REGION_SIZE_256B     ((uint8_t)0x07U) ///< MPU Region Size 256 Bytes
+#define ARM_MPU_REGION_SIZE_512B     ((uint8_t)0x08U) ///< MPU Region Size 512 Bytes
+#define ARM_MPU_REGION_SIZE_1KB      ((uint8_t)0x09U) ///< MPU Region Size 1 KByte
+#define ARM_MPU_REGION_SIZE_2KB      ((uint8_t)0x0AU) ///< MPU Region Size 2 KBytes
+#define ARM_MPU_REGION_SIZE_4KB      ((uint8_t)0x0BU) ///< MPU Region Size 4 KBytes
+#define ARM_MPU_REGION_SIZE_8KB      ((uint8_t)0x0CU) ///< MPU Region Size 8 KBytes
+#define ARM_MPU_REGION_SIZE_16KB     ((uint8_t)0x0DU) ///< MPU Region Size 16 KBytes
+#define ARM_MPU_REGION_SIZE_32KB     ((uint8_t)0x0EU) ///< MPU Region Size 32 KBytes
+#define ARM_MPU_REGION_SIZE_64KB     ((uint8_t)0x0FU) ///< MPU Region Size 64 KBytes
+#define ARM_MPU_REGION_SIZE_128KB    ((uint8_t)0x10U) ///< MPU Region Size 128 KBytes
+#define ARM_MPU_REGION_SIZE_256KB    ((uint8_t)0x11U) ///< MPU Region Size 256 KBytes
+#define ARM_MPU_REGION_SIZE_512KB    ((uint8_t)0x12U) ///< MPU Region Size 512 KBytes
+#define ARM_MPU_REGION_SIZE_1MB      ((uint8_t)0x13U) ///< MPU Region Size 1 MByte
+#define ARM_MPU_REGION_SIZE_2MB      ((uint8_t)0x14U) ///< MPU Region Size 2 MBytes
+#define ARM_MPU_REGION_SIZE_4MB      ((uint8_t)0x15U) ///< MPU Region Size 4 MBytes
+#define ARM_MPU_REGION_SIZE_8MB      ((uint8_t)0x16U) ///< MPU Region Size 8 MBytes
+#define ARM_MPU_REGION_SIZE_16MB     ((uint8_t)0x17U) ///< MPU Region Size 16 MBytes
+#define ARM_MPU_REGION_SIZE_32MB     ((uint8_t)0x18U) ///< MPU Region Size 32 MBytes
+#define ARM_MPU_REGION_SIZE_64MB     ((uint8_t)0x19U) ///< MPU Region Size 64 MBytes
+#define ARM_MPU_REGION_SIZE_128MB    ((uint8_t)0x1AU) ///< MPU Region Size 128 MBytes
+#define ARM_MPU_REGION_SIZE_256MB    ((uint8_t)0x1BU) ///< MPU Region Size 256 MBytes
+#define ARM_MPU_REGION_SIZE_512MB    ((uint8_t)0x1CU) ///< MPU Region Size 512 MBytes
+#define ARM_MPU_REGION_SIZE_1GB      ((uint8_t)0x1DU) ///< MPU Region Size 1 GByte
+#define ARM_MPU_REGION_SIZE_2GB      ((uint8_t)0x1EU) ///< MPU Region Size 2 GBytes
+#define ARM_MPU_REGION_SIZE_4GB      ((uint8_t)0x1FU) ///< MPU Region Size 4 GBytes
+
+#define ARM_MPU_AP_NONE 0U ///< MPU Access Permission no access
+#define ARM_MPU_AP_PRIV 1U ///< MPU Access Permission privileged access only
+#define ARM_MPU_AP_URO  2U ///< MPU Access Permission unprivileged access read-only
+#define ARM_MPU_AP_FULL 3U ///< MPU Access Permission full access
+#define ARM_MPU_AP_PRO  5U ///< MPU Access Permission privileged access read-only
+#define ARM_MPU_AP_RO   6U ///< MPU Access Permission read-only access
+
+#define ARM_MPU_REGION(Region) \
+  ((Region) & MPU_RBAR_REGION_Msk)
+
+/**
+* MPU Region Size Value
+* 
+* \param SubRegionDisable  Sub-region disable field.
+* \param Size              Region size of the region to be configured, for example 4K, 8K.
+*/
+#define ARM_MPU_SIZE(SubRegionDisable, Size)    \
+  ((((SubRegionDisable) << MPU_RASR_SRD_Pos)  & MPU_RASR_SRD_Msk)                                 | \
+   (((Size)             << MPU_RASR_SIZE_Pos) & MPU_RASR_SIZE_Msk)                                | \
+   (((MPU_RASR_ENABLE_Msk))))
+
+/**
+* MPU Memory Access Attributes
+* 
+* \param TypeExtField      Type extension field, allows you to configure memory access type, for example strongly ordered, peripheral.
+* \param IsShareable       Region is shareable between multiple bus masters.
+* \param IsCacheable       Region is cacheable, i.e. its value may be kept in cache.
+* \param IsBufferable      Region is bufferable, i.e. using write-back caching. Cacheable but non-bufferable regions use write-through policy.
+*/  
+#define ARM_MPU_ACCESS_(TypeExtField, IsShareable, IsCacheable, IsBufferable)   \
+  ((((TypeExtField) << MPU_RASR_TEX_Pos) & MPU_RASR_TEX_Msk)                  | \
+   (((IsShareable)  << MPU_RASR_S_Pos)   & MPU_RASR_S_Msk)                    | \
+   (((IsCacheable)  << MPU_RASR_C_Pos)   & MPU_RASR_C_Msk)                    | \
+   (((IsBufferable) << MPU_RASR_B_Pos)   & MPU_RASR_B_Msk))
+
+/**
+* MPU Region Attribute Value
+* 
+* \param DisableExec       Instruction access disable bit, 1= disable instruction fetches.
+* \param AccessPermission  Data access permissions, allows you to configure read/write access for User and Privileged mode.
+* \param AccessAttributes  Memory access attribution, see \ref ARM_MPU_ACCESS_.
+*/
+#define ARM_MPU_ATTRIB_EX(DisableExec, AccessPermission, AccessAttributes)    \
+  ((((DisableExec)      << MPU_RASR_XN_Pos)   & MPU_RASR_XN_Msk)                                  | \
+   (((AccessPermission) << MPU_RASR_AP_Pos)   & MPU_RASR_AP_Msk)                                  | \
+   (((AccessAttributes) & (MPU_RASR_TEX_Msk | MPU_RASR_S_Msk | MPU_RASR_C_Msk | MPU_RASR_B_Msk))))
+
+/**
+* MPU Region Attribute Value
+* See the DRACR register description in the ARM DDI0458 Cortex-R7 MPCore Technical Reference Manual for details.
+* 
+* \param DisableExec       XN: Instruction access disable bit, 1= disable instruction fetches.
+* \param AccessPermission  AP: Data access permissions, allows you to configure read/write access for User and Privileged mode.
+* \param TypeExtField      TEX: Type extension field, allows you to configure memory access type, for example strongly ordered, peripheral.
+* \param IsShareable       S: Region is shareable between multiple bus masters.
+* \param IsCacheable       C: Region is cacheable, i.e. its value may be kept in cache.
+* \param IsBufferable      B: Region is bufferable, i.e. using write-back caching. Cacheable but non-bufferable regions use write-through policy.
+*/                         
+#define ARM_MPU_ATTRIB(DisableExec, AccessPermission, TypeExtField, IsShareable, IsCacheable, IsBufferable) \
+  ARM_MPU_ATTRIB_EX(DisableExec, AccessPermission, ARM_MPU_ACCESS_(TypeExtField, IsShareable, IsCacheable, IsBufferable))
+
+/**
+* MPU Memory Access Attribute for strongly ordered memory.
+*  - TEX: 000b
+*  - Shareable
+*  - Non-cacheable
+*  - Non-bufferable
+*/ 
+#define ARM_MPU_ACCESS_ORDERED ARM_MPU_ACCESS_(0U, 1U, 0U, 0U)
+
+/**
+* MPU Memory Access Attribute for device memory.
+*  - TEX: 000b (if non-shareable) or 010b (if shareable)
+*  - Shareable or non-shareable
+*  - Non-cacheable
+*  - Bufferable (if shareable) or non-bufferable (if non-shareable)
+*
+* \param IsShareable Configures the device memory as shareable or non-shareable.
+*/ 
+#define ARM_MPU_ACCESS_DEVICE(IsShareable) ((IsShareable) ? ARM_MPU_ACCESS_(0U, 1U, 0U, 1U) : ARM_MPU_ACCESS_(2U, 0U, 0U, 0U))
+
+/**
+* MPU Memory Access Attribute for normal memory.
+*  - TEX: 1BBb (reflecting outer cacheability rules)
+*  - Shareable or non-shareable
+*  - Cacheable or non-cacheable (reflecting inner cacheability rules)
+*  - Bufferable or non-bufferable (reflecting inner cacheability rules)
+*
+* \param OuterCp Configures the outer cache policy.
+* \param InnerCp Configures the inner cache policy.
+* \param IsShareable Configures the memory as shareable or non-shareable.
+*/ 
+#define ARM_MPU_ACCESS_NORMAL(OuterCp, InnerCp, IsShareable) ARM_MPU_ACCESS_((4U | (OuterCp)), IsShareable, ((InnerCp) & 2U), ((InnerCp) & 1U))
+
+/**
+* MPU Memory Access Attribute non-cacheable policy.
+*/
+#define ARM_MPU_CACHEP_NOCACHE 0U
+
+/**
+* MPU Memory Access Attribute write-back, write and read allocate policy.
+*/
+#define ARM_MPU_CACHEP_WB_WRA 1U
+
+/**
+* MPU Memory Access Attribute write-through, no write allocate policy.
+*/
+#define ARM_MPU_CACHEP_WT_NWA 2U
+
+/**
+* MPU Memory Access Attribute write-back, no write allocate policy.
+*/
+#define ARM_MPU_CACHEP_WB_NWA 3U
+
+
+/** Enable the MPU.
+*/
+__STATIC_INLINE void ARM_MPU_Enable(void)
+{
+	uint32_t tmp;
+
+	__get_CP(15, 0, tmp, 1, 0, 0);
+	tmp |= SCTLR_M_Msk;
+	__DSB();
+	__set_CP(15, 0, tmp, 1, 0, 0);
+	__ISB();
+}
+
+/** Clear and disable the given MPU region.
+* \param rnr Region number to be cleared.
+*/
+__STATIC_INLINE void ARM_MPU_ClrRegion(uint32_t rnr)
+{
+	uint32_t zero = 0;
+
+	__set_CP(15, 0, rnr, 6, 2, 0);
+	__ISB();
+	__set_CP(15, 0, zero, 6, 1, 2);
+	__ISB();
+}
+
+/** Disable the MPU.
+*/
+__STATIC_INLINE void ARM_MPU_Disable(void)
+{
+	uint32_t tmp;
+
+	__DSB();
+	__ISB();
+	__get_CP(15, 0, tmp, 1, 0, 0);
+	tmp &= ~SCTLR_M_Msk;
+	__DSB();
+	__set_CP(15, 0, tmp, 1, 0, 0);
+	__ISB();
+}
+
+/** Configure an MPU region.
+* \param rnr    Region number to be configured.
+* \param addr   Address of the start of the region. Must be aligned to the region size.
+* \param attrib Attributes of the region specified with @ref ARM_MPU_ATTRIB.
+* \param size   Size of the region, one of @ref ARM_MPU_REGION_SIZE_256B to @ref ARM_MPU_REGION_SIZE_4GB.
+*/   
+__STATIC_INLINE void ARM_MPU_SetRegionCR(uint32_t rnr, uint32_t addr, uint32_t attrib, uint32_t size)
+{
+	uint32_t val;
+
+	/* RGNR (MPU Memory Region Number Register) */
+	val = ARM_MPU_REGION(rnr);
+	__set_CP(15, 0, val, 6, 2, 0);
+	__ISB();
+
+	/* DRBAR (Data Region Base Address Register) */
+	__set_CP(15, 0, addr, 6, 1, 0);
+	__ISB();
+
+	/* DRACR (Data Region Access Control Register) */
+	__set_CP(15, 0, attrib, 6, 1, 4);
+	__ISB();
+
+	/* DRSR (Data Region Size and Enable Register) */
+	val = ARM_MPU_SIZE(0, size);
+	__set_CP(15, 0, val, 6, 1, 2);
+	__ISB();
+}
+
+/** Get the number of MPU regions that the device supports.
+*/
+__STATIC_INLINE uint32_t ARM_MPU_GetNrRegions(void)
+{
+	uint32_t tmp;
+
+	__DSB();
+	__ISB();
+	__get_CP(15, 0, tmp, 0, 0, 4);
+
+	return ((tmp >> 8) & 0xff);
+}
+
+/** @} */ /* End MPU */
+
+#endif
diff --git a/machines/cortex-r/armv7/RCar/Makefile b/machines/cortex-r/armv7/RCar/Makefile
new file mode 100644
index 00000000..b9fa91a3
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/Makefile
@@ -0,0 +1,41 @@
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Copyright ESEO for function and data structures documentation and ARM port
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# $Date$
+# $Rev$
+# $Author$
+# $URL$
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#          generated by goil.
+#
+#kernel OS architecture dependant files
+
+
+override CFLAGS += -std=gnu99 -mcpu=cortex-r7 -g
+
+include $(MACHINE_PATH)/cortex-r/armv7/RCar/common/Makefile
+include $(MACHINE_PATH)/cortex-r/armv7/RCar/CMSIS/Makefile
+
+MACHINE_INCLUDE_PATH += -I$(MACHINE_PATH)/cortex-r/armv7/RCar/common
+MACHINE_INCLUDE_PATH += -I$(MACHINE_PATH)/cortex-r/armv7/RCar/CMSIS
+
+MACHINE_ALL_PATHS += $(MACHINE_PATH)/cortex-r/armv7/RCar/common
+MACHINE_ALL_PATHS += $(MACHINE_PATH)/cortex-r/armv7/RCar/CMSIS
diff --git a/machines/cortex-r/armv7/RCar/common/Makefile b/machines/cortex-r/armv7/RCar/common/Makefile
new file mode 100644
index 00000000..127070b4
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/Makefile
@@ -0,0 +1,38 @@
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Copyright ESEO for function and data structures documentation and ARM port
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#
+# Trampoline OS
+#
+# Trampoline is copyright (c) IRCCyN 2005+
+# Trampoline is protected by the French intellectual property law.
+#
+# This software is distributed under the Lesser GNU Public Licence
+#
+# $Date$
+# $Rev$
+# $Author$
+# $URL$
+#
+# Warning: This Makefile SHOULD not be called directly.
+#          It is automatically called from the Makefile
+#          generated by goil.
+#
+#kernel OS architecture dependant files
+
+SOURCES += \
+boot.S \
+system_rcar_gen3.c \
+interrupts.c \
+tick_config.c \
+serial.c \
+scif.S
+
diff --git a/machines/cortex-r/armv7/RCar/common/asm_vectors.S b/machines/cortex-r/armv7/RCar/common/asm_vectors.S
new file mode 100644
index 00000000..4e03cc90
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/asm_vectors.S
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2019-2020 Renesas Electronics Europe Ltd. All Rights Reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+    .text
+    .code 32
+
+    .extern _reset
+    .extern FreeRTOS_IRQ_Handler
+    .extern FreeRTOS_SWI_Handler
+
+    .global _Reset
+
+.section .isr_vector
+
+_Reset:
+    ldr pc, =_reset			/* Reset Vector */
+    ldr pc, =undefined_handler
+    ldr pc, =FreeRTOS_SWI_Handler
+    ldr pc, =prefetch_handler
+    ldr pc, =abort_handler
+    ldr pc, =reserved_handler
+    ldr pc, =FreeRTOS_IRQ_Handler
+    ldr pc, =fiq_handler
+
+
+undefined_handler:
+    b  undefined_handler
+
+svc_handler:
+    b  svc_handler
+
+prefetch_handler:
+    b  prefetch_handler
+
+abort_handler:
+    b  abort_handler
+
+reserved_handler:
+    b  reserved_handler
+
+irq_handler:
+    b  irq_handler
+
+fiq_handler:
+    b  fiq_handler
+
+.end
diff --git a/machines/cortex-r/armv7/RCar/common/boot.S b/machines/cortex-r/armv7/RCar/common/boot.S
new file mode 100644
index 00000000..2a51d514
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/boot.S
@@ -0,0 +1,92 @@
+/*
+ * Copyright (C) 2019-2020 Renesas Electronics Europe Ltd. All Rights Reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+.extern usr_stack_bottom
+.extern irq_stack_bottom
+.extern svc_stack_bottom
+.extern abt_stack_bottom
+.extern fiq_stack_bottom
+.extern und_stack_bottom
+.extern _vector_table
+.extern SystemInit
+
+.global _reset
+.global software_init_hook
+.section .startup_code, "ax"
+
+#define MODE_MASK	0x1F		/* Bit mask for mode bits in CPSR */
+#define ARM_MODE_USR	0x10
+#define ARM_MODE_FIQ	0x11
+#define ARM_MODE_IRQ	0x12
+#define ARM_MODE_SVC	0x13
+#define ARM_MODE_MON	0x16
+#define ARM_MODE_ABT	0x17
+#define ARM_MODE_UND	0x1B
+#define ARM_MODE_SYS	0x1F
+
+_reset:
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_SYS	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =usr_stack_bottom
+	mov 	r14, #0
+
+	bl 	SystemInit		/* Initialize caches, MPU, etc */
+
+	bl	_start
+
+.Ldone:	b	.Ldone			/* Should never get here */
+
+
+/* Called by newlib crt0 _start after it has set up the stacks */
+software_init_hook:
+	/* Initialise stack pointers, registers are banked so we have to read PSR each time */
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_IRQ	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =irq_stack_bottom
+	mov 	r14, #0
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_SVC	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =svc_stack_bottom
+	mov 	r14, #0
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_ABT	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =abt_stack_bottom
+	mov 	r14, #0
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_FIQ	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =fiq_stack_bottom
+	mov 	r14, #0
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_UND	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =und_stack_bottom
+	mov 	r14, #0
+
+	mrs	r0, cpsr		/* Original PSR value */
+	bic	r0 ,r0, #MODE_MASK	/* Clear the mode bits */
+	orr	r0 ,r0, #ARM_MODE_SYS	/* Set mode bits */
+	msr	cpsr_c, r0		/* Change the mode */
+	ldr	sp, =usr_stack_bottom
+
+	mov		pc, lr          /* return to calling function */
+
+.end
diff --git a/machines/cortex-r/armv7/RCar/common/gpio.h b/machines/cortex-r/armv7/RCar/common/gpio.h
new file mode 100644
index 00000000..bf258360
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/gpio.h
@@ -0,0 +1,46 @@
+/*
+ * RCar GPIO support macros
+ *
+ */
+
+#ifndef __GPIO_H_
+#define __GPIO_H_
+
+/* MSTP for GPIO */
+#define MSTPSR9 (*(uint32 volatile *)0xE61509A4)
+/* channel mapping */
+#define GPIO_BASE_CH0 ((uint32 volatile *)0xE6050000)
+#define GPIO_BASE_CH1 ((uint32 volatile *)0xE6051000)
+#define GPIO_BASE_CH2 ((uint32 volatile *)0xE6052000)
+#define GPIO_BASE_CH3 ((uint32 volatile *)0xE6053000)
+#define GPIO_BASE_CH4 ((uint32 volatile *)0xE6054000)
+#define GPIO_BASE_CH5 ((uint32 volatile *)0xE6055000)
+#define GPIO_BASE_CH6 ((uint32 volatile *)0xE6055400)
+#define GPIO_BASE_CH7 ((uint32 volatile *)0xE6055800)
+
+/* register mapping macros */
+#define GPIO_IOINTSEL(ch) GPIO_BASE_CH ## ch[0]
+#define GPIO_INOUTSEL(ch) GPIO_BASE_CH ## ch[1]
+#define GPIO_OUTDT(ch)    GPIO_BASE_CH ## ch[2]
+#define GPIO_INDT(ch)     GPIO_BASE_CH ## ch[3]
+#define GPIO_INTDT(ch)    GPIO_BASE_CH ## ch[4]
+#define GPIO_INTCLR(ch)   GPIO_BASE_CH ## ch[5]
+#define GPIO_INTMSK(ch)   GPIO_BASE_CH ## ch[6]
+#define GPIO_MSKCLR(ch)   GPIO_BASE_CH ## ch[7]
+#define GPIO_POSNEG(ch)   GPIO_BASE_CH ## ch[8]
+#define GPIO_EDGLEVEL(ch) GPIO_BASE_CH ## ch[9]
+#define GPIO_FILONOFF(ch) GPIO_BASE_CH ## ch[10]
+#define GPIO_INTMSKS(ch)  GPIO_BASE_CH ## ch[14]
+#define GPIO_MSKCLRS(ch)  GPIO_BASE_CH ## ch[15]
+#define GPIO_OUTDTSEL(ch) GPIO_BASE_CH ## ch[16]
+#define GPIO_OUTDTH(ch)   GPIO_BASE_CH ## ch[17]
+#define GPIO_OUTDTL(ch)   GPIO_BASE_CH ## ch[18]
+#define GPIO_BOTHEDGE(ch) GPIO_BASE_CH ## ch[19]
+
+/* pin oriented expansion macros */
+#define GPIO_MSTP_OFF(ch)        MSTPSR9 &= ~(1<<(12-ch))
+#define GPIO_SET(reg,ch,pin) GPIO_ ## reg (ch) |= (1<<pin)
+#define GPIO_CLR(reg,ch,pin) GPIO_ ## reg (ch) &= ~(1<<pin)
+#define GPIO_EQU(reg,ch,pin) GPIO_ ## reg (ch) = (1<<pin)
+
+#endif /* __GPIO_H_*/
diff --git a/machines/cortex-r/armv7/RCar/common/heap_useNewlib.c b/machines/cortex-r/armv7/RCar/common/heap_useNewlib.c
new file mode 100644
index 00000000..aaab936b
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/heap_useNewlib.c
@@ -0,0 +1,45 @@
+#include <stdlib.h> // maps to newlib...
+#include <malloc.h> // mallinfo...
+#include <errno.h>  // ENOMEM
+#include <stdbool.h>
+#include <stddef.h>
+#include <stdint.h>
+
+#include "newlib.h"
+
+#include "tpl_os.h"
+
+// ================================================================================================
+// External routines required by newlib's malloc (sbrk/_sbrk, __malloc_lock/unlock)
+// ================================================================================================
+extern char HeapBase, HeapLimit, _HEAP_SIZE;  // make sure to define these symbols in linker command file
+static int heapBytesRemaining = (int)&_HEAP_SIZE; // that's (&HeapLimit)-(&HeapBase)
+
+//! _sbrk_r version supporting reentrant newlib (depends upon above symbols defined by linker control file).
+void * _sbrk_r(struct _reent *pReent, int incr) {
+    static char *currentHeapEnd = &HeapBase;
+    GetResource(RES_SCHEDULER);
+    if (currentHeapEnd + incr > &HeapLimit) {
+        // Ooops, no more memory available...
+        return (char *)-1; // the malloc-family routine that called sbrk will return 0
+    }
+    // 'incr' of memory is available: update accounting and return it.
+    char *previousHeapEnd = currentHeapEnd;
+    currentHeapEnd += incr;
+    heapBytesRemaining -= incr;
+    ReleaseResource(RES_SCHEDULER);
+    return (char *) previousHeapEnd;
+}
+//! non-reentrant sbrk uses is actually reentrant by using current context
+// ... because the current _reent structure is pointed to by global _impure_ptr
+char * sbrk(int incr) { return _sbrk_r(_impure_ptr, incr); }
+//! _sbrk is a synonym for sbrk.
+char * _sbrk(int incr) { return sbrk(incr); };
+
+void *pvPortMalloc( size_t xSize ) {
+    void *p = malloc(xSize);
+    return p;
+}
+void vPortFree( void *pv ) {
+    free(pv);
+}
\ No newline at end of file
diff --git a/machines/cortex-r/armv7/RCar/common/interrupts.c b/machines/cortex-r/armv7/RCar/common/interrupts.c
new file mode 100644
index 00000000..d94621f0
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/interrupts.c
@@ -0,0 +1,147 @@
+/*
+ * Copyright (c) 2019-2021 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include <stddef.h>
+#include "cmsis_rcar_gen3.h"
+#include "interrupts.h"
+#include "irq_ctrl.h"
+#include "register.h"
+
+/* The R-Car Gen3 has two interrupt controllers related to the CR7.
+ * The CR7 GIC only handles SGI (Software Generated Interrupt) and PPI (Private
+ * Peripheral Interrupt), it does not handle SPI (Shared Peripheral Interrupt)
+ * from peripheral modules Interrupt). For SPI, you need to use the INTC-RT.
+ * The output of INTC-RT is an input to the CR7 GIC on PPI[4].
+ *
+ * We use the ARM CMSIS code to manage the INTC-RT GIC, whereas the FreeRTOS
+ * interrupt related code just deals with the CR7 GIC.
+ */
+
+#define CR7_INTC_ROUTING_CTRL   0xE6271004U     /* INTCRTRCR */
+
+#define CR7_GICD_ADDR           ((void *)0xF0001000U)
+#define CR7_GICC_ADDR           ((void *)0xF0000100U)
+#define CR7_GIC_NR_IRQS         32
+#define CR7_GIC_ID_IRQ          31      /* PPI[4] legacy nIRQ input, from INTC-RT */
+
+#define INTC_RT_GICD_ADDR       ((void *)0xF1110000U)
+#define INTC_RT_GICC_ADDR       ((void *)0xF1120000U)
+#define INTC_RT_NR_IRQS         512
+
+#define DEFAULT_ISR_PRIORITY    0xA0
+#define ISR_PRIORITY_MASK       0xF0
+
+
+/* Special R-Car interrupt initialisation */
+static void CR7GicInit(void)
+{
+    uint32_t val;
+
+    /* Set 0th output signal of INTC-RT connect to CR7 */
+    val = readl(CR7_INTC_ROUTING_CTRL);
+    val |= BIT(8);
+    writel(val, CR7_INTC_ROUTING_CTRL);
+
+    GIC_Enable(CR7_GICD_ADDR, CR7_GICC_ADDR);
+
+    /* Enable legacy nIRQ (PPI[4]) in CR7 GIC. This comes from the INTC-RT GIC */
+    Irq_Enable(CR7_GIC_ID_IRQ);
+    Irq_SetPriority(CR7_GIC_ID_IRQ, DEFAULT_ISR_PRIORITY);
+}
+
+void Irq_Setup(void)
+{
+    CR7GicInit();
+
+    GIC_Enable(INTC_RT_GICD_ADDR, INTC_RT_GICC_ADDR);
+}
+
+/* Set up a CR7 or INTC-RT GIC entry */
+
+void Irq_Enable(unsigned int id)
+{
+    if (id <= CR7_GIC_ID_IRQ)
+        GIC_EnableIRQ(CR7_GICD_ADDR, id);
+    else
+        GIC_EnableIRQ(INTC_RT_GICD_ADDR, id);
+}
+
+void Irq_Disable(unsigned int id)
+{
+    if (id <= CR7_GIC_ID_IRQ)
+        GIC_DisableIRQ(CR7_GICD_ADDR, id);
+    else
+        GIC_DisableIRQ(INTC_RT_GICD_ADDR, id);
+}
+
+void Irq_SetPriority(unsigned int id, unsigned int priority)
+{
+    if (id <= CR7_GIC_ID_IRQ)
+        GIC_SetPriority(CR7_GICD_ADDR, id, priority);
+    else
+        GIC_SetPriority(INTC_RT_GICD_ADDR, id, priority);
+}
+
+/* CR7 GIC interrupt handler that also checks the INTC-RT GIC */
+void Irq_Handler(void)
+{
+    /*
+     * Interrupts cannot be re-enabled until the source of the interrupt is
+     * cleared. The ID of the interrupt is obtained by bitwise ANDing the ICCIAR
+     * value with 0x3FF
+     */
+    /*
+     * Start by checking the CR7 GIC and go from there
+     */
+    uint32_t id = IRQ_GetActiveIRQ(CR7_GICD_ADDR, CR7_GICC_ADDR) & 0x3FFU;
+    tpl_it_vector_entry const *pEntry;
+
+    /* If the interrupt is PPI[4], then the interrupt is generated by INTC-RT */
+    if (id == CR7_GIC_ID_IRQ)
+        id = IRQ_GetActiveIRQ(INTC_RT_GICD_ADDR, INTC_RT_GICC_ADDR);
+
+    /* Note: the GIC can return ID=1023 under certain conditions:
+     *  - forwarding of interrupts by the Distributor to the CPU interface is disabled
+     *  - signalling of interrupts by the CPU interface to the connected processor is disabled
+     *  - no pending interrupt on the CPU interface has sufficient priority for the interface to signal it to the processor.
+     */
+    if (id >= INTC_RT_NR_IRQS) {
+        return;
+    }
+
+    /* find our handler entry */
+    pEntry = &tpl_it_vector[id];
+
+    if (pEntry->func) {
+        /* Call application function for any processing */
+        pEntry->func(pEntry->args);
+
+        /* All INTC-RT interrupts are handled as Autosar Category 2 interrupts,
+         * i.e. they are not run from the interrupt handler context, so we need
+         * to disable the interrupts here.
+         */
+        if (id >= CR7_GIC_NR_IRQS) {
+            Irq_Disable(id);
+        }
+    } else {
+        /* No interrupt handler! */
+        while (1)
+            ;
+    }
+
+    /* If the interrupt was from the INTC-RT, clear it */
+    if (id >= CR7_GIC_NR_IRQS)
+    {
+        GIC_EndInterrupt(INTC_RT_GICC_ADDR, id);
+        /* we need to clear out the cr7 gic irq too */
+        GIC_EndInterrupt(CR7_GICC_ADDR, CR7_GIC_ID_IRQ);
+    }
+    else
+    {
+        /* unlike freertos, we need to clear here as no separate callback */
+        GIC_EndInterrupt(CR7_GICC_ADDR, id);
+    }
+}
diff --git a/machines/cortex-r/armv7/RCar/common/interrupts.h b/machines/cortex-r/armv7/RCar/common/interrupts.h
new file mode 100644
index 00000000..8101de6f
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/interrupts.h
@@ -0,0 +1,63 @@
+/*
+ * CMSIS GIC wrapper
+ *
+ * The CMSIS GIC code does most of what we need, with the exception of
+ * registering a context that is used in the interrupt callback.
+ *
+ * This wrapper also allows us to set the default properties for interrupts
+ * and do any device specifc initialisation.
+ */
+
+#ifndef __INTERRUPTS_H_
+#define __INTERRUPTS_H_
+/* TODO: Improve THIS */
+#include "tpl_os_interrupt_kernel.h"
+extern CONST(tpl_it_vector_entry, OS_CONST) tpl_it_vector[512];
+
+/** @defgroup group1 Interrupts
+ *  @brief Set up and configure the Generic Interrupt Controllers (GICs).
+ *
+ *  The R-Car devices utilize a cascading GIC structure where the output of the
+ *  RT-INTC GIC is used as the PPI[4] input to the CR7 GIC. This is abstracted
+ *  away by this API as all of the interrupt IDs are unique.
+ *  @{
+ */
+
+
+/**
+ * Initialize the interrupt controllers.
+ */
+void Irq_Setup(void);
+
+/**
+ * Enable an interrupt.
+ *
+ * @param id        Interrupt ID number.
+ */
+void Irq_Enable(unsigned int id);
+
+/**
+ * Disable an interrupt.
+ *
+ * @param id        Interrupt ID number.
+ */
+void Irq_Disable(unsigned int id);
+
+/**
+ * Set the priority of an interrupt.
+ *
+ * @param id        Interrupt ID number.
+ * @param priority  Priority of the interrupt.
+ */
+void Irq_SetPriority(unsigned int id, unsigned int priority);
+
+/**
+ * Handle the interrupt by calling table handler.
+ *
+ */
+void Irq_Handler(void);
+
+/** @} */ /* End Interrupts */
+
+
+#endif /* __INTERRUPTS_H_*/
diff --git a/machines/cortex-r/armv7/RCar/common/lscript.ld b/machines/cortex-r/armv7/RCar/common/lscript.ld
new file mode 100644
index 00000000..faecfcc1
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/lscript.ld
@@ -0,0 +1,254 @@
+
+/* These values may need changing depending on your app */
+_STACK_SIZE       = 0x4000;
+_IRQ_STACK_SIZE   = 0x400;
+_FIQ_STACK_SIZE   = 0x400;
+_SVC_STACK_SIZE   = 0x400;
+_ABORT_STACK_SIZE = 0x400;
+_UNDEF_STACK_SIZE = 0x400;
+_HEAP_SIZE        = 0x8000;
+/* Heap uses HeapBase global var, see configTOTAL_HEAP_SIZE */
+
+/* Note: See RCAR_VIDEO_BUFFER_START for additional memory used */
+
+MEMORY
+{
+   ddr_base_addr : ORIGIN = 0x40040000, LENGTH = 0x060000
+}
+
+ENTRY(_start)
+
+SECTIONS
+{
+.text : {
+   *(.isr_vector)
+   *(.vectors)
+   *(.boot)
+   *(.text)
+   *(.text.*)
+   *(.rawpcm)
+   *(.gnu.linkonce.t.*)
+   *(.plt)
+   *(.gnu_warning)
+   *(.gcc_execpt_table)
+   *(.glue_7)
+   *(.glue_7t)
+   *(.ARM.extab)
+   *(.gnu.linkonce.armextab.*)
+} > ddr_base_addr
+
+.init : {
+   KEEP (*(.init))
+} > ddr_base_addr
+
+.fini : {
+   KEEP (*(.fini))
+} > ddr_base_addr
+
+.interp : {
+   KEEP (*(.interp))
+} > ddr_base_addr
+
+.rodata : {
+   __rodata_start = .;
+   *(.rodata)
+   *(.rodata.*)
+   *(.gnu.linkonce.r.*)
+   __rodata_end = .;
+} > ddr_base_addr
+
+.rodata1 : {
+   __rodata1_start = .;
+   *(.rodata1)
+   *(.rodata1.*)
+   __rodata1_end = .;
+} > ddr_base_addr
+
+.data : {
+   __data_start = .;
+   *(.data)
+   *(.data.*)
+   *(.gnu.linkonce.d.*)
+   *(.jcr)
+   *(.got)
+   *(.got.plt)
+   __data_end = .;
+} > ddr_base_addr
+
+.data1 : {
+   __data1_start = .;
+   *(.data1)
+   *(.data1.*)
+   __data1_end = .;
+} > ddr_base_addr
+
+.got : {
+   *(.got)
+} > ddr_base_addr
+
+
+.ctors : {
+   __CTOR_LIST__ = .;
+   ___CTORS_LIST___ = .;
+   KEEP (*crtbegin.o(.ctors))
+   KEEP (*(EXCLUDE_FILE(*crtend.o) .ctors))
+   KEEP (*(SORT(.ctors.*)))
+   KEEP (*(.ctors))
+   __CTOR_END__ = .;
+   ___CTORS_END___ = .;
+} > ddr_base_addr
+
+.dtors : {
+   __DTOR_LIST__ = .;
+   ___DTORS_LIST___ = .;
+   KEEP (*crtbegin.o(.dtors))
+   KEEP (*(EXCLUDE_FILE(*crtend.o) .dtors))
+   KEEP (*(SORT(.dtors.*)))
+   KEEP (*(.dtors))
+   __DTOR_END__ = .;
+   ___DTORS_END___ = .;
+} > ddr_base_addr
+
+.fixup : {
+   __fixup_start = .;
+   *(.fixup)
+   __fixup_end = .;
+} > ddr_base_addr
+
+.eh_frame : {
+   *(.eh_frame)
+} > ddr_base_addr
+
+.eh_framehdr : {
+   __eh_framehdr_start = .;
+   *(.eh_framehdr)
+   __eh_framehdr_end = .;
+} > ddr_base_addr
+
+.gcc_except_table : {
+   *(.gcc_except_table)
+} > ddr_base_addr
+
+
+.ARM.exidx : {
+   __exidx_start = .;
+   *(.ARM.exidx*)
+   *(.gnu.linkonce.armexidix.*.*)
+   __exidx_end = .;
+} > ddr_base_addr
+
+.preinit_array : {
+   __preinit_array_start = .;
+   KEEP (*(SORT(.preinit_array.*)))
+   KEEP (*(.preinit_array))
+   __preinit_array_end = .;
+} > ddr_base_addr
+
+.init_array : {
+   __init_array_start = .;
+   KEEP (*(SORT(.init_array.*)))
+   KEEP (*(.init_array))
+   __init_array_end = .;
+} > ddr_base_addr
+
+
+.fini_array : {
+   __fini_array_start = .;
+   KEEP (*(SORT(.fini_array.*)))
+   KEEP (*(.fini_array))
+   __fini_array_end = .;
+} > ddr_base_addr
+
+.ARM.attributes : {
+   __ARM.attributes_start = .;
+   *(.ARM.attributes)
+   __ARM.attributes_end = .;
+} > ddr_base_addr
+
+.sdata : {
+   __sdata_start = .;
+   *(.sdata)
+   *(.sdata.*)
+   *(.gnu.linkonce.s.*)
+   __sdata_end = .;
+} > ddr_base_addr
+
+.sbss (NOLOAD) : {
+   __sbss_start = .;
+   *(.sbss)
+   *(.sbss.*)
+   *(.gnu.linkonce.sb.*)
+   __sbss_end = .;
+} > ddr_base_addr
+
+.tdata : {
+   __tdata_start = .;
+   *(.tdata)
+   *(.tdata.*)
+   *(.gnu.linkonce.td.*)
+   __tdata_end = .;
+} > ddr_base_addr
+
+.tbss : {
+   __tbss_start = .;
+   *(.tbss)
+   *(.tbss.*)
+   *(.gnu.linkonce.tb.*)
+   __tbss_end = .;
+} > ddr_base_addr
+
+.bss (NOLOAD) : {
+   . = ALIGN(4);
+   __bss_start__ = .;
+   *(.bss)
+   *(.bss.*)
+   *(.gnu.linkonce.b.*)
+   *(COMMON)
+   . = ALIGN(4);
+   __bss_end__ = .;
+} > ddr_base_addr
+
+/* Generate Stack and Heap definitions */
+
+.heap (NOLOAD) : {
+   . = ALIGN(16);
+   HeapBase = .;
+   __heap_start__ = .;
+   end = __heap_start__;
+   _end = end;
+   __end = end;
+   . += _HEAP_SIZE;
+   _heap_end = .;
+   HeapLimit = .;
+} > ddr_base_addr
+
+.stack (NOLOAD) : {
+   . = ALIGN(16);
+   _stack_end = .;
+   . += _STACK_SIZE;
+   _stack = .;
+   __stack = _stack;
+   . = ALIGN(16);
+   _irq_stack_end = .;
+   . += _IRQ_STACK_SIZE;
+   __irq_stack = .;
+   _supervisor_stack_end = .;
+   . += _SVC_STACK_SIZE;
+   . = ALIGN(16);
+   __supervisor_stack = .;
+   _abort_stack_end = .;
+   . += _ABORT_STACK_SIZE;
+   . = ALIGN(16);
+   __abort_stack = .;
+   _fiq_stack_end = .;
+   . += _FIQ_STACK_SIZE;
+   . = ALIGN(16);
+   __fiq_stack = .;
+   _undef_stack_end = .;
+   . += _UNDEF_STACK_SIZE;
+   . = ALIGN(16);
+   __undef_stack = .;
+} > ddr_base_addr
+
+_end = .;
+}
diff --git a/machines/cortex-r/armv7/RCar/common/main.c b/machines/cortex-r/armv7/RCar/common/main.c
new file mode 100644
index 00000000..626c946c
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/main.c
@@ -0,0 +1,216 @@
+/*
+ * FreeRTOS Kernel V10.2.1
+ * Copyright (C) 2019 Amazon.com, Inc. or its affiliates.  All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy of
+ * this software and associated documentation files (the "Software"), to deal in
+ * the Software without restriction, including without limitation the rights to
+ * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
+ * the Software, and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
+ * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
+ * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
+ * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * http://www.FreeRTOS.org
+ * http://aws.amazon.com/freertos
+ *
+ * 1 tab == 4 spaces!
+ */
+
+/******************************************************************************
+ * This project provides two demo applications.  A simple blinky style project,
+ * and a more comprehensive test and demo application.  The
+ * mainCREATE_SIMPLE_BLINKY_DEMO_ONLY setting (defined in this file) is used to
+ * select between the two.  The simply blinky demo is implemented and described
+ * in main_blinky.c.  The more comprehensive test and demo application is
+ * implemented and described in main_full.c.
+ *
+ * This file implements the code that is not demo specific, including the
+ * hardware setup and standard FreeRTOS hook functions.
+ *
+ * ENSURE TO READ THE DOCUMENTATION PAGE FOR THIS PORT AND DEMO APPLICATION ON
+ * THE http://www.FreeRTOS.org WEB SITE FOR FULL INFORMATION ON USING THIS DEMO
+ * APPLICATION, AND ITS ASSOCIATE FreeRTOS ARCHITECTURE PORT!
+ */
+
+/* Scheduler include files. */
+#include "FreeRTOS.h"
+#include "task.h"
+
+#include "interrupts.h"
+#include "register.h"
+
+/* Set mainCREATE_SIMPLE_BLINKY_DEMO_ONLY to one to run the simple blinky demo,
+or 0 to run the more comprehensive test and demo application. */
+#define mainCREATE_SIMPLE_BLINKY_DEMO_ONLY	1
+
+/*-----------------------------------------------------------*/
+
+/*
+ * Configure the hardware as necessary to run this demo.
+ */
+static void prvSetupHardware( void );
+
+/*
+ * main_blinky() is used when mainCREATE_SIMPLE_BLINKY_DEMO_ONLY is set to 1.
+ * main_full() is used when mainCREATE_SIMPLE_BLINKY_DEMO_ONLY is set to 0.
+ */
+extern void main_blinky( void );
+extern void main_full( void );
+
+/*-----------------------------------------------------------*/
+
+int main_unused( void )
+{
+	/* Configure the hardware ready to run the demo. */
+	prvSetupHardware();
+
+	/* The mainCREATE_SIMPLE_BLINKY_DEMO_ONLY setting is described at the top
+	of this file. */
+	#if mainCREATE_SIMPLE_BLINKY_DEMO_ONLY == 1
+	{
+		main_blinky();
+	}
+	#else
+	{
+		main_full();
+	}
+	#endif
+
+	/* Don't expect to reach here. */
+	return 0;
+}
+/*-----------------------------------------------------------*/
+
+static void prvSetupHardware( void )
+{
+	/* Ensure no interrupts execute while the scheduler is in an inconsistent
+	state.  Interrupts are automatically enabled when the scheduler is
+	started. */
+	portDISABLE_INTERRUPTS();
+
+	Irq_Setup();
+}
+/*-----------------------------------------------------------*/
+
+void vApplicationMallocFailedHook( void )
+{
+	/* Called if a call to pvPortMalloc() fails because there is insufficient
+	free memory available in the FreeRTOS heap.  pvPortMalloc() is called
+	internally by FreeRTOS API functions that create tasks, queues, software
+	timers, and semaphores.  The size of the FreeRTOS heap is set by the
+	configTOTAL_HEAP_SIZE configuration constant in FreeRTOSConfig.h. */
+	taskDISABLE_INTERRUPTS();
+	for( ;; );
+}
+/*-----------------------------------------------------------*/
+
+void vApplicationStackOverflowHook( TaskHandle_t pxTask, char *pcTaskName )
+{
+	( void ) pcTaskName;
+	( void ) pxTask;
+
+	/* Run time stack overflow checking is performed if
+	configCHECK_FOR_STACK_OVERFLOW is defined to 1 or 2.  This hook
+	function is called if a stack overflow is detected. */
+	taskDISABLE_INTERRUPTS();
+	for( ;; );
+}
+/*-----------------------------------------------------------*/
+
+void vApplicationIdleHook( void )
+{
+volatile size_t xFreeHeapSpace;
+
+	/* This is just a trivial example of an idle hook.  It is called on each
+	cycle of the idle task.  It must *NOT* attempt to block.  In this case the
+	idle task just queries the amount of FreeRTOS heap that remains.  See the
+	memory management section on the http://www.FreeRTOS.org web site for memory
+	management options.  If there is a lot of heap memory free then the
+	configTOTAL_HEAP_SIZE value in FreeRTOSConfig.h can be reduced to free up
+	RAM. */
+	xFreeHeapSpace = xPortGetFreeHeapSize();
+
+	/* Remove compiler warning about xFreeHeapSpace being set but never used. */
+	( void ) xFreeHeapSpace;
+}
+/*-----------------------------------------------------------*/
+
+void vApplicationTickHook( void )
+{
+	/* Nothing to do */
+}
+/*-----------------------------------------------------------*/
+
+/* configUSE_STATIC_ALLOCATION is set to 1, so the application must provide an
+implementation of vApplicationGetIdleTaskMemory() to provide the memory that is
+used by the Idle task. */
+void vApplicationGetIdleTaskMemory( StaticTask_t **ppxIdleTaskTCBBuffer, StackType_t **ppxIdleTaskStackBuffer, uint32_t *pulIdleTaskStackSize )
+{
+/* If the buffers to be provided to the Idle task are declared inside this
+function then they must be declared static - otherwise they will be allocated on
+the stack and so not exists after this function exits. */
+static StaticTask_t xIdleTaskTCB;
+static StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ];
+
+	/* Pass out a pointer to the StaticTask_t structure in which the Idle task's
+	state will be stored. */
+	*ppxIdleTaskTCBBuffer = &xIdleTaskTCB;
+
+	/* Pass out the array that will be used as the Idle task's stack. */
+	*ppxIdleTaskStackBuffer = uxIdleTaskStack;
+
+	/* Pass out the size of the array pointed to by *ppxIdleTaskStackBuffer.
+	Note that, as the array is necessarily of type StackType_t,
+	configMINIMAL_STACK_SIZE is specified in words, not bytes. */
+	*pulIdleTaskStackSize = configMINIMAL_STACK_SIZE;
+}
+/*-----------------------------------------------------------*/
+
+/* configUSE_STATIC_ALLOCATION and configUSE_TIMERS are both set to 1, so the
+application must provide an implementation of vApplicationGetTimerTaskMemory()
+to provide the memory that is used by the Timer service task. */
+void vApplicationGetTimerTaskMemory( StaticTask_t **ppxTimerTaskTCBBuffer, StackType_t **ppxTimerTaskStackBuffer, uint32_t *pulTimerTaskStackSize )
+{
+/* If the buffers to be provided to the Timer task are declared inside this
+function then they must be declared static - otherwise they will be allocated on
+the stack and so not exists after this function exits. */
+static StaticTask_t xTimerTaskTCB;
+static StackType_t uxTimerTaskStack[ configTIMER_TASK_STACK_DEPTH ];
+
+	/* Pass out a pointer to the StaticTask_t structure in which the Timer
+	task's state will be stored. */
+	*ppxTimerTaskTCBBuffer = &xTimerTaskTCB;
+
+	/* Pass out the array that will be used as the Timer task's stack. */
+	*ppxTimerTaskStackBuffer = uxTimerTaskStack;
+
+	/* Pass out the size of the array pointed to by *ppxTimerTaskStackBuffer.
+	Note that, as the array is necessarily of type StackType_t,
+	configMINIMAL_STACK_SIZE is specified in words, not bytes. */
+	*pulTimerTaskStackSize = configTIMER_TASK_STACK_DEPTH;
+}
+/*-----------------------------------------------------------*/
+
+int printf_raw(const char *format, ...);
+
+void vMainAssertCalled( const char *pcFileName, uint32_t ulLineNumber )
+{
+	/* Don't use printf as it uses FreeRTOS resources */
+	printf_raw("ASSERT!  Line %d of file %s\n", ulLineNumber, pcFileName);
+	taskENTER_CRITICAL();
+	for( ;; );
+}
+
+void vDeleteCallingTask( void )
+{
+     vTaskDelete( NULL );
+}
diff --git a/machines/cortex-r/armv7/RCar/common/r_os_cache.c b/machines/cortex-r/armv7/RCar/common/r_os_cache.c
new file mode 100644
index 00000000..a0b41519
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/r_os_cache.c
@@ -0,0 +1,54 @@
+/*
+ * Copyright (c) 2021 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include <stddef.h>
+#include "cmsis_rcar_gen3.h"
+#include "r_os_cache.h"
+
+/*
+ * This code is only for the R-Car Cortex R7 as it does not have a L2 cache.
+ * We could read the Cache Size ID Register (CCSIDR), to get the cache line size
+ * but Cortex-R7 only supports 32 bytes per cache line.
+ */
+#define LOC_L1_CACHE_LINE_SIZE	32U
+#define LOC_L1_CACHE_ADDR_MASK	(~0x1FU)
+#define LOC_L1_CACHE_SIZE	(16 * 1024)
+
+void R_OS_Cache_FlushData(uintptr_t Start_Addr, size_t Size)
+{
+	uintptr_t addr = Start_Addr & LOC_L1_CACHE_ADDR_MASK;
+	uintptr_t End_Addr = Start_Addr + Size;
+
+	if (End_Addr - Start_Addr > LOC_L1_CACHE_SIZE) {
+		/* If flushing a large region, it's faster to flush everything */
+		__L1C_MaintainDCacheSetWay(1, 1);
+	} else {
+		while (addr < End_Addr) {
+			__set_DCCMVAC(addr);
+			addr += LOC_L1_CACHE_LINE_SIZE;
+		}
+		__DMB();
+	}
+}
+
+void R_OS_Cache_InvalidateInstruction(uintptr_t Start_Addr, size_t Size)
+{
+	/* CMSIS doesn't have functions to invalidate by address, just
+	 * invalidate everything */
+	L1C_InvalidateICacheAll();
+}
+
+void R_OS_Cache_InvalidateData(uintptr_t Start_Addr, size_t Size)
+{
+	uintptr_t addr = Start_Addr & LOC_L1_CACHE_ADDR_MASK;
+	uintptr_t End_Addr = Start_Addr + Size;
+
+	while (addr < End_Addr) {
+		__set_DCIMVAC(addr);
+		addr += LOC_L1_CACHE_LINE_SIZE;
+	}
+	__DMB();
+}
diff --git a/machines/cortex-r/armv7/RCar/common/r_os_cache.h b/machines/cortex-r/armv7/RCar/common/r_os_cache.h
new file mode 100644
index 00000000..17fff187
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/r_os_cache.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (c) 2021 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#ifndef __R_OS_CACHE_H_
+#define __R_OS_CACHE_H_
+
+/** @defgroup group_cache Manage Caches
+ *  @brief Manage the instruction and data caches.
+ *
+ *  @{
+ */
+
+/**
+ * Flush an address range from the data cache.
+ * 
+ * This writes any dirty data in the cache to memory, so that another core can
+ * read the data.
+ *
+ * @param Start_Addr Start address of the range to be flushed.
+ * @param Size       Size in bytes to be flushed.
+ */
+void R_OS_Cache_FlushData(uintptr_t Start_Addr, size_t Size);
+
+/**
+ * Invalidate an address range from the instruction cache.
+ *
+ * @param Start_Addr Start address of the range to be invalidated.
+ * @param Size       Size in bytes to be invalidated.
+ */
+void R_OS_Cache_InvalidateInstruction(uintptr_t Start_Addr, size_t Size);
+
+/**
+ * Invalidate an address range from the data cache.
+ *
+ * WARNING: This will invalidate all data in the affected cache lines.
+ * If the CPU core has written data to the cache in one of these lines, but it
+ * has not yet been written back to memory, the changes are thrown away. You
+ * are advised to flush the data before invalidating it.
+ *
+ * @param Start_Addr Start address of the range to be invalidated.
+ * @param Size       Size in bytes to be invalidated.
+ */
+void R_OS_Cache_InvalidateData(uintptr_t Start_Addr, size_t Size);
+
+/** @} */
+
+#endif /* __R_OS_CACHE_H_*/
diff --git a/machines/cortex-r/armv7/RCar/common/register.h b/machines/cortex-r/armv7/RCar/common/register.h
new file mode 100644
index 00000000..56aa18da
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/register.h
@@ -0,0 +1,62 @@
+/*
+ * Copyright (c) 2019-2020 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+ 
+#ifndef REGISTER_H
+#define REGISTER_H
+
+/* Standard includes. */
+#include <stdio.h>
+#include <stdint.h>
+
+typedef uint32_t u32;
+typedef uint16_t u16;
+typedef uint8_t u8;
+
+/*-----------------------------------------------------------*/
+#define BIT(nr)			(1UL << (nr))
+#define BIT_MASK(nr)		(BIT(nr) - 1)
+/*
+ * Generic virtual read/write.  Note that we don't support half-word
+ * read/writes.  We define __arch_*[bl] here, and leave __arch_*w
+ * to the architecture specific code.
+ */
+#define __arch_getb(a)			(*(volatile unsigned char *)((u32)(a)))
+#define __arch_getw(a)			(*(volatile unsigned short *)((u32)(a)))
+#define __arch_getl(a)			(*(volatile unsigned int *)((u32)(a)))
+
+#define __arch_putb(v,a)		(*(volatile unsigned char *)((u32)(a)) = (v))
+#define __arch_putw(v,a)		(*(volatile unsigned short *)((u32)(a)) = (v))
+#define __arch_putl(v,a)		(*(volatile unsigned int *)((u32)(a)) = (v))
+
+#define __raw_writeb(v,a)	__arch_putb(v,a)
+#define __raw_writew(v,a)	__arch_putw(v,a)
+#define __raw_writel(v,a)	__arch_putl(v,a)
+
+#define __raw_readb(a)		__arch_getb(a)
+#define __raw_readw(a)		__arch_getw(a)
+#define __raw_readl(a)		__arch_getl(a)
+
+/*
+ * TODO: The kernel offers some more advanced versions of barriers, it might
+ * have some advantages to use them instead of the simple one here.
+ */
+#define reg_dmb()		__asm__ __volatile__ ("dmb" : : : "memory")
+#define __iormb()	reg_dmb()
+#define __iowmb()	reg_dmb()
+
+#define writeb(v,c)	({ u8  __v = (v); __iowmb(); __arch_putb(__v,c); __v; })
+#define writew(v,c)	({ u16 __v = (v); __iowmb(); __arch_putw(__v,c); __v; })
+#define writel(v,c)	({ u32 __v = (v); __iowmb(); __arch_putl(__v,c); __v; })
+
+#define readb(c)	({ u8  __v = __arch_getb(c); __iormb(); __v; })
+#define readw(c)	({ u16 __v = __arch_getw(c); __iormb(); __v; })
+#define readl(c)	({ u32 __v = __arch_getl(c); __iormb(); __v; })
+
+#define setbitsl(dest, bits)	(writel(readl(dest) | (bits), (dest)))
+#define clrbitsl(dest, bits)	(writel(readl(dest) & ~(bits), (dest)))
+
+#endif		/* REGISTER_H */
+
diff --git a/machines/cortex-r/armv7/RCar/common/scif.S b/machines/cortex-r/armv7/RCar/common/scif.S
new file mode 100644
index 00000000..9b8c932d
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/scif.S
@@ -0,0 +1,221 @@
+/*
+ * Copyright (c) 2015-2017, Renesas Electronics Corporation
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice,
+ *    this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * 3. Neither the names of the copyright holders nor the names of any
+ *    contributors may be used to endorse or promote products derived from this
+ *    software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifdef INTEGRITY_GUEST
+	/* FIXME: Workaround for compatibility with INTEGRITY guest */
+	#define SCIF SCIF1
+#endif
+
+	#include "scif.h"
+
+	.global	console_init
+	.global	console_putc
+	.global	console_wait
+
+console_init:
+	ldr	r0, =CPG_BASE
+	ldr	r1, [r0, #CPG_SMSTPCR3]
+	and	r1, r1, #~MSTP310		/* MSTP310=0 */
+	mvn	r2, r1
+	str	r2, [r0, #CPG_CPGWPR]
+	str	r1, [r0, #CPG_SMSTPCR3]
+
+	/* Enable MOD clock for SCIF1 or SCIF2.
+	   Do by setting the RMSTPCRn so that Linux will have
+	   no effect on it */
+#if SCIF==SCIF1
+	ldr	r1, [r0, #CPG_RMSTPCR2]
+	and	r1, r1, #~RMSTP206		/* RMSTP=0 -> SCIF1 */
+	mvn	r2, r1
+	str	r2, [r0, #CPG_CPGWPR]
+	str	r1, [r0, #CPG_RMSTPCR2]
+#endif
+
+	ldr	r0, =PFC_BASE
+	ldr	r1, [r0, #MOD_SEL1]
+#if SCIF==SCIF1
+	and	r1, r1, #~MOD_SEL1_SCIF2_MASK
+#else
+	and	r1, r1, #~MOD_SEL1_SCIF1_MASK
+#endif
+	mvn	r2, r1
+	str	r2, [r0, #PMMR]
+	str	r1, [r0, #MOD_SEL1]
+
+#if SCIF==SCIF1
+	ldr	r1, [r0, #IPSR11]
+	and	r1, r1, #~IPSR11_MASK
+	mov	r2, #IPSR11_INIT_DATA		/* IP11[19:16]=H'0, IP11[15:12]=H'0 */
+#else
+	ldr	r1, [r0, #IPSR12]
+	and	r1, r1, #~IPSR12_MASK
+	mov	r2, #IPSR12_INIT_DATA		/* IP12[7:4]=H'0, IP12[3:0]=H'0 */
+#endif
+	orr	r1, r1, r2
+	mvn	r2, r1
+	str	r2, [r0, #PMMR]
+#if SCIF==SCIF1
+	str	r1, [r0, #IPSR11]
+#else
+	str	r1, [r0, #IPSR12]
+#endif
+
+	ldr	r1, [r0, #GPSR5]
+	and	r1, r1, #~GPSR5_MASK		/* GP2[12]=Peripheral function selected by IP4[23:22] */
+	orr	r1, r1, #GPSR5_INIT_DATA	/* GP2[13]=Peripheral function selected by IP4[25:24] */
+	mvn	r2, r1
+	str	r2, [r0, #PMMR]
+	str	r1, [r0, #GPSR5]
+
+	ldr	r0, =SCIF_BASE
+	mov	r1, #0
+	strh	r1, [r0, #SCIF_SCSMRIR]
+	/* Clear bits TE and RE in SCSCR to 0 */
+	mov	r1, #(SCSCR_TE_DIS + SCSCR_RE_DIS)	/* TE=0,RE=0 */
+	strh	r1, [r0, #SCIF_SCSCR]
+	/* Set bits TFRST and RFRST in SCFCR to 1 */
+	ldrh	r1, [r0, #SCIF_SCFCR]
+	/* TFRESET=1,RFRESET=1 */
+	orr	r1, r1, #(SCFCR_TFRST_EN + SCFCR_RFRS_EN)
+	strh	r1, [r0, #SCIF_SCFCR]
+	/* Read flags of ER, DR, BRK, and RDF in SCFSR 		   */
+	/* and those of TO and ORER in SCLSR, then clear them to 0 */
+	mov	r1, #SCFSR_INIT_DATA
+	strh	r1, [r0, #SCIF_SCFSR]
+	mov	r1, #0
+	strh	r1, [r0, #SCIF_SCLSR]
+	/* Set bits CKE[1:0] in SCSCR */
+	ldrh	r1, [r0, #SCIF_SCSCR]
+	and	r1, r1, #~SCSCR_CKE_MASK
+	mov	r2, #SCSCR_CKE_INT_CLK		/* CKE=00 */
+	orr	r1, r1, r2
+	strh	r1, [r0, #SCIF_SCSCR]
+	/* Set data transfer format in SCSMR */
+	mov	r1, #SCSMR_INIT_DATA
+	/* CA=0,CHR=0,PE=0,STOP=0,CKS=P */
+	strh	r1, [r0, #SCIF_SCSMR]
+	/* Set value in SCBRR */
+#if SCIF_CLK == SCIF_INTERNAL_CLK
+	ldr	r1, =PRR
+	ldr	r1, [r1]
+	ldr	r2, =PRR_PRODUCT_CUT_MASK
+	and	r1, r1, r2
+	mov	r2, #PRR_PRODUCT_H3_VER_10
+	cmp	r1, r2
+	beq	3f
+	and	r1, r1, #PRR_PRODUCT_MASK
+	mov	r2, #PRR_PRODUCT_E3
+	cmp	r1, r2
+	bne	4f
+
+	ldr	r1, =RST_MODEMR
+	ldr	r1, [r1]
+	and	r1, r1, #MODEMR_MD12
+	mov	r2, #MODEMR_MD12
+	cmp	r1, r2
+	bne	4f
+
+	mov	r1, #SCBRR_115200BPS_E3_SSCG	/* 115200bps@60MHz SSCG */
+	b	2f
+4:
+	mov	r1, #SCBRR_115200BPS		/* 115200bps */
+	b	2f
+3:
+	/* H3 Ver.1.0 sets clock to doubling */
+	mov	r1, #SCBRR_230400BPS
+2:
+	strb	r1, [r0, #SCIF_SCBRR]
+#else
+	mov	r1, #DL_INIT_DATA
+	strh	r1, [r0, #SCIF_DL]
+	mov	r1, #CKS_INIT_DATA		/* CKS=0,XIN=0 */
+	strh	r1, [r0, #SCIF_CKS]
+#endif
+	/* 1-bit interval elapsed */
+	mov	r1, #100			/* 100 times */
+1:
+	subs	r1, r1, #1
+	bne	1b
+	/* Set bits RTRG[1:0], TTRG[1:0], and MCE in SCFCR, */
+	/* and clear bits FRST and RFRST to 0		    */
+	mov	r1, #SCFCR_INIT_DATA
+	strh	r1, [r0, #SCIF_SCFCR]
+	/* Set bits TE and RE in SCSCR to 1 */
+	ldrh	r1, [r0, #SCIF_SCSCR]
+	orr	r1, r1, #(SCSCR_TE_EN + SCSCR_RE_EN)	/* TE=1,RE=1 */
+	strh	r1, [r0, #SCIF_SCSCR]
+	mov	r1, #1
+
+	bx	lr
+
+console_putc:
+	ldr	r1, =SCIF_BASE
+	cmp	r0, #0xA
+	/* Prepend '\r' to '\n' */
+	bne	2f
+1:
+	/* Check if the transmit FIFO is full */
+	ldrh	r2, [r1, #SCIF_SCFDR]
+	ubfx	r2, r2, #8, #5
+	cmp	r2, #16
+	bcs	1b
+	mov	r2, #0x0D
+	strb	r2, [r1, #SCIF_SCFTDR]
+2:
+	/* Check if the transmit FIFO is full */
+	ldrh	r2, [r1, #SCIF_SCFDR]
+	ubfx	r2, r2, #8, #5
+	cmp	r2, #16
+	bcs	2b
+	strb	r0, [r1, #SCIF_SCFTDR]
+
+	/* Clear TEND flag */
+	ldrh	r2, [r1, #SCIF_SCFSR]
+	and	r2, r2, #~SCFSR_TEND_MASK
+	strh	r2, [r1, #SCIF_SCFSR]
+
+	bx	lr
+
+
+console_wait:
+	ldr	r1, =SCIF_BASE
+1:
+	/* Check TEND flag */
+	ldrh	r2, [r1, #SCIF_SCFSR]
+	and	r2, r2, #SCFSR_TEND_MASK
+	cmp	r2, #SCFSR_TEND_TRANS_END
+	bne	1b
+
+	bx	lr
+
+
+	.end
+
diff --git a/machines/cortex-r/armv7/RCar/common/scif.h b/machines/cortex-r/armv7/RCar/common/scif.h
new file mode 100644
index 00000000..f78e0a80
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/scif.h
@@ -0,0 +1,282 @@
+/*
+ * Copyright (c) 2015-2017, Renesas Electronics Corporation
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice,
+ *    this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * 3. Neither the names of the copyright holders nor the names of any
+ *    contributors may be used to endorse or promote products derived from this
+ *    software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __SCIF_H__
+#define __SCIF_H__
+
+#define BIT(nr)			(1UL << (nr))
+
+#define RCAR_SCIF1_BASEADDR	0xE6E68000
+#define RCAR_SCIF2_BASEADDR	0xE6E88000
+
+#ifdef INTEGRITY_GUEST
+	/* FIXME: Workaround for compatibility with INTEGRITY guest */
+	#if SCIF==SCIF1
+	#undef R_SCIF_CHAN
+	#define R_SCIF_CHAN 1
+	#endif
+#endif
+
+/*
+ * On Salvator-XS and Ebisu boards, U-Boot and Linux use SCIF2.
+ * On Salvator-XS, you have the option of using SCIF1 for the Cortex-R7.
+ * However, the Ebisu board doesn't have SCIF1 available on a connector.
+ */
+#if (R_SCIF_CHAN == 1)
+ #define STDOUT_BASEADDRESS RCAR_SCIF1_BASEADDR
+#else
+ #define STDOUT_BASEADDRESS RCAR_SCIF2_BASEADDR
+#endif
+
+#if (STDOUT_BASEADDRESS == RCAR_SCIF2_BASEADDR)
+#define SCIF_INTR_ID				SCIF2_INTR_ID
+#elif (STDOUT_BASEADDRESS == RCAR_SCIF1_BASEADDR)
+#define SCIF_INTR_ID				SCIF1_INTR_ID
+#else
+#error "Define a UART port\n"
+#endif
+
+
+/* Product Register */
+#define	PRR			(0xFFF00044)
+#define	PRR_PRODUCT_MASK	(0x00007F00)
+#define PRR_CUT_MASK		(0x000000FF)
+#define PRR_PRODUCT_CUT_MASK	(PRR_PRODUCT_MASK | PRR_CUT_MASK)
+#define	PRR_PRODUCT_H3_VER_10	(0x00004F00)	/* R-Car H3 Ver.1.0 */
+#define	PRR_PRODUCT_E3		(0x00005700)	/* R-Car E3 */
+
+
+#define	SCIF_INTERNAL_CLK	0	/* Internal clock(S3D4:66.66MHz) */
+#define	SCIF_EXTARNAL_CLK	1	/* External clock(SCK2:14.7456MHz) */
+#define	SCIF_CLK		    SCIF_INTERNAL_CLK
+#define SCIF1               0
+#define SCIF2               1
+#if (STDOUT_BASEADDRESS == RCAR_SCIF2_BASEADDR)
+#define	SCIF                SCIF2
+#else
+#define	SCIF                SCIF1
+#endif
+
+
+/* Pin functon */
+#ifndef PFC_BASE
+#define	PFC_BASE		(0xE6060000)
+#endif
+
+#define	PMMR			(0x0000)
+#define	GPSR5			(0x0114)
+#define	IPSR11			(0x022C)
+#define	IPSR12			(0x0230)
+#define	MOD_SEL1		(0x0504)
+
+/* module stop */
+#define	CPG_BASE		(0xE6150000)
+#define	CPG_SMSTPCR3		(0x013C)
+#define	CPG_RMSTPCR2		(0x0118)
+#define RMSTP206		(1 << 6)
+
+#define	MSTP310			(1 << 10)
+#define	CPG_CPGWPR		(0x0900)
+
+#define	SCIF_BASE		(STDOUT_BASEADDRESS)
+#define	SCIF_SCSMR		0x00		/* Serial mode register */
+#define	SCIF_SCBRR		0x04		/* Bit rate register */
+#define	SCIF_SCSCR		0x08		/* Serial control register */
+#define	SCIF_SCFTDR		0x0C		/* Transmit FIFO data register */
+#define	SCIF_SCFSR		0x10		/* Serial status register */
+#define SCIF_SCFRDR		0x14		/* Receive FIFO data register */
+#define	SCIF_SCFCR		0x18		/* FIFO control register */
+#define	SCIF_SCFDR		0x1C		/* FIFO data count register */
+#define SCIF_SCSPTR		0x20		/* Serial port register */
+#define	SCIF_SCLSR		0x24		/* Line status register */
+#define	SCIF_DL			0x30		/* Frequency division register */
+#define	SCIF_CKS		0x34		/* Clock Select register */
+#define	SCIF_SCSMRIR	0x40		/* Serial mode register */
+
+/* mode pin */
+#define	RST_MODEMR		(0xE6160060)
+#define	MODEMR_MD12		(0x00001000)	/* MD12 bit mask */
+
+#define	SCSMR_CA_MASK		(1 << 7)
+#define	SCSMR_CA_ASYNC		(0x0000)
+#define	SCSMR_CHR_MASK		(1 << 6)
+#define	SCSMR_CHR_8	    	(0x0000)
+#define	SCSMR_PE_MASK		(1 << 5)
+#define	SCSMR_PE_DIS		(0x0000)
+#define	SCSMR_STOP_MASK		(1 << 3)
+#define	SCSMR_STOP_1		(0x0000)
+#define	SCSMR_CKS_MASK		(3 << 0)
+#define	SCSMR_CKS_DIV1		(0x0000)
+#define	SCSMR_INIT_DATA		(SCSMR_CA_ASYNC + SCSMR_CHR_8 + \
+			                 SCSMR_PE_DIS + SCSMR_STOP_1 +	\
+			                 SCSMR_CKS_DIV1)
+
+#define	SCBRR_230400BPS		(8)		/* 230400bps@66MHz */
+#define	SCBRR_115200BPS_E3_SSCG	(15)		/* 115200bps@60MHz SSCG */
+#define	SCBRR_115200BPS		(17)		/* 115200bps@66MHz */
+#define	SCBRR_INIT_DATA		(SCBRR_230400BPS)
+
+#define	SCSCR_TE_MASK		(1 << 5)
+#define	SCSCR_TE_DIS		(0x0000)
+#define	SCSCR_TE_EN	    	(0x0020)
+#define	SCSCR_RE_MASK		(1 << 4)
+#define	SCSCR_RE_DIS		(0x0000)
+#define	SCSCR_RE_EN	    	(0x0010)
+#define	SCSCR_CKE_MASK		(3 << 0)
+#define SCSCR_CKE_INT		(0x0000)
+#define SCSCR_CKE_BRG		(0x0002)
+#if SCIF_CLK == SCIF_EXTARNAL_CLK
+#define	SCSCR_CKE_INT_CLK	(SCSCR_CKE_BRG)
+#else
+#define	SCSCR_CKE_INT_CLK	(SCSCR_CKE_INT)
+#endif
+
+#define	SCFSR_TEND_MASK		(1 << 6)
+#define	SCFSR_TEND_TRANS_END	(0x0040)
+#define	SCFSR_INIT_DATA		(0x0000)
+
+#define	SCFCR_TTRG_MASK		(3 << 4)
+#define	SCFCR_TTRG_8		(0x0000)
+#define	SCFCR_TTRG_0		(0x0030)
+#define	SCFCR_TFRST_MASK	(1 << 2)
+#define	SCFCR_TFRST_DIS		(0x0000)
+#define	SCFCR_TFRST_EN		(0x0004)
+#define	SCFCR_RFRS_MASK		(1 << 1)
+#define	SCFCR_RFRS_DIS		(0x0000)
+#define	SCFCR_RFRS_EN		(0x0002)
+#define	SCFCR_INIT_DATA		(SCFCR_TTRG_8)
+
+#define SCFDR_T_MASK		(0x1f << 8)
+#define SCFDR_R_MASK		(0x1f << 0)
+
+#define	DL_INIT_DATA		(8)		/* 14.7456MHz/(115200bps*16)*/
+			
+#define	CKS_CKS_DIV_MASK	(1 << 15)
+#define	CKS_CKS_DIV_CLK		(0x0000)
+#define	CKS_XIN_MASK		(1 << 14)
+#define	CKS_XIN_SCIF_CLK	(0x0000)
+#define	CKS_INIT_DATA		(CKS_CKS_DIV_CLK + CKS_XIN_SCIF_CLK)
+
+#if SCIF==SCIF1
+#define	GPSR5_MASK	(3 << 5)
+#else
+#define	GPSR5_MASK	(3 << 10)
+#endif
+
+#define	GPSR5_RX1_A	(1 << 5)
+#define	GPSR5_TX1_A	(1 << 6)
+#define	GPSR5_RX2_A	(1 << 11)
+#define	GPSR5_TX2_A	(1 << 10)
+#define	GPSR5_SCK2	(1 << 9)
+
+#if SCIF==SCIF1
+#define	GPSR5_INIT_DATA		(GPSR5_RX1_A + GPSR5_TX1_A)
+#else
+#if SCIF_CLK == SCIF_EXTARNAL_CLK
+#define	GPSR5_INIT_DATA		(GPSR5_RX2_A + GPSR5_TX2_A + GPSR5_SCK2)
+#else
+#define	GPSR5_INIT_DATA		(GPSR5_RX2_A + GPSR5_TX2_A)
+#endif
+#endif
+
+#define	IPSR11_MASK	    	(255 << 0)
+#define	IPSR11_RX1_A		(0 << 12)
+#define	IPSR11_TX1_A		(0 << 16)
+#define	IPSR11_INIT_DATA	(IPSR11_RX1_A + IPSR11_TX1_A)
+
+#define	IPSR12_MASK	    	(255 << 0)
+#define	IPSR12_RX2_A		(0 << 4)
+#define	IPSR12_TX2_A		(0 << 0)
+#define	IPSR12_INIT_DATA	(IPSR12_RX2_A + IPSR12_TX2_A)
+
+#define	MOD_SEL1_SCIF2_MASK	(1 << 12)
+#define	MOD_SEL1_SCIF2		(0 << 12)
+
+#define	MOD_SEL1_SCIF1_MASK	(1 << 11)
+#define	MOD_SEL1_SCIF1		(0 << 11)
+
+/*----------------------------------------------------------------------------*/
+#define SCIF0_INTR_ID		184
+#define SCIF1_INTR_ID		185
+#define SCIF2_INTR_ID		196
+#define SCIF3_INTR_ID		55
+#define SCIF4_INTR_ID		48
+#define SCIF5_INTR_ID		49
+/*----------------------------------------------------------------------------*/
+/*		Name		Offset		Size	Init-val */
+#define SCSMR		0x00	/* 16:	0x0000 */
+#define SCBRR		0x04	/* 8:	0xFF */
+#define SCSCR		0x08	/* 16:	0x0000 */
+#define SCFTDR		0x0C	/* 8:	Undefined */
+#define SCFSR		0x10	/* 16:	0x0060 */
+#define SCFRDR		0x14	/* 8:	Undefined */
+#define SCFCR		0x18	/* 16:	0x0000 */
+#define SCFDR		0x1C	/* 16:	0x0000 */
+#define SCSPTR		0x20	/* 16:	0x00XX (bit6,4,2,0 Undefined) */
+#define SCLSR		0x24	/* 16:	0x0000 */
+#define DL			0x30	/* 16:	0x0000 */
+#define CKS			0x34	/* 16:	0x0000 */
+/* Status Code */
+#define SCIF_ER		BIT(7)
+#define SCIF_TEND	BIT(6)
+#define SCIF_TDFE	BIT(5)
+#define SCIF_BRK	BIT(4)
+#define SCIF_FER	BIT(3)
+#define SCIF_PER	BIT(2)
+#define SCIF_RDF	BIT(1)
+#define SCIF_DR		BIT(0)
+#define SCIF_ERRORS	(SCIF_PER | SCIF_FER | SCIF_ER | SCIF_BRK)
+
+
+/* SCIF_INTRRUPT_OFFSET_BIT */
+#define SCSCR_CKE		0x0001		/* bit[1:0] */
+#define SCSCR_TOIE		BIT(2)
+#define SCSCR_REIE		BIT(3)
+#define SCSCR_RE		BIT(4)
+#define SCSCR_TE		BIT(5)
+#define SCSCR_RIE		BIT(6)
+#define SCSCR_TIE		BIT(7)
+#define SCSCR_TEIE		BIT(11)
+
+#define SCIF_ORER					0x0001
+
+#define	SCxSR_TEND					SCIF_TEND
+#define	SCxSR_ERRORS				SCIF_ERRORS
+#define	SCxSR_RDxF					SCIF_RDF
+#define	SCxSR_TDxE					SCIF_TDFE
+#define	SCxSR_FER					SCIF_FER
+#define	SCxSR_PER					SCIF_PER
+#define	SCxSR_BRK					SCIF_BRK
+#define	SCxSR_ORER					SCIF_ORER
+
+
+
+#endif	/* __SCIF_H__ */
diff --git a/machines/cortex-r/armv7/RCar/common/serial.c b/machines/cortex-r/armv7/RCar/common/serial.c
new file mode 100644
index 00000000..8a68e8d4
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/serial.c
@@ -0,0 +1,55 @@
+/*
+ * Copyright (c) 2019-2020 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+ 
+#include <stdarg.h>
+#include <stdio.h>
+#include <string.h>
+
+#include "scif.h"
+
+extern uint32_t console_init(void);
+extern void console_putc(char c);
+
+static int locSerialPortInitialized;
+
+void outbyte(char c)
+{
+	if (!locSerialPortInitialized) {
+		console_init();
+		locSerialPortInitialized = 1;
+	}
+
+	/* Standard practice to convert \n to \r\n */
+	if (c == '\n') {
+		console_putc('\r');
+	}
+
+	console_putc(c);
+}
+
+/* Override std C lib output for printf, fprintf */
+int _write(int file, char *ptr, int len)
+{
+	int i;
+
+	for (i = 0; i < len; i++) {
+		outbyte(*ptr++);
+	}
+
+	return len;
+}
+
+int printf_raw(const char *format, ...)
+{
+	va_list args;
+	int ret;
+
+	va_start(args, format);
+	ret = vfprintf(stderr, format, args);
+	va_end(args);
+
+	return ret;
+}
diff --git a/machines/cortex-r/armv7/RCar/common/system_rcar_gen3.c b/machines/cortex-r/armv7/RCar/common/system_rcar_gen3.c
new file mode 100644
index 00000000..df746156
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/system_rcar_gen3.c
@@ -0,0 +1,113 @@
+/*
+ * Copyright (C) 2019-2020 Renesas Electronics Europe Ltd. All Rights Reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include <stdint.h>
+#include <stdlib.h>
+#include <string.h>
+#include "cmsis_rcar_gen3.h"
+#include "register.h"
+
+#define R_CR7BAR	0xE6160070U
+
+extern uint32_t _Reset;
+#if ETHER_ENABLE
+extern uint32_t eth_non_cache_start;
+#endif
+
+extern int main(void);
+
+static void Init_MPU(void)
+{
+	int region = 0;
+	uint32_t attributes;
+	uint32_t nr_regions = ARM_MPU_GetNrRegions();
+
+	ARM_MPU_Disable();
+
+	/* ARM_MPU_ATTRIB = XN, AP, TEX, S, C, B. See DRACR register description for
+	 * the meanings */
+
+	/* Default */
+	attributes = ARM_MPU_ATTRIB(1, ARM_MPU_AP_NONE, 1, 0, 1, 1);
+	ARM_MPU_SetRegionCR(region++, 0x00000000U, attributes, ARM_MPU_REGION_SIZE_4GB);
+
+	/* Peripherals */
+	attributes = ARM_MPU_ATTRIB(1, ARM_MPU_AP_FULL, 2, 0, 0, 0);
+	ARM_MPU_SetRegionCR(region++, 0xC0000000U, attributes, ARM_MPU_REGION_SIZE_1GB);
+
+	/* Data */
+	/* This code is for all Ebsiu and Salvator-XS boards. All have 2GB at 0x4000_0000,
+	 * except the 4GB H3 Salvator-XS boards. Since we do not need to access above
+	 * 0x8000_0000, set the size to 1GB here.
+	 */
+	attributes = ARM_MPU_ATTRIB(1, ARM_MPU_AP_FULL, 1, 0, 1, 1);
+	ARM_MPU_SetRegionCR(region++, 0x40000000U, attributes, ARM_MPU_REGION_SIZE_1GB);
+
+	/* Code */
+	/* Note: Make sure the region marked as executable really exists. The CR7 branch
+	 * predictor can result in addresses to anywhere, but often only happen with optimised
+	 * code. Due to interactions with the cache, a bad branch predictor address falling
+	 * outside of valid DDR can look like random async aborts.
+	 */
+	attributes = ARM_MPU_ATTRIB(0, ARM_MPU_AP_FULL, 1, 0, 1, 1);
+	ARM_MPU_SetRegionCR(region++, (uint32_t)&_Reset, attributes, ARM_MPU_REGION_SIZE_256MB);
+
+	/*
+	 * The Cortex R7 can have the vectors at address 0x0 or 0xffff0000 (see the
+	 * SCTLR V bit). On R-Car they are at 0x0, but the access is offset by
+	 * the address programmed into the CR7BAR register. However, as far as
+	 * the MPU is concerned, the access is not offset.
+	 * Therefore, set the MPU to enable access to address 0x0 for the vectors.
+	 */
+	ARM_MPU_SetRegionCR(region++, 0x00000000U, attributes, ARM_MPU_REGION_SIZE_256B);
+
+#if ETHER_ENABLE
+	/* 128KB non-cached area for URAM (descriptor) area of ETH */
+	attributes = ARM_MPU_ATTRIB(1, ARM_MPU_AP_FULL, 1, 0, 0, 0);
+	ARM_MPU_SetRegionCR(region++, (uint32_t)&eth_non_cache_start, attributes, ARM_MPU_REGION_SIZE_128KB);
+#endif
+	while (region < nr_regions)
+		ARM_MPU_ClrRegion(region++);
+
+	ARM_MPU_Enable();
+}
+
+void SystemInit(void)
+{
+	/*
+	 * This is run before the C startup code, so global variables are not yet
+	 * initialised/cleared.
+	 */
+
+	/*
+	 * R-Car specific
+	 * Set the address of the vector table using RBAR. Note that although
+	 * we can change the address of the vector table using RBAR, as far as
+	 * the MPU is concerned, the vector table is still at address 0x0.
+	 */
+	writel((uint32_t)&_Reset, R_CR7BAR);
+	__ISB();
+	/* Enable BAREN */
+	writel((uint32_t)&_Reset | BIT(4), R_CR7BAR);
+
+	/* Enable Floating point hardware */
+#if (defined(__FPU_USED) && (__FPU_USED == 1U))
+	__FPU_Enable();
+#endif
+
+	L1C_DisableBTAC();
+	L1C_DisableCaches();
+	ARM_MPU_Disable();
+
+	L1C_InvalidateBTAC();
+	L1C_InvalidateICacheAll();
+	L1C_InvalidateDCacheAll();
+
+	Init_MPU();
+
+	L1C_EnableBTAC();
+	L1C_EnableCaches();
+}
diff --git a/machines/cortex-r/armv7/RCar/common/tick_config.c b/machines/cortex-r/armv7/RCar/common/tick_config.c
new file mode 100644
index 00000000..2dfe2db3
--- /dev/null
+++ b/machines/cortex-r/armv7/RCar/common/tick_config.c
@@ -0,0 +1,47 @@
+/*
+ * Copyright (c) 2019-2020 Renesas Electronics Europe Ltd. All rights reserved.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "register.h"
+#include "interrupts.h"
+
+// I can't find a configuration for TPL timer rate
+#define configTICK_RATE_HZ (1000)
+#define R_OS_BSP_GENERIC_ARM_TIMER_IRQNUM                29
+
+#define R_OS_BSP_GENERIC_ARM_CR7_PRIV_TIMER_BASEADDR     0xf0000600
+
+#define LOC_PTIMER_BASE R_OS_BSP_GENERIC_ARM_CR7_PRIV_TIMER_BASEADDR
+
+#define LOC_PTLR        (LOC_PTIMER_BASE + 0x00)
+#define LOC_PTCR        (LOC_PTIMER_BASE + 0x04)
+#define LOC_PTCONR      (LOC_PTIMER_BASE + 0x08)
+#define LOC_PTISR       (LOC_PTIMER_BASE + 0x0C)
+
+#define CR7_PRIV_TIMER_CLOCK    200000000   /* Hz */
+
+#define LOC_PT_WRITE32(ADDR, VAL) *((volatile unsigned int*)((uintptr_t)ADDR)) = (VAL)
+#define LOC_PT_READ32(ADDR) *((volatile unsigned int*)((uintptr_t)ADDR))
+
+static uint64_t loc_TickCount;
+
+void vConfigureTickInterrupt(void)
+{
+    uint32_t tmr_load_val = CR7_PRIV_TIMER_CLOCK / configTICK_RATE_HZ;
+
+    LOC_PT_WRITE32(LOC_PTLR, tmr_load_val);
+    LOC_PT_WRITE32(LOC_PTCONR, 0x7);
+}
+
+void vClearTickInterrupt(void)
+{
+    LOC_PT_WRITE32(LOC_PTISR, 0x1);
+    loc_TickCount++;
+}
+
+r_TickCounter_t R_OS_Get1msTickCount(void)
+{
+    return loc_TickCount;
+}
diff --git a/machines/cortex-r/armv7/tpl_asm_definitions.h b/machines/cortex-r/armv7/tpl_asm_definitions.h
new file mode 100644
index 00000000..41748b35
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_asm_definitions.h
@@ -0,0 +1,70 @@
+/**
+ * @file tpl_asm_definitions.h
+ *
+ * @section descr File description
+ *
+ * Common definitions for ARM assembler source files
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+#ifndef TPL_ASM_DEFINITIONS_H
+#define TPL_ASM_DEFINITIONS_H
+
+#include "tpl_os_definitions.h"
+#include "tpl_service_ids.h"
+
+/*
+ * tpl_kern data structure offsets (for use into assembler sources)
+ */
+#define TPL_KERN_OFFSET_S_RUNNING 0
+#define TPL_KERN_OFFSET_S_ELECTED 4
+#define TPL_KERN_OFFSET_RUNNING   8
+#define TPL_KERN_OFFSET_ELECTED   12
+#define TPL_KERN_OFFSET_RUNNING_ID 16
+#define TPL_KERN_OFFSET_ELECTED_ID 20
+#define TPL_KERN_OFFSET_NEED_SWITCH 24
+#define TPL_KERN_OFFSET_NEED_SCHEDULE 25
+
+/**
+ * tpl_proc data structure offsets
+ */
+#if WITH_MEMORY_PROTECTION == YES
+#define TPL_PROC_TRUSTED_COUNT 4
+#endif /* WITH_MEMORY_PROTECTION == YES */
+
+/*
+ * ARM modes codes
+ */
+#define CPSR_USR_MODE 0b10000
+#define CPSR_FIQ_MODE 0b10001
+#define CPSR_IRQ_MODE 0b10010
+#define CPSR_SVC_MODE 0b10011
+#define CPSR_ABT_MODE 0b10111
+#define CPSR_UND_MODE 0b11011
+#define CPSR_SYS_MODE 0b11111
+#define CPSR_MODE_MASK 0b11111
+
+/*
+ * Interrupt masks
+ */
+#define CPSR_IRQ_LOCKED 0b10000000
+#define CPSR_FIQ_LOCKED 0b01000000
+
+#endif /* TPL_ASM_DEFINITIONS_H */
+
+/* Enf of file tpl_asm_definitions.h */
diff --git a/machines/cortex-r/armv7/tpl_irq.S b/machines/cortex-r/armv7/tpl_irq.S
new file mode 100644
index 00000000..c22383c8
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_irq.S
@@ -0,0 +1,239 @@
+/**
+ * @file tpl_irq.S
+ *
+ * @section descr File description
+ *
+ * IRQ handling.
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+
+#include "tpl_asm_definitions.h"
+
+#define OS_START_SEC_CODE
+#include "tpl_as_memmap.h"
+/*
+ * First stage category 2 interrupt handler (which means only IRQ on
+ * this architecture, FIQ are category 1 interrupts)
+ */
+.global tpl_primary_irq_handler
+tpl_primary_irq_handler:
+  @push {r0-r12, lr}
+  @bl trace_in
+  @pop {r0-r12, lr}
+  @push {r0-r12, lr}
+  @bl trace_regs
+  @pop {r0-r12, lr}
+  @push {r0-r12, lr}
+  @bl trace_context
+  @pop {r0-r12, lr}
+  @push {r0-r12, lr}
+  @mov r0, sp
+  @bl trace_val
+  @pop {r0-r12, lr}
+
+@test:
+@  b test
+    /**********************
+     * KERNEL ENTER STAGE *
+     **********************
+     * After this stage, stack looks like this :
+     *
+     *         |---------------------------|
+     *         | task's return address     |
+     * SP+24-> |---------------------------|
+     *         | ip (r12)                  |
+     * SP+18-> |---------------------------|
+     *         | r11                       |
+     * SP+14-> |---------------------------|
+     *         | r9                        |
+     * SP+10-> |---------------------------|
+     *         | r3                        |
+     * SP+C -> |---------------------------|
+     *         | r2                        |
+     * SP+8 -> |---------------------------|
+     *         | r1                        |
+     * SP+4 -> |---------------------------|
+     *         | r0                        |
+     * SP   -> |---------------------------|
+     *
+     * Every caller-saved register is saved here, as the
+     * other ones shall be saved by callee. We don't want
+     * to save every register here as we don't know if
+     * a context switch is actually needed.
+     */
+
+    /* fix LR to make it point on task's return address */
+    sub lr, lr, #4
+    /* store caller-saved registers */
+    stmfd sp!, {r0-r3,r9,r11,ip,lr}
+    /* manage reentrance of kernel */
+    ldr r1, =nested_kernel_entrance_counter
+    ldr r2, [r1]
+    add r2, r2, #1
+    str r2, [r1]
+
+#if WITH_MEMORY_PROTECTION == YES
+    bl tpl_mp_kernel_enter
+#endif /* WITH_MEMORY_PROTECTION == YES */
+
+    /* reset tpl_kern variables */
+    ldr r1, =tpl_kern
+    mov r2, #NO_NEED_SWITCH
+    strb r2, [r1, #TPL_KERN_OFFSET_NEED_SWITCH]
+
+    /************************
+     * IRQ processing stage *
+     ************************/
+    bl tpl_arm_subarch_irq_handler
+
+#if WITH_MEMORY_PROTECTION == YES
+    bl tpl_mp_kernel_exit
+#endif
+
+    /***************************************************
+     * on the way to exit IRQ routine (with or without *
+     * context switch)                                 *
+     ***************************************************/
+context_switch_swi:
+    /* load the tpl_kern base address */
+    ldr r1, =tpl_kern
+
+    /* then, do we need to switch context ? */
+    mov r0, #0	/* set save parameter to 0 */
+    ldrb r2, [r1, #TPL_KERN_OFFSET_NEED_SWITCH]
+    cmp r2, #NO_NEED_SWITCH
+    beq irq_no_context_switch
+    mov r0, #1	/* set save parameter to 1 */
+
+    /*
+     * SAVES OLD CONTEXT
+     */
+
+    /* do we need to save the context ? if not, jump to load */
+    ldrb r2, [r1, #TPL_KERN_OFFSET_NEED_SWITCH]
+    tst r2, #NEED_SAVE
+    beq skip_save_context_irq
+
+    /* get the context block address */
+    ldr r2, [r1, #TPL_KERN_OFFSET_S_RUNNING] /* get the address of the context bloc */
+    ldr r2, [r2]                /* jump to context bloc (from static descriptor) */
+    add r2, r2, #(4 * 4)        /* jump over r0-r3 saving zone */
+    stmia r2, {r4-r14}^         /* save callee saved registers (r9 and r12 will be overwritten) */
+    sub r2, r2, #(4 * 4)        /* get back to begining of task's saving zone... */
+    mrs r4, spsr
+    str r4, [r2, #(16 * 4)]
+
+    /* save ABI's caller-saved registers, those which are saved into
+     * kernel_enter macro
+     */
+    ldmfd sp!, {r4-r7,r9,r11,ip,lr} /* /!\ r0-r3 <=> r4-r7 */
+    stmia r2, {r4-r7}
+    str r9, [r2, #(9*4)]
+    str r11, [r2, #(11*4)]
+    str ip, [r2, #(12*4)]
+    str lr, [r2, #(15*4)]
+
+    b load_context_irq
+
+    /* only executed if context saving step has not been done */
+skip_save_context_irq:
+    add sp, sp, #(8 * 4) /* skip saved register frame (8 = r0-r3 + r9 + r11 + r12 + r14) */
+
+load_context_irq:
+
+call_tpl_run_elected:
+	/* First call tpl_run_elected with the value of tpl_kern.need_switch
+	 * and get the value of the elected task.
+	 * tpl_kern.need_switch (stored into r3) is copied into r0
+	 */
+	bl tpl_run_elected
+
+  /* We updates kernel reentrance counter while registers are freely
+   * usable and as we know we won't enter in kernel again (IRQ locked and
+   * no SWI can occur) */
+    ldr r3, =nested_kernel_entrance_counter
+    ldr r2, [r3]
+    sub r2, r2, #1
+    str r2, [r3]
+
+    /*
+     * LOADS NEW CONTEXT
+     */
+
+    /* Get the context block address.
+     *
+     * We use r14 as it will be restored separatly and later, it
+     * is useful for the following ldmia instruction
+     */
+    ldr r1, =tpl_kern
+    ldr r14, [r1, #TPL_KERN_OFFSET_S_RUNNING] /* get the address of the context block */
+    ldr r14, [r14]                   /* jump to context bloc (from static descriptor) */
+
+    ldr r0, [r14, #(16 * 4)]        /* restore SPSR register from context block */
+    msr spsr, r0
+
+    /* finish load and get back to running task */
+    ldmia lr, {r0-r14}^
+    ldr lr, [lr, #(15 * 4)]
+
+    @push {r0-r12, lr}
+    @bl trace_2
+    @pop {r0-r12, lr}
+    @push {r0-r12, lr}
+    @bl trace_stack_irq
+    @pop {r0-r12, lr}
+
+    movs pc, lr
+
+    /********************************************
+     * KERNEL EXIT WITHOUT CONTEXT SWITCH STAGE *
+     ********************************************/
+irq_no_context_switch:
+    /* manage reentrance of kernel */
+    ldr r3, =nested_kernel_entrance_counter
+    ldr r2, [r3]
+    sub r2, r2, #1
+    str r2, [r3]
+
+    /* restore caller-saved registers */
+    ldmfd sp!, {r0-r3,r9,r11,ip,lr}
+    /* LR is 4 bytes far after return address */
+    add lr, lr, #4
+
+    @push {r0-r12, lr}
+    @bl trace_regs
+    @pop {r0-r12, lr}
+    @push {r0-r12, lr}
+    @bl trace_out
+    @pop {r0-r12, lr}
+
+    /* return to interrupted task */
+    subs pc,lr,#4
+    @movs pc,lr
+
+
+#define OS_STOP_SEC_CODE
+#include "tpl_as_memmap.h"
+
+#define OS_START_LTORG
+#include "tpl_as_memmap.h"
+#define OS_STOP_LTORG
+#include "tpl_as_memmap.h"
+
+/* End of file tpl_irq.S */
diff --git a/machines/cortex-r/armv7/tpl_machine.h b/machines/cortex-r/armv7/tpl_machine.h
new file mode 100644
index 00000000..48042bcb
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_machine.h
@@ -0,0 +1,72 @@
+/**
+ * @file tpl_machine.h
+ *
+ * @section descr File description
+ *
+ * Trampoline core exported definitions
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+#ifndef TPL_MACHINE_H
+#define TPL_MACHINE_H
+
+#include <stdint.h>
+#include "tpl_machine_arm.h"
+
+/**
+ * Gives the ARM processor mode the normal user tasks
+ * will run into. The value can be :
+ * - 0x10 : unprivileged
+ * - 0x1F : privileged
+ */
+#define USER_TASKS_ARM_MODE 0x1F
+
+typedef struct ARM_CONTEXT *tpl_context;
+
+extern struct ARM_CONTEXT idle_task_context;
+
+/**
+ * @def SIZE_OF_IDLE_TASK
+ *
+ * The size of the stack of the idle task which is also the stack
+ * used for machine startup
+ */
+#define IDLE_STACK_SIZE  300
+
+/*
+ * Configuration of systick timer (can be a generic timer if systick is not available
+ * on the target) for alarms and schedule tables.
+ */
+FUNC(void, OS_CODE) tpl_set_systick_timer();
+
+/* TODO : This function is called after an ISR2 has been terminated. It should
+ *        restore the hardware's cpu priority if it has been increased before
+ *        the execution of the ISR2 (see ppc/multicore/tpl_machine.h for an
+ *        example).
+ */
+#define tpl_restore_cpu_priority()
+
+
+/* Additional functions that can only be provided by the OS */
+typedef uint64_t r_TickCounter_t;
+
+r_TickCounter_t R_OS_Get1msTickCount(void);
+
+#endif /* TPL_MACHINE_H */
+
+/* End of file tpl_machine.h */
diff --git a/machines/cortex-r/armv7/tpl_machine_arm.c b/machines/cortex-r/armv7/tpl_machine_arm.c
new file mode 100644
index 00000000..6617c149
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_machine_arm.c
@@ -0,0 +1,306 @@
+/**
+ * @file tpl_machine_arm_generic.c
+ *
+ * @section descr File description
+ *
+ * common routines and variables for generic ARM platform
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+#include "tpl_machine.h"
+#include "tpl_machine_interface.h"
+#include "tpl_os_application_def.h"
+#include "tpl_os_definitions.h"
+#include "tpl_os.h"
+#if WITH_AUTOSAR == YES
+#include "tpl_as_definitions.h"
+#endif
+#include "tpl_os_interrupt.h"
+#include "interrupts.h"
+#include "gpio.h"
+
+#define OS_START_SEC_VAR_UNSPECIFIED
+#include "tpl_memmap.h"
+/**
+ * Stack for the idle task
+ */
+VAR(tpl_stack_word, OS_VAR) idle_stack[SIZE_OF_IDLE_STACK/sizeof(tpl_stack_word)];
+
+/**
+ * Context for the idle task
+ */
+VAR (arm_context, OS_VAR) idle_task_context;
+
+/**
+ * Kernel entry counter
+ */
+volatile VAR (uint32, OS_VAR) nested_kernel_entrance_counter;
+#define OS_STOP_SEC_VAR_UNSPECIFIED
+#include "tpl_memmap.h"
+
+#define API_START_SEC_CODE
+#include "tpl_memmap.h"
+
+#if TASK_COUNT > 0
+extern FUNC(void, OS_CODE) CallTerminateTask(void);
+#endif
+
+#if ISR_COUNT > 0
+extern FUNC(void, OS_CODE) CallTerminateISR2(void);
+#endif
+
+#define API_STOP_SEC_CODE
+#include "tpl_memmap.h"
+
+#define OS_START_SEC_CODE
+#include "tpl_memmap.h"
+
+/* GPIO5_5 pushbutton used to generate interrupts */
+#define PB_CH 5
+#define PB_PIN 5
+
+FUNC (void, OS_CODE) tpl_init_machine (void)
+{
+  nested_kernel_entrance_counter = 0;
+  Irq_Setup();
+#if WITH_MEMORY_PROTECTION == YES
+  tpl_init_mp();
+#endif
+  // TODO: Generate a tpl_init_external_interrupts();
+  /* enable any used interrupts in the GICs */
+  for(int i=0; i< (sizeof(tpl_it_vector)/sizeof(tpl_it_vector[0])); i++) {
+      if(tpl_null_it != tpl_it_vector[i].func) {
+          Irq_Enable(i);
+      }
+  }
+  tpl_set_systick_timer();
+
+  /* configure the pushbutton as IRQ */
+  {
+      /* make sure GPIO being clocked */
+      GPIO_MSTP_OFF(PB_CH);
+      /* set pin as irq source */
+      GPIO_SET(IOINTSEL,PB_CH,PB_PIN);
+      /* set pin positive logic */
+      GPIO_CLR(POSNEG,PB_CH,PB_PIN);
+      /* set pin to edge triggered */
+      GPIO_SET(EDGLEVEL,PB_CH,PB_PIN);
+      /* not both edges (rising edge) */
+      GPIO_CLR(BOTHEDGE,PB_CH,PB_PIN);
+      /* unmask the pin (generate interrupts) */
+      GPIO_EQU(MSKCLR,PB_CH,PB_PIN);
+  }
+}
+
+/*
+ * tpl_sleep is used by the idle task
+ */
+void idle_function(void)
+{
+
+  while(1) {
+  };
+}
+
+/**
+ * Call Terminate Task function when no TerminateTask hasn't been called
+ * or when TerminateTask didn't success because of resource hold or
+ * interrupts disabled.
+ *
+ */
+extern FUNC(void, OS_CODE) CallTerminateTask(void);
+
+
+/**
+ * Call Terminate ISR2 function when TerminateISR didn't success doing it
+ * because of resource hold or interrupts disabled.
+ *
+ */
+extern FUNC(void, OS_CODE) CallTerminateISR2(void);
+
+/*
+ * As kernel mode is non-interruptible, these function does nothing
+ */
+FUNC(void, OS_CODE) tpl_get_task_lock (void)
+{
+}
+
+FUNC(void, OS_CODE) tpl_release_task_lock (void)
+{
+}
+
+/**
+ * Enable interrupts
+ */
+void tpl_enable_interrupts(void)
+{
+  /* unlock is scheduled to next switch back to task */
+  __asm__
+  (
+  "mrs r0, spsr ;"
+  "bic r0, r0, #0b11000000 ;"
+  "msr spsr, r0 ;"
+  : : : "r0" // clobbered register
+  );
+
+}
+
+/**
+ * Disable interrupts
+ */
+void tpl_disable_interrupts(void)
+{
+
+  __asm__
+  (
+  "mrs r0, cpsr ;"
+  "orr r0, r0, #0b11000000 ;"
+  "msr cpsr, r0 ;"
+  "mrs r0, spsr ;" // interrupts remain locked in user space
+  "orr r0, r0, #0b11000000 ;"
+  "msr spsr, r0"
+  : : : "r0" // clobbered register
+  );
+
+}
+
+void tpl_disable_os_interrupts(void)
+{
+  tpl_disable_interrupts();
+}
+
+void tpl_enable_os_interrupts(void)
+{
+  tpl_enable_interrupts();
+}
+
+/*
+ * tpl_init_context initialize a context to prepare a task to run.
+ * It sets up the stack and the entry point
+ */
+FUNC(void, OS_CODE) tpl_init_context(
+    CONST(tpl_proc_id, OS_APPL_DATA) proc_id)
+{
+  struct ARM_CONTEXT *core_context;
+  const tpl_proc_static *the_proc;
+
+  /* initialize shortcuts */
+  the_proc = tpl_stat_proc_table[proc_id];
+  core_context = the_proc->context;
+#if WITH_PAINT_REGISTERS == YES || WITH_PAINT_STACK == YES
+  VAR(int, AUTOMATIC) i;
+  /* The size of the stack in 32 bits word above the esception frame */
+//  CONST(uint32, AUTOMATIC) size_of_stack_above_exception_frame =
+//    (the_proc->stack.stack_size - ARM_CORE_EXCEPTION_FRAME_SIZE) >> 2;
+  /* The pointer to the stack of the process */
+  CONSTP2VAR(tpl_stack_word, AUTOMATIC, OS_APPL_DATA) stack =
+    the_proc->stack.stack_zone;
+  CONST(uint32, AUTOMATIC) size_of_stack =
+    (the_proc->stack.stack_size) >> 2;
+#endif
+
+
+  // trace_var((const unsigned char*)"proc_id", (uint32)proc_id);
+  // trace_var((const unsigned char*)"the_proc->stack.stack_zone", (uint32)the_proc->stack.stack_zone);
+  // trace_var((const unsigned char*)"the_proc->stack.stack_size", (uint32)the_proc->stack.stack_size);
+  /* setup entry point */
+  core_context->r[armreg_pc] = (uint32)(the_proc->entry);
+  /* setup initial stack pointer */
+  core_context->r[armreg_sp] = ((uint32)the_proc->stack.stack_zone)
+      + the_proc->stack.stack_size;
+  /* task runs at a defined processor mode */
+  core_context->psr = USER_TASKS_ARM_MODE; /* macro defined into subarch part */
+
+  /*
+   * set the return address of the task/isr. This is usefull in case the
+   * user forgets to call TerminateTask/TerminateISR
+   * MISRA RULE 1,45,85 VIOLATION: the function pointer is used and stored
+   * in a 32bits variable, but as the Os is dependant on the target,
+   * the behaviour is controled
+   */
+  core_context->r[armreg_lr] = (IS_ROUTINE == the_proc->type) ?
+                                (uint32)(CallTerminateISR2) :
+                                (uint32)(CallTerminateTask); /*  lr  */
+
+  // trace_var((const unsigned char*)"core_context->r[armreg_sp]", core_context->r[armreg_sp]);
+  /* TODO: initialize stack footprint */
+#if WITH_PAINT_STACK == YES
+  /*
+   * Paint the stack with a pattern. This is not mandatory, so it is done
+   * only if the OIL OS attribute PAINT_STACK is set to TRUE. Otherwise the
+   * stack above the exception frame is not initialized.
+   */
+  for (i = 0; i < size_of_stack; i++)
+  {
+    stack[i] = OS_STACK_PATTERN;
+  }
+#endif
+
+}
+
+FUNC(uint8, OS_CODE) tpl_check_stack_footprint (
+    CONST(tpl_proc_id, OS_APPL_DATA) proc_id)
+{
+  uint8 tmp;
+  /*to do*/
+  tmp=0;
+  return tmp;
+}
+
+FUNC(void, OS_CODE) tpl_shutdown(void)
+{
+    /* FIXME: this is does not conform to AUTOSAR OS specifications,
+     * should return to main with initial context */
+    DISABLE_FIQ ();
+    DISABLE_IRQ ();
+
+    /* TODO : fall into very low consumption mode : all
+     * internal CPU clocks are disabled.
+     */
+
+    while (1);
+}
+
+void vConfigureTickInterrupt(void);
+void vClearTickInterrupt(void);
+FUNC(void, OS_CODE) tpl_set_systick_timer(void) {
+    vConfigureTickInterrupt();
+}
+
+/******************************************************************************
+ * IRQ acknowledge functions.
+ ******************************************************************************/
+FUNC(void, OS_CODE) CR7_PRIVATE_TIMER_ClearFlag(void) {
+    vClearTickInterrupt();
+}
+FUNC(void, OS_CODE) GPIO_CH5_ClearFlag(void)
+{
+    /* clear the IRQ from the GPIO */
+    GPIO_EQU(INTCLR,PB_CH,PB_PIN);
+}
+
+void tpl_arm_subarch_irq_handler ()
+{
+    Irq_Handler();
+}
+
+
+#define OS_STOP_SEC_CODE
+#include "tpl_memmap.h"
+
+/* End of file tpl_machine_arm_generic.c */
diff --git a/machines/cortex-r/armv7/tpl_machine_arm.h b/machines/cortex-r/armv7/tpl_machine_arm.h
new file mode 100644
index 00000000..58bb76f5
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_machine_arm.h
@@ -0,0 +1,170 @@
+/**
+ * @file tpl_machine_arm_generic.h
+ *
+ * @section descr File description
+ *
+ * Common definitions for generic ARM platform
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+
+#ifndef TPL_MACHINE_ARM_GENERIC_H
+#define TPL_MACHINE_ARM_GENERIC_H
+
+#include "tpl_os_std_types.h"
+#include "tpl_os_internal_types.h"
+#include "tpl_os_custom_types.h"
+
+/**
+ * ARM internal registers symbolic names
+ */
+typedef enum
+{
+  armreg_r0 = 0,
+    armreg_a1 = 0,
+  armreg_r1 = 1,
+    armreg_a2 = 1,
+  armreg_r2 = 2,
+    armreg_a3 = 2,
+  armreg_r3 = 3,
+    armreg_a4 = 3,
+  armreg_r4 = 4,
+    armreg_v1 = 4,
+  armreg_r5 = 5,
+    armreg_v2 = 5,
+  armreg_r6 = 6,
+    armreg_v3 = 6,
+  armreg_r7 = 7,
+    armreg_v4 = 7,
+  armreg_r8 = 8,
+    armreg_v5 = 8,
+  armreg_r9 = 9,
+    armreg_v6 = 9,
+    armreg_rfp = 9,
+  armreg_r10 = 10,
+    armreg_v7 = 10,
+    armreg_sl = 10,
+  armreg_r11 = 11,
+    armreg_v8 = 11,
+    armreg_fp = 11,
+  armreg_r12 = 12,
+    armreg_ip = 12,
+  armreg_r13 = 13,
+    armreg_sp = 13,
+  armreg_r14 = 14,
+    armreg_lr = 14,
+  armreg_r15 = 15,
+    armreg_pc = 15
+} tpl_arm_register_names;
+
+/**
+ * ARM core registers
+ */
+struct ARM_CONTEXT {
+  uint32 r[16];
+  uint32 psr;
+};
+
+/**
+ * ARM generic platform context
+ */
+typedef struct ARM_CONTEXT arm_context;
+
+/**
+ * default size of an element in a stack
+ */
+typedef uint32 tpl_stack_word;
+
+/**
+ * type of a stack size
+ */
+typedef uint32 tpl_stack_size;
+
+/**
+ * Stack definition
+ */
+struct TPL_STACK {
+    tpl_stack_word  *stack_zone;
+    tpl_stack_size  stack_size;
+};
+
+/**
+ * Stack definition
+ */
+typedef struct TPL_STACK tpl_stack;
+
+#define OS_STACK_PATTERN ((uint32)0xDEADBEEF)
+
+extern VAR (arm_context, OS_VAR) idle_task_context;
+
+/** 
+ * Defines the context block of the task "idle"
+ */
+#define IDLE_CONTEXT &idle_task_context
+
+#define SIZE_OF_IDLE_STACK 200
+
+extern VAR(tpl_stack_word, OS_VAR) idle_stack[SIZE_OF_IDLE_STACK/sizeof(tpl_stack_word)];
+
+/**
+ * Defines the stack (void) of the task "idle"
+ */
+#define IDLE_STACK {idle_stack,SIZE_OF_IDLE_STACK}
+
+
+/**
+ * Defines the entry point of the idle task
+ */
+#define IDLE_ENTRY tpl_sleep
+
+#define DISABLE_FIQ() __asm__ __volatile__ ("mrs r0, cpsr ;" \
+                                            "orr r0, r0, #0b01000000 ;" \
+                                            "msr cpsr_c, r0" \
+                                            : \
+                                            : \
+                                            : "r0")
+
+#define ENABLE_FIQ()  __asm__ __volatile__ ("mrs r0, cpsr ;" \
+                                            "bic r0, r0, #0b01000000 ;" \
+                                            "msr cpsr_c, r0" \
+                                            : \
+                                            : \
+                                            : "r0")
+
+#define DISABLE_IRQ() __asm__ __volatile__ ("mrs r0, cpsr ;" \
+                                            "orr r0, r0, #0b10000000 ;" \
+                                            "msr cpsr_c, r0" \
+                                            : \
+                                            : \
+                                            : "r0")
+
+#define ENABLE_IRQ()  __asm__ __volatile__ ("mrs r0, cpsr ;" \
+                                            "bic r0, r0, #0b10000000 ;" \
+                                            "msr cpsr_c, r0" \
+                                            : \
+                                            : \
+                                            : "r0")
+                                            
+
+FUNC (void, OS_CODE) tpl_init_machine_generic (void);
+
+FUNC(void, OS_CODE) CR7_PRIVATE_TIMER_ClearFlag(void);
+                                            
+#endif /* TPL_MACHINE_ARM_GENERIC_H */
+
+/* End of file tpl_machine_arm_generic.h */
diff --git a/machines/cortex-r/armv7/tpl_os_std_types.h b/machines/cortex-r/armv7/tpl_os_std_types.h
new file mode 100644
index 00000000..3109e7bc
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_os_std_types.h
@@ -0,0 +1,89 @@
+/**
+ * @file tpl_os_std_types_generic.h
+ *
+ * @section descr File description
+ *
+ * Trampoline standard types. Here for MISRA rule 13 compliance
+ * and for platform specific type definition
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date: 2010-10-27 15:34:11 +0200 (mer., 27 oct. 2010) $
+ * $Rev: 1227 $
+ * $Author: pacco $
+ * $URL: https://trampoline.rts-software.org/svn/trunk/machines/thumb2/tpl_os_std_types_generic.h $
+ */
+
+#ifndef TPL_OS_STD_TYPES_GENERIC_H
+#define TPL_OS_STD_TYPES_GENERIC_H
+
+/**
+ * @typedef u8
+ *
+ * 8 bits unsigned number
+ */
+typedef unsigned char   uint8;
+
+/**
+ * @typedef s8
+ *
+ * 8 bits signed number
+ */
+typedef signed char     sint8;
+
+/**
+ * @typedef u16
+ *
+ * 16 bits unsigned number
+ */
+typedef unsigned short  uint16;
+
+/**
+ * @typedef s16
+ *
+ * 16 bits signed number
+ */
+typedef signed short    sint16;
+
+/**
+ * @typedef u32
+ *
+ * 32 bits unsigned number
+ */
+typedef unsigned long   uint32;
+
+/**
+ * @typedef s32
+ *
+ * 32 bits signed number
+ */
+typedef signed long     sint32;
+
+/**
+ * @typedef u64
+ *
+ * 64 bits unsigned integer
+ */
+typedef unsigned long long uint64;
+
+/**
+ * @typedef s64
+ *
+ * 64 bits signed integer
+ */
+typedef signed long long sint64;
+
+#endif /* TPL_OS_STD_TYPES_GENERIC_H */
+
+/* End of file tpl_os_std_generic.h */
+
diff --git a/machines/cortex-r/armv7/tpl_stacks.S b/machines/cortex-r/armv7/tpl_stacks.S
new file mode 100644
index 00000000..02ffdb34
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_stacks.S
@@ -0,0 +1,97 @@
+/**
+ * @file tpl_stacks.s
+ *
+ * @section descr File description
+ *
+ * Provides system stacks for generic ARM port
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+
+/*
+ * Stacks are placed just after BSS segment as we don't need to initialize
+ * them. See into ldscript file.
+ */
+#include "tpl_stacks_size.h"
+
+#define OS_START_SEC_STACKS
+#include "tpl_as_memmap.h"
+
+/*
+ * IRQ mode stack
+ */
+.global irq_stack_top
+irq_stack_top:
+.space IRQ_STACK_SIZE
+.global irq_stack_bottom
+irq_stack_bottom:
+
+/*
+ * FIQ mode stack
+ */
+.global fiq_stack_top
+fiq_stack_top:
+.space FIQ_STACK_SIZE
+.global fiq_stack_bottom
+fiq_stack_bottom:
+
+/*
+ * Service mode stack
+ */
+.global svc_stack_top
+svc_stack_top:
+.space SVC_STACK_SIZE
+.global svc_stack_bottom
+svc_stack_bottom:
+
+/*
+ * Abort mode stack
+ */
+.global abt_stack_top
+abt_stack_top:
+.space ABT_STACK_SIZE
+.global abt_stack_bottom
+abt_stack_bottom:
+
+/*
+ * undefined mode stack
+ */
+.global und_stack_top
+und_stack_top:
+.space UND_STACK_SIZE
+.global und_stack_bottom
+und_stack_bottom:
+
+/*
+ * default user mode stack (used at startup and by IDLE task)
+ */
+.global usr_stack_top
+usr_stack_top:
+.space USR_STACK_SIZE
+.global usr_stack_bottom
+usr_stack_bottom:
+
+#define OS_STOP_SEC_STACKS
+#include "tpl_as_memmap.h"
+
+#define OS_START_LTORG
+#include "tpl_as_memmap.h"
+#define OS_STOP_LTORG
+#include "tpl_as_memmap.h"
+
+/* End of file tpl_stacks.h */
diff --git a/machines/cortex-r/armv7/tpl_stacks_size.h b/machines/cortex-r/armv7/tpl_stacks_size.h
new file mode 100644
index 00000000..af76808d
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_stacks_size.h
@@ -0,0 +1,40 @@
+/**
+ * @file tpl_stacks_size.h
+ *
+ * @section descr File description
+ *
+ * Trampoline standard types. Here for MISRA rule 13 compliance
+ * and for platform specific type definition
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+
+#ifndef TPL_OS_STACKS_SIZE_H
+#define TPL_OS_STACKS_SIZE_H
+
+#define IRQ_STACK_SIZE 256*4
+#define FIQ_STACK_SIZE 256*4
+#define SVC_STACK_SIZE 512*4
+#define ABT_STACK_SIZE 256*4
+#define UND_STACK_SIZE 256*4
+#define USR_STACK_SIZE 256*4
+
+#endif /* TPL_OS_STACKS_SIZE_H */
+
+/* End of file tpl_stacks_size.h */
+
diff --git a/machines/cortex-r/armv7/tpl_system_call.S b/machines/cortex-r/armv7/tpl_system_call.S
new file mode 100644
index 00000000..2888d2c7
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_system_call.S
@@ -0,0 +1,272 @@
+/**
+ * @file tpl_system_call.S
+ *
+ * @section descr File description
+ *
+ * System calls handling.
+ *
+ * @section copyright Copyright
+ *
+ * Trampoline OS
+ *
+ * Trampoline is copyright (c) IRCCyN 2005+
+ * Copyright ESEO for function and data structures documentation and ARM port
+ * Trampoline is protected by the French intellectual property law.
+ *
+ * This software is distributed under the Lesser GNU Public Licence
+ *
+ * @section infos File informations
+ *
+ * $Date$
+ * $Rev$
+ * $Author$
+ * $URL$
+ */
+
+#include "tpl_asm_definitions.h"
+
+#define OS_START_SEC_CODE
+#include "tpl_as_memmap.h"
+
+/* Main system call handler
+ *
+ * We take care to not alter callee saved registers
+ * which are all except r0-r3 (EABI convention).
+ *
+ * We do not use r3 because it is used to give the service number
+ * in a system call. After dispatching, r3 can be altered.
+ *
+ * This exception to EABI conventions is specific to system call
+ * mechanism.
+ */
+.global tpl_primary_syscall_handler
+tpl_primary_syscall_handler:
+  /**********************
+   * KERNEL ENTER STAGE *
+   **********************
+   * The stack generated after this stage looks like this :
+   *
+   *         |---------------------------|
+   *         | task's return address     |
+   * SP+16-> |---------------------------|
+   *         | r2 saved value            |
+   * SP+12-> |---------------------------|
+   *         | r1 saved value            |
+   * SP+8 -> |---------------------------|
+   *         | r0 saved value            |
+   * SP+4 -> |---------------------------|
+   *         | spsr #0                   |
+   * SP   -> |---------------------------|
+   *
+   * The SPSR is pushed to make possible to nest system calls
+   */
+
+  /* first we disable all IRQ (IRQ are ISR cat. 2, FIQ are
+   * ISR cat. 1) to prevent any preemption while in kernel
+   * mode.
+   */
+  msr cpsr_c, #(CPSR_IRQ_LOCKED | CPSR_SVC_MODE)
+
+  /* We save R0 to R2 here as they may contain system call
+   * parameter. We save LR as the task's return address.
+   * R3 is not saved as it is known to never being used as
+   * system call parameter (and contains system call number).
+   */
+  stmfd sp!, {r0-r2,lr}
+
+  /* System calls should be reentrant, so we have to
+   * save the SPSR on the stack. */
+  mrs r1, spsr
+  stmfd sp!, {r1}
+
+  /* manage reentrance of kernel */
+  ldr r1, =nested_kernel_entrance_counter
+  ldr r2, [r1]
+  add r2, r2, #1
+  str r2, [r1]
+  cmp r2, #1
+  bhi skip_kernel_enter
+
+#if WITH_MEMORY_PROTECTION == YES
+  stmfd sp!, {r3}    /* r3 must not be altered : it contains service s identifier */
+  bl tpl_mp_kernel_enter
+  ldmfd sp!, {r3}
+#endif /* WITH_MEMORY_PROTECTION == YES */
+
+  /* reset tpl_kern variables */
+  ldr r1, =tpl_kern
+  mov r2, #NO_NEED_SWITCH
+  strb r2, [r1, #TPL_KERN_OFFSET_NEED_SWITCH]
+
+skip_kernel_enter:
+  /*********************************
+   * SYSTEM CALL DISPATCHING STAGE *
+   *********************************/
+  /* WARNING : r3 should not be altered until here
+   * as it is used to give the service identifier while calling swi
+   */
+  cmp r3, #SYSCALL_COUNT
+  bhs invalid_service_id
+
+  /* get the appropriate system call address into R3 */
+  ldr r1, =tpl_dispatch_table
+  ldr r3, [r1, r3, LSL #2]
+
+  /* pop registers values from the stack without altering
+   * the stack pointer */
+  add sp, sp, #4     /* just jump over SPSR saved value */
+  ldmia sp, {r0-r2}
+  sub sp, sp, #4     /* restore current value of SP */
+
+  /* call the service (blx does not exist on ARM7TDMI, so we split it in
+   * two instructions) */
+  mov lr, pc
+  bx r3
+
+  /* we save back returned value (r0-r1) into r0-r1 saved values on the stack */
+  add sp, sp, #4
+  stmia sp, {r0-r1}
+  sub sp, sp, #4
+
+  /* check if context switch is needed (requested by system service) */
+  ldr r2, =tpl_kern
+  ldrb r2, [r2, #TPL_KERN_OFFSET_NEED_SWITCH]
+  cmp r2, #NO_NEED_SWITCH
+  beq swi_no_context_switch_exit
+
+  /* do not switch context nor do kernel exit if nested kernel entrance */
+  ldr r2, =nested_kernel_entrance_counter
+  ldr r2, [r2]
+  cmp r2, #1
+  bhi swi_skip_kernel_exit
+
+  /***************************
+   * CONTEXT SWITCHING STAGE *
+   ***************************/
+context_switch_swi:
+  /* load the tpl_kern base address */
+  ldr r1, =tpl_kern
+
+  /* do we need to save the context ? if not, jump to load */
+ 	mov r0, #0	/* set save parameter to 0 */
+  ldrb r2, [r1, #TPL_KERN_OFFSET_NEED_SWITCH]
+  tst r2, #NEED_SAVE
+  beq skip_save_context_swi
+  mov r0, #1	/* set save parameter to 1 */
+
+  /*
+   * SAVES OLD CONTEXT
+   */
+save_context_swi:
+  /* get the context block address */
+  ldr r2, [r1, #TPL_KERN_OFFSET_S_RUNNING] /* get the address of the context bloc */
+  ldr r2, [r2]                /* jump to context bloc (from static descriptor) */
+  add r2, r2, #(4 * 4)        /* jump over r0-r3 saving zone */
+  stmia r2, {r4-r14}^
+  sub r2, r2, #(4 * 4)        /* get back to begining of task's saving zone... */
+
+  ldmfd sp!, {r4}          /* as SWI is reentrant, true SPSR is found in the stack */
+  str r4, [r2, #(16 * 4)]
+
+  /* save ABI's caller-saved registers, those which are saved into
+   * kernel_enter macro
+   */
+  ldmfd sp!, {r4-r6} /* r0-r2 <=> r4-r6 */
+  stmia r2, {r4-r6}
+
+  ldmfd sp!, {r4}          /* pop task's return address */
+  str r4, [r2, #(15 * 4)]  /* and store it into task's saving zone */
+
+  /* NB: R3 is not saved as we know its value won't be significant */
+  b load_context_swi       /* jump to suite */
+
+  /* only executed if context saving step has not been done */
+skip_save_context_swi:
+  add sp, sp, #(5 * 4) /* discards kernel enter stack frame */
+
+  /*
+   * LOADS NEW CONTEXT
+   */
+load_context_swi:
+
+call_tpl_run_elected:
+	/* First call tpl_run_elected with the value of tpl_kern.need_switch
+	 * and get the value of the elected task.
+	 * tpl_kern.need_switch (stored into r3) is copied into r0
+	 */
+	bl tpl_run_elected
+
+#if WITH_MEMORY_PROTECTION == YES
+    bl tpl_mp_kernel_exit
+#endif
+
+  /* We updates kernel reentrance counter while registers are freely
+   * usable and as we know we won't enter in kernel again (IRQ locked and
+   * no SWI can occur) */
+  ldr r3, =nested_kernel_entrance_counter
+  ldr r2, [r3]
+  sub r2, r2, #1
+  str r2, [r3]
+
+  /* Get the context block address.
+   *
+   * We use r14 as it will be restored separatly and later, it
+   * is useful for the following ldmia instruction
+   */
+  ldr r1, =tpl_kern
+  ldr lr, [r1, #TPL_KERN_OFFSET_S_RUNNING] /* get the address of the context bloc */
+  ldr lr, [lr]                   /* jump to context bloc (from static descriptor) */
+
+  /* loads SPSR*/
+  ldr r0, [lr, #(16 * 4)]
+  msr spsr, r0
+
+  /* finish load and get back to running task */
+#if !defined NO_OKI_PIPELINE_BUG
+  ldmia lr, {r0-r14}^
+  b flush_pipeline
+flush_pipeline:
+  ldr lr, [lr, #(15 * 4)]
+  movs pc, lr
+#else
+  ldmia lr, {r0-r15}^
+#endif /* defined NO_OKI_PIPELINE_BUG */
+
+  /********************************************
+   * KERNEL EXIT WITHOUT CONTEXT SWITCH STAGE *
+   ********************************************/
+invalid_service_id:  /* currently, if invalid service id is specified, we do nothing */
+swi_no_context_switch_exit:
+
+#if WITH_MEMORY_PROTECTION == YES
+  /* in case we enter in trusted function, we must prepare
+   * the memory protection to give all rights to a process
+   * which is initially non-trusted
+   */
+  cmp r2, #0
+  bleq tpl_mp_kernel_exit
+#endif /* WITH_MEMORY_PROTECTION == YES */
+
+swi_skip_kernel_exit:
+  /* manage reentrance of kernel */
+  ldr r3, =nested_kernel_entrance_counter
+  ldr r2, [r3]
+  sub r2, r2, #1
+  str r2, [r3]
+
+  /* pops the kernel enter stack frame */
+  ldmfd sp!, {r3}
+  msr spsr, r3
+  ldmfd sp!, {r0-r2,lr}
+
+  movs pc, lr
+
+#define OS_STOP_SEC_CODE
+#include "tpl_as_memmap.h"
+
+#define OS_START_LTORG
+#include "tpl_as_memmap.h"
+#define OS_STOP_LTORG
+#include "tpl_as_memmap.h"
+
+/* End of file tpl_system_call.S */
diff --git a/machines/cortex-r/armv7/tpl_vector_table.s b/machines/cortex-r/armv7/tpl_vector_table.s
new file mode 100644
index 00000000..1d47307f
--- /dev/null
+++ b/machines/cortex-r/armv7/tpl_vector_table.s
@@ -0,0 +1,43 @@
+
+;@ ------------------------------------------------------------------
+;@ ------------------------------------------------------------------
+
+.section .vectbl, "ax"
+.code 32
+.align 2
+        
+@.align 4
+.global _Reset
+_Reset:
+    ldr pc, =_reset			/* Reset Vector */
+    ldr pc, =undefined_handler
+    ldr pc, =tpl_primary_syscall_handler
+    ldr pc, =prefetch_handler
+    ldr pc, =abort_handler
+    ldr pc, =reserved_handler
+    ldr pc, =tpl_primary_irq_handler
+    ldr pc, =fiq_handler
+
+
+undefined_handler:
+    b  undefined_handler
+
+svc_handler:
+    b  svc_handler
+
+prefetch_handler:
+    b  prefetch_handler
+
+abort_handler:
+    b  abort_handler
+
+reserved_handler:
+    b  reserved_handler
+
+irq_handler:
+    b  irq_handler
+
+fiq_handler:
+    b  fiq_handler
+
+.end
diff --git a/os/tpl_os_kernel.c b/os/tpl_os_kernel.c
index 5c2d3cde..72c7bda2 100644
--- a/os/tpl_os_kernel.c
+++ b/os/tpl_os_kernel.c
@@ -609,6 +609,26 @@ FUNC(void, OS_CODE) tpl_preempt(CORE_ID_OR_VOID(core_id))
     tpl_put_preempted_proc((tpl_proc_id)TPL_KERN_REF(kern).elected_id);
   }
 }
+//#define OTMv0 (change line )
+#ifdef OTMv0
+#define traceOTMv0(value) \
+ { \
+   __asm volatile ("MCR    P15, 0x0,%0,C13,C0,0x1" : :"r" (value)); \
+ }
+#define traceTASK_SWITCHED_IN(rtid) \
+{ \
+  traceOTMv0((rtid<<1)|0x0) \
+}
+#define traceISR2_SWITCHED_IN(isrid) \
+{ \
+  traceOTMv0((isrid<<1)|0x1) \
+}
+#else
+#define traceTASK_SWITCHED_IN(rtid) \
+ { \
+   __asm volatile ("MCR    P15, 0x0,%0,C13,C0,0x1" : :"r" (rtid)); \
+ }
+#endif
 
 /**
  * @internal
@@ -684,7 +704,15 @@ FUNC(P2CONST(tpl_context, AUTOMATIC, OS_CONST), OS_CODE)
   TPL_KERN_REF(kern).running = TPL_KERN_REF(kern).elected;
   TPL_KERN_REF(kern).s_running = TPL_KERN_REF(kern).s_elected;
   TPL_KERN_REF(kern).running_id = TPL_KERN_REF(kern).elected_id;
-
+#ifdef OTMv0
+  if (TPL_KERN_REF(kern).s_elected->type == IS_ROUTINE) {
+      traceISR2_SWITCHED_IN(TPL_KERN_REF(kern).running_id);
+  } else {
+      traceTASK_SWITCHED_IN(TPL_KERN_REF(kern).running_id);
+  }
+#else
+  traceTASK_SWITCHED_IN(TPL_KERN_REF(kern).running_id);
+#endif
   DOW_DO(printf(
     "start %s, %d\n",
     proc_name_table[TPL_KERN_REF(kern).running_id],
